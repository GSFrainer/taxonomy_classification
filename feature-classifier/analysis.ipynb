{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levels to handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [\"domain\", \"class\", \"order\", \"family\", \"genus\", \"species\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select type of splited data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitters = [\n",
    "    \"prop_0-1/min_5/RandomSplit_0\",\n",
    "    \"prop_0-1/min_5/RandomSplit_14\",\n",
    "    \"prop_0-1/min_5/RandomSplit_56\",\n",
    "    \"prop_0-1/min_5/RandomSplit_84\",\n",
    "    \"prop_0-1/min_5/RandomSplit_92\",\n",
    "    \"prop_0-1/min_5/RandomSplit_101\",\n",
    "    \"prop_0-1/min_5/RandomSplit_105\",\n",
    "    \"prop_0-1/min_5/RandomSplit_227\",\n",
    "    \"prop_0-1/min_5/StratifiedSplit2_0\",\n",
    "    \"prop_0-1/min_5/StratifiedSplit2_14\",\n",
    "    \"prop_0-1/min_5/StratifiedSplit2_56\",\n",
    "    \"prop_0-1/min_5/StratifiedSplit2_84\",\n",
    "    \"prop_0-1/min_5/StratifiedSplit2_92\",\n",
    "    \"prop_0-1/min_5/StratifiedSplit2_101\",\n",
    "    \"prop_0-1/min_5/StratifiedSplit2_105\",\n",
    "    \"prop_0-1/min_5/StratifiedSplit2_227\",\n",
    "\n",
    "    \"prop_0-1/min_10/RandomSplit_0\",\n",
    "    \"prop_0-1/min_10/RandomSplit_14\",\n",
    "    \"prop_0-1/min_10/RandomSplit_56\",\n",
    "    \"prop_0-1/min_10/RandomSplit_84\",\n",
    "    \"prop_0-1/min_10/RandomSplit_92\",\n",
    "    \"prop_0-1/min_10/RandomSplit_101\",\n",
    "    \"prop_0-1/min_10/RandomSplit_105\",\n",
    "    \"prop_0-1/min_10/RandomSplit_227\",    \n",
    "    \"prop_0-1/min_10/StratifiedSplit2_0\",\n",
    "    \"prop_0-1/min_10/StratifiedSplit2_14\",\n",
    "    \"prop_0-1/min_10/StratifiedSplit2_56\",\n",
    "    \"prop_0-1/min_10/StratifiedSplit2_84\",\n",
    "    \"prop_0-1/min_10/StratifiedSplit2_92\",\n",
    "    \"prop_0-1/min_10/StratifiedSplit2_101\",\n",
    "    \"prop_0-1/min_10/StratifiedSplit2_105\",\n",
    "    \"prop_0-1/min_10/StratifiedSplit2_227\",\n",
    "    \n",
    "    \"prop_0-2/min_5/RandomSplit_0\",\n",
    "    \"prop_0-2/min_5/RandomSplit_14\",\n",
    "    \"prop_0-2/min_5/RandomSplit_56\",\n",
    "    \"prop_0-2/min_5/RandomSplit_84\",\n",
    "    \"prop_0-2/min_5/RandomSplit_92\",\n",
    "    \"prop_0-2/min_5/RandomSplit_101\",\n",
    "    \"prop_0-2/min_5/RandomSplit_105\",\n",
    "    \"prop_0-2/min_5/RandomSplit_227\",\n",
    "    \"prop_0-2/min_5/StratifiedSplit2_0\",\n",
    "    \"prop_0-2/min_5/StratifiedSplit2_14\",\n",
    "    \"prop_0-2/min_5/StratifiedSplit2_56\",\n",
    "    \"prop_0-2/min_5/StratifiedSplit2_84\",\n",
    "    \"prop_0-2/min_5/StratifiedSplit2_92\",\n",
    "    \"prop_0-2/min_5/StratifiedSplit2_101\",\n",
    "    \"prop_0-2/min_5/StratifiedSplit2_105\",\n",
    "    \"prop_0-2/min_5/StratifiedSplit2_227\",\n",
    "    \n",
    "    \"prop_0-2/min_10/RandomSplit_0\",\n",
    "    \"prop_0-2/min_10/RandomSplit_14\",\n",
    "    \"prop_0-2/min_10/RandomSplit_56\",\n",
    "    \"prop_0-2/min_10/RandomSplit_84\",\n",
    "    \"prop_0-2/min_10/RandomSplit_92\",\n",
    "    \"prop_0-2/min_10/RandomSplit_101\",\n",
    "    \"prop_0-2/min_10/RandomSplit_105\",\n",
    "    \"prop_0-2/min_10/RandomSplit_227\",\n",
    "    \"prop_0-2/min_10/StratifiedSplit2_0\",\n",
    "    \"prop_0-2/min_10/StratifiedSplit2_14\",\n",
    "    \"prop_0-2/min_10/StratifiedSplit2_56\",\n",
    "    \"prop_0-2/min_10/StratifiedSplit2_84\",\n",
    "    \"prop_0-2/min_10/StratifiedSplit2_92\",\n",
    "    \"prop_0-2/min_10/StratifiedSplit2_101\",\n",
    "    \"prop_0-2/min_10/StratifiedSplit2_105\",\n",
    "    \"prop_0-2/min_10/StratifiedSplit2_227\",\n",
    "    \n",
    "    \"prop_0-05/min_10/RandomSplit_0\",\n",
    "    \"prop_0-05/min_10/RandomSplit_14\",\n",
    "    \"prop_0-05/min_10/RandomSplit_56\",\n",
    "    \"prop_0-05/min_10/RandomSplit_84\",\n",
    "    \"prop_0-05/min_10/RandomSplit_92\",\n",
    "    \"prop_0-05/min_10/RandomSplit_101\",\n",
    "    \"prop_0-05/min_10/RandomSplit_105\",\n",
    "    \"prop_0-05/min_10/RandomSplit_227\",\n",
    "    \"prop_0-05/min_10/StratifiedSplit2_0\",\n",
    "    \"prop_0-05/min_10/StratifiedSplit2_14\",\n",
    "    \"prop_0-05/min_10/StratifiedSplit2_56\",\n",
    "    \"prop_0-05/min_10/StratifiedSplit2_84\",\n",
    "    \"prop_0-05/min_10/StratifiedSplit2_92\",\n",
    "    \"prop_0-05/min_10/StratifiedSplit2_101\",\n",
    "    \"prop_0-05/min_10/StratifiedSplit2_105\",\n",
    "    \"prop_0-05/min_10/StratifiedSplit2_227\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files of feature-classifier predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_paths = { \n",
    "#     \"class\":    \"./\"+splitter+\"/class/results/data/taxonomy.tsv\", \n",
    "#     \"order\":    \"./\"+splitter+\"/order/results/data/taxonomy.tsv\", \n",
    "#     \"family\":   \"./\"+splitter+\"/family/results/data/taxonomy.tsv\", \n",
    "#     \"genus\":    \"./\"+splitter+\"/genus/results/data/taxonomy.tsv\",\n",
    "#     \"species\":  \"./\"+splitter+\"/species/results/data/taxonomy.tsv\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format taxonomic classification the data and split it in levels columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitLevels(row):\n",
    "    classifications = row[\"Taxon\"].split(\"; \")\n",
    "\n",
    "    levels_columns = {\n",
    "        \"d__\":\"domain\", \n",
    "        \"c__\":\"class\", \n",
    "        \"o__\":\"order\", \n",
    "        \"f__\":\"family\", \n",
    "        \"g__\":\"genus\", \n",
    "        \"s__\":\"species\"\n",
    "    }\n",
    "\n",
    "    for c in classifications:\n",
    "        if c[3:] == \"\" or c[:3] == \"Una\":\n",
    "            continue\n",
    "        \n",
    "        row[levels_columns[c[0:3]]] = c[3:]\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadLevelsColumns(dataset, level):\n",
    "    for l in levels:\n",
    "        dataset.insert(dataset.shape[1], l, np.nan)\n",
    "        if l == level:\n",
    "            break\n",
    "    \n",
    "    dataset = dataset.apply(SplitLevels, axis=1).dropna(axis=\"columns\", how=\"all\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check each row if the prediction matches the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckResults(row, level):\n",
    "    row[\"correct\"] = True\n",
    "\n",
    "    for l in levels:\n",
    "        if not l+\"_pred\" in row.index:\n",
    "            continue\n",
    "        row[\"correct\"] = (row[l+\"_pred\"] == row[l+\"_ref\"]) and row[\"correct\"]\n",
    "\n",
    "        if l == level:\n",
    "            break\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = []\n",
    "not_loaded = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute results analysis for each level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for splitter in splitters:\n",
    "    results_paths = { \n",
    "        \"class\":    \"./\"+splitter+\"/class/results/data/taxonomy.tsv\", \n",
    "        \"order\":    \"./\"+splitter+\"/order/results/data/taxonomy.tsv\", \n",
    "        \"family\":   \"./\"+splitter+\"/family/results/data/taxonomy.tsv\", \n",
    "        \"genus\":    \"./\"+splitter+\"/genus/results/data/taxonomy.tsv\",\n",
    "        \"species\":  \"./\"+splitter+\"/species/results/data/taxonomy.tsv\"\n",
    "    }\n",
    "    \n",
    "    for level, result_path in results_paths.items():\n",
    "        try:\n",
    "            results = pd.read_csv(result_path, sep=\"\\t\", index_col=0)\n",
    "            results = LoadLevelsColumns(results, level)\n",
    "\n",
    "            reference = pd.read_csv(\"../new_data/\"+splitter+\"/\"+level+\"/pr2_test_taxonomy.txt\", names=[\"Feature ID\", \"Taxon\"], sep=\"\\t\", index_col=0)\n",
    "            reference = LoadLevelsColumns(reference, level)\n",
    "        \n",
    "        except Exception as e:\n",
    "            not_loaded.append({\n",
    "                \"level\": level,\n",
    "                \"splitter\": splitter,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        data = results.join(reference, lsuffix=\"_pred\", rsuffix=\"_ref\")\n",
    "        data = data.apply(CheckResults, axis=1, level=level)\n",
    "\n",
    "        r.append({\n",
    "            \"level\":level,\n",
    "            \"splitter\": splitter,\n",
    "            \"total_of_sequences\": data.shape[0], \n",
    "            \"correct\": data.loc[data[\"correct\"]].shape[0], \n",
    "            \"wrong\": data.loc[~data[\"correct\"]].shape[0],\n",
    "            \"accuracy\": (data.loc[data[\"correct\"]].shape[0]/data.shape[0]),\n",
    "        })\n",
    "\n",
    "        print(\"Level: \"+level)\n",
    "        print(\"Splitter: \"+splitter)\n",
    "        print(\"Total of sequences: \"+str(data.shape[0]))\n",
    "        print(\"Correct predictions: \"+str(data.loc[data[\"correct\"]].shape[0]))\n",
    "        print(\"Wrong predictions: \"+str(data.loc[~data[\"correct\"]].shape[0]))\n",
    "        print(\"Accuracy: \"+str(data.loc[data[\"correct\"]].shape[0]/data.shape[0]))\n",
    "        print(\"\\n\")\n",
    "\n",
    "print(\"Not Loaded: \")\n",
    "print(not_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(data=r)\n",
    "a = a.sort_values(by=[\"splitter\", \"level\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gustavo_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
