{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stark/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import GradScaler\n",
    "\n",
    "dtype = torch.float\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "torch.get_default_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_bernoulli(seq, prob=0.005):\n",
    "    idx = torch.bernoulli(prob * torch.ones(len(seq))).nonzero().squeeze(dim=1)\n",
    "    s = list(seq)\n",
    "\n",
    "    for i in idx.tolist():\n",
    "        s[i] = \"N\"\n",
    "\n",
    "    return \"\".join(s)\n",
    "\n",
    "def sequences_augmentation(data, level, cat, n):\n",
    "    to_copy = data.loc[data[level] == cat]\n",
    "\n",
    "    new_data = to_copy[0:1]\n",
    "    new_data = new_data.drop(new_data.index[0])\n",
    "\n",
    "    while new_data.shape[0] < n:\n",
    "        qnt = ((n-(new_data.shape[0])) / to_copy.shape[0]).__ceil__()\n",
    "\n",
    "        new_data = pd.concat(([to_copy]*qnt)+[new_data])\n",
    "        new_data[\"truncated_sequence\"] = new_data[\"truncated_sequence\"].apply(augmentation_bernoulli, prob=0.002)\n",
    "        new_data = new_data.drop_duplicates(subset=[\"truncated_sequence\"])\n",
    "    \n",
    "    new_data = new_data[:n-to_copy.shape[0]]\n",
    "    return new_data\n",
    "\n",
    "def data_augmentation(data, level, lower, upper):\n",
    "    class_count = data.groupby(level)[level].count().reset_index(name=\"count\")\n",
    "    \n",
    "    cats = class_count.loc[(class_count[\"count\"] < upper) & (class_count[\"count\"] >= lower)][level].to_list()\n",
    "\n",
    "    clones = sequences_augmentation(data, level, cats[0], upper)\n",
    "    for cat in cats[1:]:\n",
    "        clones = pd.concat([clones, sequences_augmentation(data, level, cat, upper)])\n",
    "\n",
    "    return pd.concat([data, clones])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_map = {\n",
    "    \"A\":[1.0, 0.0, 0.0, 0.0],\n",
    "    \"T\":[0.0, 1.0, 0.0, 0.0],\n",
    "    \"G\":[0.0, 0.0, 1.0, 0.0],\n",
    "    \"C\":[0.0, 0.0, 0.0, 1.0],\n",
    "\n",
    "    'W':[0.5, 0.5, 0.0, 0.0],\n",
    "    'S':[0.0, 0.0, 0.5, 0.5],\n",
    "    'M':[0.5, 0.0, 0.0, 0.5],\n",
    "    'K':[0.0, 0.5, 0.5, 0.0],\n",
    "    'R':[0.5, 0.0, 0.5, 0.0],\n",
    "    'Y':[0.0, 0.5, 0.0, 0.5],\n",
    "    \n",
    "    'B':[0.0, 0.3, 0.3, 0.3],\n",
    "    'D':[0.3, 0.3, 0.3, 0.0],\n",
    "    'H':[0.3, 0.3, 0.0, 0.3],\n",
    "    'V':[0.3, 0.0, 0.3, 0.3],\n",
    "\n",
    "    'N':[0.25, 0.25, 0.25, 0.25],\n",
    "}\n",
    "\n",
    "def encode_sequence(sequence):\n",
    "    encoded_seq = []\n",
    "\n",
    "    for base in sequence:\n",
    "        encoded_seq.append(base_map[base])\n",
    "    \n",
    "    return torch.tensor(encoded_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch dataset object to load Sequences and Classification Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, train, test, level, augmentation=False):\n",
    "\n",
    "        self.classes = pd.concat([train[level], test[level]]).unique().tolist()\n",
    "        self.classes.sort()\n",
    "        self.level = level\n",
    "\n",
    "        if augmentation:\n",
    "            train = data_augmentation(train, level, 10, 500)\n",
    "        \n",
    "        self.labels = train[level]\n",
    "        self.encoded_labels = SequenceDataset.__encoded_labels__(self.classes, self.labels)\n",
    "        self.sequences = SequenceDataset.__sequences__(train)\n",
    "\n",
    "        self.test = SequenceDatasetTest(\n",
    "            labels = test[level],\n",
    "            classes = self.classes,\n",
    "            encoded_labels = SequenceDataset.__encoded_labels__(self.classes, test[level]),\n",
    "            sequences = SequenceDataset.__sequences__(test)\n",
    "            )\n",
    "\n",
    "    def __encoded_labels__(classes, labels):\n",
    "        return torch.nn.functional.one_hot(torch.tensor([classes.index(l) for l in labels]), len(classes)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    def __sequences__(ds):\n",
    "        sequences = []\n",
    "        for _, row in ds.iterrows():\n",
    "            sequences.append(encode_sequence(row[\"truncated_sequence\"]))        \n",
    "        return torch.stack(sequences, dim=0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return   self.sequences[idx], self.encoded_labels[idx]\n",
    "    \n",
    "    def __getitems__(self, ids):\n",
    "        idx = torch.tensor(ids, device=torch.device('cuda:0'))\n",
    "        return   list(zip(torch.index_select(self.sequences, 0, idx), torch.index_select(self.encoded_labels, 0, idx)))\n",
    "    \n",
    "    def get_test(self):\n",
    "        return self.test\n",
    "\n",
    "class SequenceDatasetTest(SequenceDataset):    \n",
    "    def __init__(self, labels, classes, encoded_labels, sequences):\n",
    "        self.labels = labels\n",
    "        self.classes = classes\n",
    "        self.encoded_labels = encoded_labels\n",
    "        self.sequences = sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate PyTorch DataLoader objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaders_generator(ds_train, ds_test, bs = 128):\n",
    "    train_loader = DataLoader(ds_train, batch_size=bs, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "    test_loader = DataLoader(ds_test, batch_size=bs, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=4):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        # Padding to maintain input size\n",
    "        self.padding = nn.CircularPad1d((1,2))\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        \n",
    "        # Activation\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Store the input for the residual connection\n",
    "        residual = x\n",
    "        \n",
    "        # Main path\n",
    "        out = self.padding(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        residual = self.shortcut(residual)\n",
    "        \n",
    "        # Add residual connection\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class SimplestCNNClassifier_2layers_Residual(nn.Module):\n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier_2layers_Residual, self).__init__()\n",
    "        \n",
    "        # Residual blocks with adaptive pooling\n",
    "        self.residual_block1 = ResidualBlock(4, 16)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "        \n",
    "        self.residual_block2 = ResidualBlock(16, 32)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "        \n",
    "        # Activation and fully connected layers\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        # Calculate the input size for linear layers\n",
    "        # You might need to adjust this based on your specific input dimensions\n",
    "        self.linear1 = nn.Linear(7200, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Move channel dimension\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "        \n",
    "        # First residual block\n",
    "        x = self.residual_block1(x)\n",
    "        x = self.adAvgPool1(x)\n",
    "        \n",
    "        # Second residual block\n",
    "        x = self.residual_block2(x)\n",
    "        x = self.adAvgPool2(x)\n",
    "        \n",
    "        # Flatten and fully connected layers\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier_8layers_Residual(nn.Module):\n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier_8layers_Residual, self).__init__()\n",
    "        \n",
    "        # Residual blocks with adaptive pooling\n",
    "        self.residual_block1 = ResidualBlock(4, 16)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "        \n",
    "        self.residual_block2 = ResidualBlock(16, 32)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "        \n",
    "        self.residual_block3 = ResidualBlock(32, 64)\n",
    "        self.adAvgPool3 = nn.AdaptiveAvgPool1d(112)\n",
    "        \n",
    "        self.residual_block4 = ResidualBlock(64, 128)\n",
    "        self.adAvgPool4 = nn.AdaptiveAvgPool1d(56)\n",
    "        \n",
    "        self.residual_block5 = ResidualBlock(128, 256)\n",
    "        self.adAvgPool5 = nn.AdaptiveAvgPool1d(28)\n",
    "        \n",
    "        self.residual_block6 = ResidualBlock(256, 512)\n",
    "        self.adAvgPool6 = nn.AdaptiveAvgPool1d(14)\n",
    "        \n",
    "        # Two additional residual blocks\n",
    "        self.residual_block7 = ResidualBlock(512, 1024)\n",
    "        self.adAvgPool7 = nn.AdaptiveAvgPool1d(7)\n",
    "        \n",
    "        self.residual_block8 = ResidualBlock(1024, 2048)\n",
    "        self.adAvgPool8 = nn.AdaptiveAvgPool1d(3)\n",
    "        \n",
    "        # Activation and fully connected layers\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        # Calculate the input size for linear layers\n",
    "        # Note: You might need to adjust this based on your specific input dimensions\n",
    "        self.linear1 = nn.Linear(6144, 6144)\n",
    "        self.linear2 = nn.Linear(6144, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Move channel dimension\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "        \n",
    "        # First residual block\n",
    "        x = self.residual_block1(x)\n",
    "        x = self.adAvgPool1(x)\n",
    "        \n",
    "        # Second residual block\n",
    "        x = self.residual_block2(x)\n",
    "        x = self.adAvgPool2(x)\n",
    "        \n",
    "        # Third residual block\n",
    "        x = self.residual_block3(x)\n",
    "        x = self.adAvgPool3(x)\n",
    "        \n",
    "        # Fourth residual block\n",
    "        x = self.residual_block4(x)\n",
    "        x = self.adAvgPool4(x)\n",
    "        \n",
    "        # Fifth residual block\n",
    "        x = self.residual_block5(x)\n",
    "        x = self.adAvgPool5(x)\n",
    "        \n",
    "        # Sixth residual block\n",
    "        x = self.residual_block6(x)\n",
    "        x = self.adAvgPool6(x)\n",
    "        \n",
    "        # Seventh residual block\n",
    "        x = self.residual_block7(x)\n",
    "        x = self.adAvgPool7(x)\n",
    "        \n",
    "        # Eighth residual block\n",
    "        x = self.residual_block8(x)\n",
    "        x = self.adAvgPool8(x)\n",
    "        \n",
    "        # Flatten and fully connected layers\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [\n",
    "    \"class\", \n",
    "    \"order\", \n",
    "    \"family\", \n",
    "    \"genus\",\n",
    "    \"species\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [\n",
    "    # 64,\n",
    "    # 128,\n",
    "    # 256,\n",
    "    # 512,\n",
    "    # 2048,\n",
    "    # 10000,\n",
    "    \"dynamic\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [\n",
    "    # 1,\n",
    "    # 2,\n",
    "    # 5,\n",
    "    # 20,\n",
    "    # 50,\n",
    "    # 100,\n",
    "    # 150,\n",
    "    # 200,\n",
    "    # 300,\n",
    "    # 500,\n",
    "    # 600,\n",
    "    700,\n",
    "    # 1000,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [\n",
    "\n",
    "    # SimplestCNNClassifier_6layers_Residual,\n",
    "    # SimplestCNNClassifier_6layers_Residual2,\n",
    "    SimplestCNNClassifier_8layers_Residual,\n",
    "    # SimplestCNNClassifier_8layers_Residual3k,\n",
    "\n",
    "    # SimplestCNNClassifier_GELU_4layers_Residual_Pooling,\n",
    "    # SimplestCNNClassifier_4layers_Residual,\n",
    "    # SimplestCNNClassifier_4layers_Residual_Pooling,\n",
    "    # SimplestCNNClassifier_2layers_ResidualGELU,\n",
    "    # SimplestCNNClassifier_GELU2layers_Residual,\n",
    "\n",
    "    # # SimplestCNNClassifier_2layers,\n",
    "    # SimplestCNNClassifier_2layers_Residual,\n",
    "    # # # SimplestCNNClassifier_2layers_concat,\n",
    "    # SimplestCNNClassifier_3layers_Residual,\n",
    "\n",
    "    # # # SimplestCNNClassifier0_1layer,\n",
    "    # # SimplestCNNClassifier0_1layerPooling,\n",
    "    # # # SimplestCNNClassifier0_1layerGELU,\n",
    "    # # # SimplestCNNClassifier0_1layer64c,\n",
    "    # # # SimplestCNNClassifier0_1layer64cPooling,\n",
    "    # # SimplestCNNClassifier5_1layer,\n",
    "    # # # # SimplestCNNClassifier5_1layer64c,\n",
    "    # # # # SimplestCNNClassifier5_1layerPooling,\n",
    "    # # # # SimplestCNNClassifier5_1layerPooling64c,\n",
    "\n",
    "    # # # SimplestCNNClassifier0_1layer16,\n",
    "    # # # SimplestCNNClassifier0_1layerk4,\n",
    "    # # SimplestCNNClassifier0_1layerk2,\n",
    "\n",
    "    # # SimplestCNNClassifier0,\n",
    "    # # # SimplestCNNClassifier1,\n",
    "    # # # SimplestCNNClassifier2,\n",
    "    # # # SimplestCNNClassifier3,\n",
    "    # # SimplestCNNClassifier5,\n",
    "    # # # SimpleCNNClassifier1,\n",
    "\n",
    "\n",
    "    # # # SimplestCNNClassifier,\n",
    "    # # # SimpleCNNClassifier,\n",
    "    # # # SimpleCNNWithDropoutClassifier,\n",
    "    # # # BaseCNNClassifier,\n",
    "    # # # UnetBasedCNNClassifier,\n",
    "    # # # UnetBasedCNNWithDropoutClassifier,\n",
    "    # # # UnetBasedCNNWithDilationClassifier,\n",
    "    # # # UnetBasedCNNWithDropoutAndDilationClassifier,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_functions = {\n",
    "    \"CrossEntropyLoss\":{\n",
    "        \"function\":nn.CrossEntropyLoss,\n",
    "        \"params\":{},\n",
    "        \"function_params\":{}\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [\n",
    "    # 5e-2,\n",
    "    # 1e-2,\n",
    "    5e-3,\n",
    "    # 1e-3,\n",
    "    # 5e-4,\n",
    "    # 1e-4,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [\n",
    "    {\n",
    "        \"optim\":torch.optim.AdamW,\n",
    "        \"params\":{\n",
    "            \"weight_decay\":1.0,\n",
    "            \"amsgrad\":True\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparams = {\n",
    "    \"batch_size\": batch_sizes,\n",
    "    \"epochs\": epochs,\n",
    "    \"model\": models_list,\n",
    "    \"loss_function\": loss_functions,\n",
    "    \"learning_rate\": learning_rates,\n",
    "    \"optimizer\": optimizers    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': ['dynamic'],\n",
       " 'epochs': [700],\n",
       " 'model': [__main__.SimplestCNNClassifier_8layers_Residual],\n",
       " 'loss_function': {'CrossEntropyLoss': {'function': torch.nn.modules.loss.CrossEntropyLoss,\n",
       "   'params': {},\n",
       "   'function_params': {}}},\n",
       " 'learning_rate': [0.005],\n",
       " 'optimizer': [{'optim': torch.optim.adamw.AdamW,\n",
       "   'params': {'weight_decay': 1.0, 'amsgrad': True}}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>level</th>\n",
       "      <th>splitter</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model</th>\n",
       "      <th>...</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>mat_mul</th>\n",
       "      <th>obs</th>\n",
       "      <th>reserved_memory</th>\n",
       "      <th>error</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>train_acc_best_epoch</th>\n",
       "      <th>train_loss_best_epoch</th>\n",
       "      <th>test_acc_best_epoch</th>\n",
       "      <th>test_loss_best_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.734323e+09</td>\n",
       "      <td>1.734328e+09</td>\n",
       "      <td>class</td>\n",
       "      <td>prop_0-1/min_5/RandomSplit_0</td>\n",
       "      <td>False</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>700</td>\n",
       "      <td>SimplestCNNClassifier_8layers_Residual</td>\n",
       "      <td>...</td>\n",
       "      <td>AdamW (params: {'weight_decay': 1.0, 'amsgrad'...</td>\n",
       "      <td>False</td>\n",
       "      <td>9:1 _ min:5</td>\n",
       "      <td>18446.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.989240</td>\n",
       "      <td>0.057505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.734329e+09</td>\n",
       "      <td>1.734334e+09</td>\n",
       "      <td>class</td>\n",
       "      <td>prop_0-1/min_5/RandomSplit_14</td>\n",
       "      <td>False</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>700</td>\n",
       "      <td>SimplestCNNClassifier_8layers_Residual</td>\n",
       "      <td>...</td>\n",
       "      <td>AdamW (params: {'weight_decay': 1.0, 'amsgrad'...</td>\n",
       "      <td>False</td>\n",
       "      <td>9:1 _ min:5</td>\n",
       "      <td>18494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.062389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id    start_time      end_time  level  \\\n",
       "0           0   0  1.734323e+09  1.734328e+09  class   \n",
       "1           1   1  1.734329e+09  1.734334e+09  class   \n",
       "\n",
       "                        splitter  augmentation batch_size  epochs  \\\n",
       "0   prop_0-1/min_5/RandomSplit_0         False    dynamic     700   \n",
       "1  prop_0-1/min_5/RandomSplit_14         False    dynamic     700   \n",
       "\n",
       "                                    model  ...  \\\n",
       "0  SimplestCNNClassifier_8layers_Residual  ...   \n",
       "1  SimplestCNNClassifier_8layers_Residual  ...   \n",
       "\n",
       "                                           optimizer  mat_mul          obs  \\\n",
       "0  AdamW (params: {'weight_decay': 1.0, 'amsgrad'...    False  9:1 _ min:5   \n",
       "1  AdamW (params: {'weight_decay': 1.0, 'amsgrad'...    False  9:1 _ min:5   \n",
       "\n",
       "   reserved_memory error  best_epoch  train_acc_best_epoch  \\\n",
       "0          18446.0   NaN         301                   1.0   \n",
       "1          18494.0   NaN         309                   1.0   \n",
       "\n",
       "   train_loss_best_epoch  test_acc_best_epoch  test_loss_best_epoch  \n",
       "0               0.002273             0.989240              0.057505  \n",
       "1               0.002153             0.989726              0.062389  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_id = \"1734322688\"\n",
    "data = pd.read_csv(\"./results/summarized/\"+experiment_id+\"_models_train_test_400.csv\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Global references\n",
    "_model_ = None\n",
    "_lossfunction_ = None\n",
    "_optimizer_ = None\n",
    "\n",
    "# Function to clean cache\n",
    "def clear():\n",
    "    global _model_, _lossfunction_, _optimizer_\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    torch.compiler.reset()\n",
    "    torch._dynamo.reset()\n",
    "\n",
    "    if _model_:\n",
    "        del _model_\n",
    "        _model_ = None\n",
    "    if _lossfunction_:\n",
    "        del _lossfunction_\n",
    "        _lossfunction_ = None\n",
    "    if _optimizer_:\n",
    "        del _optimizer_\n",
    "        _optimizer_ = None\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/stark/Models/Gustavo/class/1734322688_0_SimplestCNNClassifier_8layers_Residual.pth\n",
      "Test Acc: 0.9892403527222716\n",
      "/media/stark/Models/Gustavo/class/1734322688_1_SimplestCNNClassifier_8layers_Residual.pth\n",
      "Test Acc: 0.9897257503438233\n",
      "/media/stark/Models/Gustavo/class/1734322688_2_SimplestCNNClassifier_8layers_Residual.pth\n",
      "Test Acc: 0.9904538467761508\n",
      "/media/stark/Models/Gustavo/class/1734322688_3_SimplestCNNClassifier_8layers_Residual.pth\n",
      "Test Acc: 0.9920718388479897\n",
      "/media/stark/Models/Gustavo/class/1734322688_4_SimplestCNNClassifier_8layers_Residual.pth\n",
      "Test Acc: 0.9915055416228461\n",
      "/media/stark/Models/Gustavo/class/1734322688_5_SimplestCNNClassifier_8layers_Residual.pth\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 27\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print(train_data)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# print(train_data.shape)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# print(test_data.shape)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 27\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mSequenceDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlevel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43maugmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m train_data\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m     35\u001b[0m test_data\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mget_test()\n",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m, in \u001b[0;36mSequenceDataset.__init__\u001b[0;34m(self, train, test, level, augmentation)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoded_labels \u001b[38;5;241m=\u001b[39m SequenceDataset\u001b[38;5;241m.\u001b[39m__encoded_labels__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequences \u001b[38;5;241m=\u001b[39m SequenceDataset\u001b[38;5;241m.\u001b[39m__sequences__(train)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest \u001b[38;5;241m=\u001b[39m SequenceDatasetTest(\n\u001b[1;32m     16\u001b[0m     labels \u001b[38;5;241m=\u001b[39m test[level],\n\u001b[1;32m     17\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses,\n\u001b[1;32m     18\u001b[0m     encoded_labels \u001b[38;5;241m=\u001b[39m SequenceDataset\u001b[38;5;241m.\u001b[39m__encoded_labels__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses, test[level]),\n\u001b[0;32m---> 19\u001b[0m     sequences \u001b[38;5;241m=\u001b[39m \u001b[43mSequenceDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sequences__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m, in \u001b[0;36mSequenceDataset.__sequences__\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m     26\u001b[0m sequences \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m ds\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 28\u001b[0m     sequences\u001b[38;5;241m.\u001b[39mappend(\u001b[43mencode_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtruncated_sequence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)        \n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(sequences, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 28\u001b[0m, in \u001b[0;36mencode_sequence\u001b[0;34m(sequence)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m base \u001b[38;5;129;01min\u001b[39;00m sequence:\n\u001b[1;32m     26\u001b[0m     encoded_seq\u001b[38;5;241m.\u001b[39mappend(base_map[base])\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_seq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_device.py:79\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "times = []\n",
    "i = 0\n",
    "\n",
    "# levels = [\"class\"]\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    # if row[\"level\"] in levels:\n",
    "    #     continue\n",
    "\n",
    "    clear()\n",
    "    \n",
    "    path = \"/media/stark/Models/Gustavo/\"+row[\"level\"]+\"/\"+experiment_id+\"_\"+str(row[\"id\"])+\"_\"+str(row[\"model\"])+\".pth\"\n",
    "    print(path)\n",
    "\n",
    "    ## Load Dataset\n",
    "    train_data = pd.read_csv(\"../new_data/\"+row[\"splitter\"]+\"/\"+row[\"level\"]+\"/train_dataset.csv\")#[0:1]\n",
    "    train_data = train_data.groupby(row[\"level\"]).first().reset_index()\n",
    "    test_data = pd.read_csv(\"../new_data/\"+row[\"splitter\"]+\"/\"+row[\"level\"]+\"/test_dataset.csv\")#[0:1000]\n",
    "\n",
    "    # print(train_data)\n",
    "\n",
    "    # print(train_data.shape)\n",
    "    # print(test_data.shape)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    dataset = SequenceDataset(\n",
    "        train=train_data, \n",
    "        test=test_data, \n",
    "        level=row[\"level\"], \n",
    "        augmentation=False)\n",
    "\n",
    "\n",
    "    train_data=dataset,\n",
    "    test_data=dataset.get_test()\n",
    "\n",
    "    ## Load Model\n",
    "    _model_ = torch.compile(SimplestCNNClassifier_8layers_Residual(dataset.encoded_labels.shape[1]))\n",
    "    _model_.load_state_dict(torch.load(path, weights_only=True))\n",
    "    _model_.eval()\n",
    "\n",
    "    ## Test Model    \n",
    "    test_loader = DataLoader(test_data, batch_size=15000, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "\n",
    "    pred_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            pred = _model_(X)\n",
    "            test_acc += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "    test_acc /= len(test_loader.dataset)\n",
    "\n",
    "    end_time = time.time()\n",
    "    \n",
    "    times.append({\n",
    "        \"experiment_id\":experiment_id,\n",
    "        \"id\":str(row[\"id\"]),\n",
    "        \"level\":row[\"level\"],\n",
    "        \"model\":str(row[\"model\"]),\n",
    "        \"splitter\":row[\"splitter\"],\n",
    "        \"batch_size\":15000,\n",
    "        \"reserved_memory\": torch.cuda.memory_reserved() / 1024 / 1024,\n",
    "        \"acc\": str(test_acc),\n",
    "        \"start_time\":start_time,\n",
    "        \"pred_time\":pred_time,\n",
    "        \"end_time\":end_time,\n",
    "    })\n",
    "\n",
    "    print(\"Test Acc: \"+str(test_acc))\n",
    "\n",
    "    i = i + 1\n",
    "    pd.DataFrame(times).to_csv(\"./results/times/\"+experiment_id+\"_\"+str(i)+\"_\"+row[\"model\"]+\"_times.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
