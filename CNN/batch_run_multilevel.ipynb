{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "dtype = torch.float\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "torch.get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>train_acc_best_epoch</th>\n",
       "      <th>test_acc_best_epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>122</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDropoutClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>108</td>\n",
       "      <td>0.999370</td>\n",
       "      <td>0.888817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDilationClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>122</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.878209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>135</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.870354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>family</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>149</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.901147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>family</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDilationClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>139</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.835733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>family</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDropoutClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>130</td>\n",
       "      <td>0.997735</td>\n",
       "      <td>0.818404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>family</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>145</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.809373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>genus</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>134</td>\n",
       "      <td>0.998401</td>\n",
       "      <td>0.746702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>genus</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDilationClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>88</td>\n",
       "      <td>0.997201</td>\n",
       "      <td>0.668985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>genus</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDropoutClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>142</td>\n",
       "      <td>0.982780</td>\n",
       "      <td>0.651715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>genus</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>61</td>\n",
       "      <td>0.989444</td>\n",
       "      <td>0.642360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>order</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>148</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.913493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>order</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDilationClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>13</td>\n",
       "      <td>0.998166</td>\n",
       "      <td>0.850254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>order</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDropoutClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>103</td>\n",
       "      <td>0.998243</td>\n",
       "      <td>0.849657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>order</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>129</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.828179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>species</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>58</td>\n",
       "      <td>0.989619</td>\n",
       "      <td>0.745501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>species</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>145</td>\n",
       "      <td>0.999238</td>\n",
       "      <td>0.662382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>species</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDilationClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>92</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.657241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>species</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDropoutClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>96</td>\n",
       "      <td>0.989238</td>\n",
       "      <td>0.641817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      level batch_size  epochs                               model  \\\n",
       "id                                                                   \n",
       "16    class    dynamic     150               SimplestCNNClassifier   \n",
       "19    class    dynamic     150   UnetBasedCNNWithDropoutClassifier   \n",
       "18    class    dynamic     150  UnetBasedCNNWithDilationClassifier   \n",
       "17    class    dynamic     150              UnetBasedCNNClassifier   \n",
       "12   family    dynamic     150               SimplestCNNClassifier   \n",
       "14   family    dynamic     150  UnetBasedCNNWithDilationClassifier   \n",
       "15   family    dynamic     150   UnetBasedCNNWithDropoutClassifier   \n",
       "13   family    dynamic     150              UnetBasedCNNClassifier   \n",
       "0     genus    dynamic     150               SimplestCNNClassifier   \n",
       "2     genus    dynamic     150  UnetBasedCNNWithDilationClassifier   \n",
       "3     genus    dynamic     150   UnetBasedCNNWithDropoutClassifier   \n",
       "1     genus    dynamic     150              UnetBasedCNNClassifier   \n",
       "8     order    dynamic     150               SimplestCNNClassifier   \n",
       "10    order    dynamic     150  UnetBasedCNNWithDilationClassifier   \n",
       "11    order    dynamic     150   UnetBasedCNNWithDropoutClassifier   \n",
       "9     order    dynamic     150              UnetBasedCNNClassifier   \n",
       "4   species    dynamic     150               SimplestCNNClassifier   \n",
       "5   species    dynamic     150              UnetBasedCNNClassifier   \n",
       "6   species    dynamic     150  UnetBasedCNNWithDilationClassifier   \n",
       "7   species    dynamic     150   UnetBasedCNNWithDropoutClassifier   \n",
       "\n",
       "    learning_rate  best_epoch  train_acc_best_epoch  test_acc_best_epoch  \n",
       "id                                                                        \n",
       "16         0.0005         122              0.999928             0.934165  \n",
       "19         0.0005         108              0.999370             0.888817  \n",
       "18         0.0005         122              0.999955             0.878209  \n",
       "17         0.0005         135              0.999937             0.870354  \n",
       "12         0.0005         149              0.999892             0.901147  \n",
       "14         0.0005         139              0.999959             0.835733  \n",
       "15         0.0005         130              0.997735             0.818404  \n",
       "13         0.0005         145              0.999973             0.809373  \n",
       "0          0.0005         134              0.998401             0.746702  \n",
       "2          0.0005          88              0.997201             0.668985  \n",
       "3          0.0005         142              0.982780             0.651715  \n",
       "1          0.0005          61              0.989444             0.642360  \n",
       "8          0.0005         148              0.999878             0.913493  \n",
       "10         0.0005          13              0.998166             0.850254  \n",
       "11         0.0005         103              0.998243             0.849657  \n",
       "9          0.0005         129              0.999934             0.828179  \n",
       "4          0.0005          58              0.989619             0.745501  \n",
       "5          0.0005         145              0.999238             0.662382  \n",
       "6          0.0005          92              0.998667             0.657241  \n",
       "7          0.0005          96              0.989238             0.641817  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = pd.read_csv(\"./results/summarized/1731930763_models_train_test_20.csv\", \n",
    "                index_col=\"id\", \n",
    "                usecols=['id','level', 'batch_size', 'epochs','model', 'learning_rate', 'error', 'best_epoch', 'train_acc_best_epoch','test_acc_best_epoch']\n",
    "                )\n",
    "r = r.loc[r[\"error\"].isna()].drop(columns=[\"error\"]).sort_values(by=[\"level\", \"test_acc_best_epoch\"], ascending=[True, False])\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>train_acc_best_epoch</th>\n",
       "      <th>test_acc_best_epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>400</td>\n",
       "      <td>SimpleCNNClassifier1</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>153</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.932950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>family</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>400</td>\n",
       "      <td>SimpleCNNClassifier1</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>69</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.878936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>genus</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>400</td>\n",
       "      <td>SimpleCNNClassifier1</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>77</td>\n",
       "      <td>0.993922</td>\n",
       "      <td>0.726793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>order</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>400</td>\n",
       "      <td>SimpleCNNClassifier1</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>272</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>0.900865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>species</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>400</td>\n",
       "      <td>SimpleCNNClassifier1</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>77</td>\n",
       "      <td>0.991714</td>\n",
       "      <td>0.710368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      level batch_size  epochs                 model  learning_rate  \\\n",
       "id                                                                    \n",
       "0     class    dynamic     400  SimpleCNNClassifier1         0.0005   \n",
       "2    family    dynamic     400  SimpleCNNClassifier1         0.0005   \n",
       "3     genus    dynamic     400  SimpleCNNClassifier1         0.0005   \n",
       "4     order    dynamic     400  SimpleCNNClassifier1         0.0005   \n",
       "1   species    dynamic     400  SimpleCNNClassifier1         0.0005   \n",
       "\n",
       "    best_epoch  train_acc_best_epoch  test_acc_best_epoch  \n",
       "id                                                         \n",
       "0          153              0.999883             0.932950  \n",
       "2           69              0.999553             0.878936  \n",
       "3           77              0.993922             0.726793  \n",
       "4          272              0.999768             0.900865  \n",
       "1           77              0.991714             0.710368  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv(\"./results/summarized/1732414050_models_train_test_5.csv\", \n",
    "                index_col=\"id\", \n",
    "                usecols=['id','level', 'batch_size', 'epochs','model', 'learning_rate', 'error', 'best_epoch', 'train_acc_best_epoch','test_acc_best_epoch']\n",
    "                )\n",
    "a = a.loc[a[\"error\"].isna()].drop(columns=[\"error\"]).sort_values(by=[\"level\", \"test_acc_best_epoch\"], ascending=[True, False])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>train_acc_best_epoch</th>\n",
       "      <th>test_acc_best_epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>122</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>0.934165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>400</td>\n",
       "      <td>SimpleCNNClassifier1</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>153</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.932950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDropoutClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>108</td>\n",
       "      <td>0.999370</td>\n",
       "      <td>0.888817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDilationClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>122</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.878209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>135</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.870354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>family</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>149</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.901147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>family</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>400</td>\n",
       "      <td>SimpleCNNClassifier1</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>69</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.878936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>family</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDilationClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>139</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.835733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>family</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDropoutClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>130</td>\n",
       "      <td>0.997735</td>\n",
       "      <td>0.818404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>family</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>145</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.809373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>genus</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>134</td>\n",
       "      <td>0.998401</td>\n",
       "      <td>0.746702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>genus</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>400</td>\n",
       "      <td>SimpleCNNClassifier1</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>77</td>\n",
       "      <td>0.993922</td>\n",
       "      <td>0.726793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>genus</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDilationClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>88</td>\n",
       "      <td>0.997201</td>\n",
       "      <td>0.668985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>genus</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDropoutClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>142</td>\n",
       "      <td>0.982780</td>\n",
       "      <td>0.651715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>genus</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>61</td>\n",
       "      <td>0.989444</td>\n",
       "      <td>0.642360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>order</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>148</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.913493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>order</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>400</td>\n",
       "      <td>SimpleCNNClassifier1</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>272</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>0.900865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>order</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDilationClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>13</td>\n",
       "      <td>0.998166</td>\n",
       "      <td>0.850254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>order</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDropoutClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>103</td>\n",
       "      <td>0.998243</td>\n",
       "      <td>0.849657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>order</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>129</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.828179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>species</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>58</td>\n",
       "      <td>0.989619</td>\n",
       "      <td>0.745501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>species</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>400</td>\n",
       "      <td>SimpleCNNClassifier1</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>77</td>\n",
       "      <td>0.991714</td>\n",
       "      <td>0.710368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>species</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>145</td>\n",
       "      <td>0.999238</td>\n",
       "      <td>0.662382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>species</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDilationClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>92</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.657241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>species</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>UnetBasedCNNWithDropoutClassifier</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>96</td>\n",
       "      <td>0.989238</td>\n",
       "      <td>0.641817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      level batch_size  epochs                               model  \\\n",
       "id                                                                   \n",
       "16    class    dynamic     150               SimplestCNNClassifier   \n",
       "0     class    dynamic     400                SimpleCNNClassifier1   \n",
       "19    class    dynamic     150   UnetBasedCNNWithDropoutClassifier   \n",
       "18    class    dynamic     150  UnetBasedCNNWithDilationClassifier   \n",
       "17    class    dynamic     150              UnetBasedCNNClassifier   \n",
       "12   family    dynamic     150               SimplestCNNClassifier   \n",
       "2    family    dynamic     400                SimpleCNNClassifier1   \n",
       "14   family    dynamic     150  UnetBasedCNNWithDilationClassifier   \n",
       "15   family    dynamic     150   UnetBasedCNNWithDropoutClassifier   \n",
       "13   family    dynamic     150              UnetBasedCNNClassifier   \n",
       "0     genus    dynamic     150               SimplestCNNClassifier   \n",
       "3     genus    dynamic     400                SimpleCNNClassifier1   \n",
       "2     genus    dynamic     150  UnetBasedCNNWithDilationClassifier   \n",
       "3     genus    dynamic     150   UnetBasedCNNWithDropoutClassifier   \n",
       "1     genus    dynamic     150              UnetBasedCNNClassifier   \n",
       "8     order    dynamic     150               SimplestCNNClassifier   \n",
       "4     order    dynamic     400                SimpleCNNClassifier1   \n",
       "10    order    dynamic     150  UnetBasedCNNWithDilationClassifier   \n",
       "11    order    dynamic     150   UnetBasedCNNWithDropoutClassifier   \n",
       "9     order    dynamic     150              UnetBasedCNNClassifier   \n",
       "4   species    dynamic     150               SimplestCNNClassifier   \n",
       "1   species    dynamic     400                SimpleCNNClassifier1   \n",
       "5   species    dynamic     150              UnetBasedCNNClassifier   \n",
       "6   species    dynamic     150  UnetBasedCNNWithDilationClassifier   \n",
       "7   species    dynamic     150   UnetBasedCNNWithDropoutClassifier   \n",
       "\n",
       "    learning_rate  best_epoch  train_acc_best_epoch  test_acc_best_epoch  \n",
       "id                                                                        \n",
       "16         0.0005         122              0.999928             0.934165  \n",
       "0          0.0005         153              0.999883             0.932950  \n",
       "19         0.0005         108              0.999370             0.888817  \n",
       "18         0.0005         122              0.999955             0.878209  \n",
       "17         0.0005         135              0.999937             0.870354  \n",
       "12         0.0005         149              0.999892             0.901147  \n",
       "2          0.0005          69              0.999553             0.878936  \n",
       "14         0.0005         139              0.999959             0.835733  \n",
       "15         0.0005         130              0.997735             0.818404  \n",
       "13         0.0005         145              0.999973             0.809373  \n",
       "0          0.0005         134              0.998401             0.746702  \n",
       "3          0.0005          77              0.993922             0.726793  \n",
       "2          0.0005          88              0.997201             0.668985  \n",
       "3          0.0005         142              0.982780             0.651715  \n",
       "1          0.0005          61              0.989444             0.642360  \n",
       "8          0.0005         148              0.999878             0.913493  \n",
       "4          0.0005         272              0.999768             0.900865  \n",
       "10         0.0005          13              0.998166             0.850254  \n",
       "11         0.0005         103              0.998243             0.849657  \n",
       "9          0.0005         129              0.999934             0.828179  \n",
       "4          0.0005          58              0.989619             0.745501  \n",
       "1          0.0005          77              0.991714             0.710368  \n",
       "5          0.0005         145              0.999238             0.662382  \n",
       "6          0.0005          92              0.998667             0.657241  \n",
       "7          0.0005          96              0.989238             0.641817  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([r,a]).sort_values(by=[\"level\", \"test_acc_best_epoch\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['level', 'batch_size', 'epochs', 'model', 'learning_rate', 'best_epoch',\n",
       "       'train_acc_best_epoch', 'test_acc_best_epoch'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_map = {\n",
    "    \"A\":[1.0, 0.0, 0.0, 0.0],\n",
    "    \"T\":[0.0, 1.0, 0.0, 0.0],\n",
    "    \"G\":[0.0, 0.0, 1.0, 0.0],\n",
    "    \"C\":[0.0, 0.0, 0.0, 1.0],\n",
    "\n",
    "    'W':[0.5, 0.5, 0.0, 0.0],\n",
    "    'S':[0.0, 0.0, 0.5, 0.5],\n",
    "    'M':[0.5, 0.0, 0.0, 0.5],\n",
    "    'K':[0.0, 0.5, 0.5, 0.0],\n",
    "    'R':[0.5, 0.0, 0.5, 0.0],\n",
    "    'Y':[0.0, 0.5, 0.0, 0.5],\n",
    "    \n",
    "    'B':[0.0, 0.3, 0.3, 0.3],\n",
    "    'D':[0.3, 0.3, 0.3, 0.0],\n",
    "    'H':[0.3, 0.3, 0.0, 0.3],\n",
    "    'V':[0.3, 0.0, 0.3, 0.3],\n",
    "\n",
    "    'N':[0.25, 0.25, 0.25, 0.25],\n",
    "}\n",
    "\n",
    "def encode_sequence(sequence):\n",
    "    encoded_seq = []\n",
    "\n",
    "    for base in sequence:\n",
    "        encoded_seq.append(base_map[base])\n",
    "    \n",
    "    return torch.tensor(encoded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, train, test, level):\n",
    "\n",
    "        self.classes = pd.concat([train[level], test[level]]).unique().tolist()\n",
    "        self.classes.sort()\n",
    "        self.level = level\n",
    "        self.labels = train[level]\n",
    "        self.encoded_labels = SequenceDataset.__encoded_labels__(self.classes, self.labels)\n",
    "        self.sequences = SequenceDataset.__sequences__(train)\n",
    "\n",
    "        self.test = SequenceDatasetTest(\n",
    "            labels = test[level],\n",
    "            classes = self.classes,\n",
    "            encoded_labels = SequenceDataset.__encoded_labels__(self.classes, test[level]),\n",
    "            sequences = SequenceDataset.__sequences__(test)\n",
    "            )\n",
    "\n",
    "    def __encoded_labels__(classes, labels):\n",
    "        return torch.nn.functional.one_hot(torch.tensor([classes.index(l) for l in labels]), len(classes)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    def __sequences__(ds):\n",
    "        sequences = []\n",
    "        for _, row in ds.iterrows():\n",
    "            sequences.append(encode_sequence(row[\"truncated_sequence\"]))        \n",
    "        return torch.stack(sequences, dim=0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return   self.sequences[idx], self.encoded_labels[idx]\n",
    "    \n",
    "    def __getitems__(self, ids):\n",
    "        idx = torch.tensor(ids, device=torch.device('cuda:0'))\n",
    "        return   list(zip(torch.index_select(self.sequences, 0, idx), torch.index_select(self.encoded_labels, 0, idx)))\n",
    "    \n",
    "    def get_test(self):\n",
    "        return self.test\n",
    "\n",
    "class SequenceDatasetTest(SequenceDataset):    \n",
    "    def __init__(self, labels, classes, encoded_labels, sequences):\n",
    "        self.labels = labels\n",
    "        self.classes = classes\n",
    "        self.encoded_labels = encoded_labels\n",
    "        self.sequences = sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [\"domain\", \"class\", \"order\", \"family\", \"genus\", \"species\"]\n",
    "\n",
    "class MultilevelSequenceDataset(Dataset):\n",
    "    def __init__(self, train, test, level):\n",
    "\n",
    "        self.classes = pd.concat([train[level], test[level]]).unique().tolist()\n",
    "        self.classes.sort()\n",
    "        self.level = level\n",
    "\n",
    "        self.labels = train[level]\n",
    "        self.encoded_labels = MultilevelSequenceDataset.__encoded_labels__(self.classes, self.labels)\n",
    "        self.sequences = MultilevelSequenceDataset.__sequences__(train)        \n",
    "\n",
    "        self.previous_level = levels[levels.index(level)-1]\n",
    "        self.previous_classes = pd.concat([train[self.previous_level], test[self.previous_level]]).unique().tolist()\n",
    "        self.previous_classes.sort()\n",
    "        self.previous_encoded_labels = MultilevelSequenceDataset.__encoded_labels__(self.previous_classes, train[self.previous_level])\n",
    "\n",
    "\n",
    "        self.test = MultilevelSequenceDatasetTest(\n",
    "            labels = test[level],\n",
    "            classes = self.classes,\n",
    "            encoded_labels = MultilevelSequenceDataset.__encoded_labels__(self.classes, test[level]),\n",
    "            sequences = MultilevelSequenceDataset.__sequences__(test),\n",
    "            previous_classes = self.previous_classes,\n",
    "            previous_encoded_labels = MultilevelSequenceDataset.__encoded_labels__(self.previous_classes, test[self.previous_level]) ,\n",
    "            previous_level = self.previous_level\n",
    "            )\n",
    "\n",
    "    def __encoded_labels__(classes, labels):\n",
    "        return torch.nn.functional.one_hot(torch.tensor([classes.index(l) for l in labels]), len(classes)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    def __sequences__(ds):\n",
    "        sequences = []\n",
    "        for _, row in ds.iterrows():\n",
    "            sequences.append(encode_sequence(row[\"truncated_sequence\"]))        \n",
    "        return torch.stack(sequences, dim=0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return   self.sequences[idx], self.previous_encoded_labels[idx], self.encoded_labels[idx]\n",
    "    \n",
    "    def __getitems__(self, ids):\n",
    "        idx = torch.tensor(ids, device=torch.device('cuda:0'))\n",
    "        return   list(zip(torch.index_select(self.sequences, 0, idx), torch.index_select(self.previous_encoded_labels, 0, idx), torch.index_select(self.encoded_labels, 0, idx)))\n",
    "    \n",
    "    def get_test(self):\n",
    "        return self.test\n",
    "\n",
    "class MultilevelSequenceDatasetTest(MultilevelSequenceDataset):    \n",
    "    def __init__(self, labels, classes, encoded_labels, sequences, previous_level, previous_classes, previous_encoded_labels ):\n",
    "        self.labels = labels\n",
    "        self.classes = classes\n",
    "        self.encoded_labels = encoded_labels\n",
    "        self.sequences = sequences\n",
    "\n",
    "        self.previous_level = previous_level \n",
    "        self.previous_classes = previous_classes\n",
    "        self.previous_encoded_labels = previous_encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaders_generator(ds_train, ds_test, bs = 128):\n",
    "    train_loader = DataLoader(ds_train, batch_size=bs, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "    test_loader = DataLoader(ds_test, batch_size=bs, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "\n",
    "        self.padding2 = nn.CircularPad1d((1,2))\n",
    "        self.conv2 = nn.Conv1d(8, 32, kernel_size=4)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.padding3 = nn.CircularPad1d((1,2))\n",
    "        self.conv3 = nn.Conv1d(32, 128, kernel_size=4)\n",
    "        self.adAvgPool3 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(28800, 28800*2)\n",
    "        self.linear2 = nn.Linear(28800*2, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "        x = self.adAvgPool1(x)\n",
    "\n",
    "        \n",
    "        x = self.conv2(self.padding2(x))\n",
    "        x = self.adAvgPool2(x)\n",
    "\n",
    "        \n",
    "        x = self.conv3(self.padding3(x))\n",
    "        x = self.adAvgPool3(x)\n",
    "        \n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleCNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimpleCNNClassifier, self).__init__()\n",
    "\n",
    "        self.padding = nn.CircularPad1d((1,2))\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(4, 4, kernel_size=4, groups=4)\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(4, 4, kernel_size=4)        \n",
    "        self.act2 = nn.ReLU()\n",
    "        \n",
    "        self.act3 = nn.ReLU()        \n",
    "        self.conv3 = nn.Conv1d(4, 8, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "        \n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        # self.adAvgPool = nn.AdaptiveAvgPool1d(900)\n",
    "\n",
    "        self.linear1 = nn.Linear(14400, 28800)\n",
    "        self.linear2 = nn.Linear(28800, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "        a = self.conv1(self.padding(x))\n",
    "        a = self.act1(a)        \n",
    "        \n",
    "        b = self.conv2(self.padding(x))\n",
    "        b = self.act2(b)\n",
    "        \n",
    "        c = self.conv3(x)\n",
    "        c = self.act3(c)\n",
    "        \n",
    "        x = torch.flatten(torch.cat([a,b,c], dim=1), 1)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        \n",
    "        x = self.act4(x)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleCNNWithDropoutClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimpleCNNWithDropoutClassifier, self).__init__()\n",
    "\n",
    "        self.padding = nn.CircularPad1d((1,2))\n",
    "\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.conv1 = nn.Conv1d(4, 4, kernel_size=4, groups=4)\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(4, 4, kernel_size=4)\n",
    "        self.act2 = nn.ReLU()\n",
    "        \n",
    "        self.act3 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(4, 8, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "\n",
    "        # self.adAvgPool = nn.AdaptiveAvgPool1d(900)\n",
    "\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.linear1 = nn.Linear(14400, 28800)\n",
    "\n",
    "        self.dropout3 = nn.Dropout(p=0.2)\n",
    "        self.linear2 = nn.Linear(28800, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "        x = self.dropout1(x)\n",
    "        a = self.conv1(self.padding(x))\n",
    "        a = self.act1(a)\n",
    "        \n",
    "        b = self.conv2(self.padding(x))\n",
    "        b = self.act2(b)\n",
    "        \n",
    "        c = self.conv3(x)\n",
    "        c = self.act3(c)\n",
    "        \n",
    "        x = torch.flatten(torch.cat([a,b,c], dim=1), 1)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        \n",
    "        x = self.act4(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseCNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(BaseCNNClassifier, self).__init__()\n",
    "\n",
    "        self.conv1_1 = nn.Conv1d(1, 4, kernel_size=4)\n",
    "        self.conv1_2 = nn.Conv1d(1, 4, kernel_size=4, dilation=2)\n",
    "        self.avgPool = nn.AvgPool1d(4, stride=2)\n",
    "        \n",
    "        self.padding = nn.CircularPad1d((1,2))\n",
    "        \n",
    "        self.act1 = nn.ReLU()\n",
    "        self.act2 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(14392, 14392)\n",
    "        self.linear2 = nn.Linear(14392, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.unsqueeze(torch.flatten(x, start_dim=1), 1)\n",
    "        x = self.padding(x)\n",
    "        \n",
    "        x_1_1 = self.conv1_1(x)\n",
    "        x_1_2 = self.conv1_2(self.padding(x))      \n",
    "\n",
    "        x = torch.cat([x_1_1, x_1_2], dim=1)\n",
    "        x = self.avgPool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.act1(x)\n",
    "        x = self.linear1(x)\n",
    "        \n",
    "        x = self.act2(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UnetBasedCNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(UnetBasedCNNClassifier, self).__init__()\n",
    "\n",
    "        # First Encode Level\n",
    "        self.padding_e_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.act_e_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_e_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_2 = nn.Conv1d(8, 8, kernel_size=4)\n",
    "        self.act_e_1_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_1_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "\n",
    "        # Second Encode Level        \n",
    "        self.padding_e_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_1 = nn.Conv1d(8, 16, kernel_size=4)\n",
    "        self.act_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_e_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_e_2_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_2_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "        \n",
    "        # Transition Level\n",
    "        self.padding_t_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_1 = nn.Conv1d(16, 32, kernel_size = 4)\n",
    "        self.act_t_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_t_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_2 = nn.Conv1d(32, 32, kernel_size = 4)\n",
    "        self.act_t_1_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # First Decode Level\n",
    "        self.upconv_1_1 = nn.ConvTranspose1d(32, 16, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_1 = nn.Conv1d(32, 16, kernel_size=4)\n",
    "        self.act_d_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_d_1_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # Second Decode Level\n",
    "        self.upconv_2_1 = nn.ConvTranspose1d(16, 8, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_1 = nn.Conv1d(16, 8, kernel_size=4)\n",
    "        self.act_d_2_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_2 = nn.Conv1d(8, 8, kernel_size=4)\n",
    "        self.act_d_2_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # Output Level\n",
    "        self.conv_out_1 = nn.Conv1d(8, nClasses, kernel_size=1)\n",
    "        \n",
    "        self.linear_out_1 = nn.Linear(7200, 14400)\n",
    "        self.act_out_1 = nn.ReLU()\n",
    "        self.linear_out_2 = nn.Linear(14400, nClasses)\n",
    "        self.act_out_2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # print(\"X shape: \"+str(x.shape))             # X shape: torch.Size([3, 900, 4])\n",
    "\n",
    "        x = x.reshape(x.shape[0],4,-1)              # Reshape X shape: torch.Size([3, 4, 900])\n",
    "        # print(\"Reshape X shape: \"+str(x.shape))\n",
    "        # print(\"\\n\")\n",
    "\n",
    "\n",
    "        # print(\"\\n------------E 1-------------\")\n",
    "        x_e_1 = self.padding_e_1_1(x)               # Padding X shape: torch.Size([3, 4, 900])\n",
    "        # print(\"Padding X shape: \"+str(x.shape))\n",
    "        x_e_1 = self.conv_e_1_1(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        # print(\"Conv X shape: \"+str(x_e_1.shape))\n",
    "        x_e_1 = self.act_e_1_1(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        # print(\"ActFunc X shape: \"+str(x_e_1.shape))\n",
    "        \n",
    "        x_e_1 = self.padding_e_1_2(x_e_1)           # Padding X shape: torch.Size([3, 8, 903])\n",
    "        # print(\"Padding X shape: \"+str(x_e_1.shape))\n",
    "        x_e_1 = self.conv_e_1_2(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        # print(\"Conv X shape: \"+str(x_e_1.shape))\n",
    "        x_e_1 = self.act_e_1_2(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        # print(\"ActFunc X shape: \"+str(x_e_1.shape))\n",
    "        \n",
    "        x_e_p_1 = self.avgPool_e_1_1(x_e_1)         # Pool X shape: torch.Size([3, 8, 450])\n",
    "        # print(\"Pool X shape: \"+str(x_e_p_1.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n-----------E 2--------------\")\n",
    "        x_e_2 = self.padding_e_2_1(x_e_p_1)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        # print(\"Padding X shape: \"+str(x_e_2.shape))\n",
    "        x_e_2 = self.conv_e_2_1(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        # print(\"Conv X shape: \"+str(x_e_2.shape))\n",
    "        x_e_2 = self.act_e_2_1(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "        # print(\"ActFunc X shape: \"+str(x_e_2.shape))\n",
    "        \n",
    "        x_e_2 = self.padding_e_2_2(x_e_2)           # Padding X shape: torch.Size([3, 16, 453])\n",
    "        # print(\"Padding X shape: \"+str(x_e_2.shape))\n",
    "        x_e_2 = self.conv_e_2_2(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        # print(\"Conv X shape: \"+str(x_e_2.shape))\n",
    "        x_e_2 = self.act_e_2_2(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "        # print(\"ActFunc X shape: \"+str(x_e_2.shape))\n",
    "\n",
    "        x_e_p_2 = self.avgPool_e_2_1(x_e_2)         # Pool X shape: torch.Size([3, 16, 225])\n",
    "        # print(\"Pool X shape: \"+str(x_e_p_2.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n------------T 1-------------\")\n",
    "        x_t_1 = self.padding_t_1_1(x_e_p_2)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        # print(\"Padding X shape: \"+str(x_t_1.shape))\n",
    "        x_t_1 = self.conv_t_1_1(x_t_1)              # Conv X shape: torch.Size([3, 32, 109])\n",
    "        # print(\"Conv X shape: \"+str(x_t_1.shape))\n",
    "        x_t_1 = self.act_t_1_1(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 109])\n",
    "        # print(\"ActFunc X shape: \"+str(x_t_1.shape))\n",
    "        \n",
    "        x_t_1 = self.padding_t_1_2(x_t_1)           # Padding X shape: torch.Size([3, 8, 453])\n",
    "        # print(\"Padding X shape: \"+str(x_t_1.shape))\n",
    "        x_t_1 = self.conv_t_1_2(x_t_1)              # Conv X shape: torch.Size([3, 32, 106])\n",
    "        # print(\"Conv X shape: \"+str(x_t_1.shape))\n",
    "        x_t_1 = self.act_t_1_2(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 106])\n",
    "        # print(\"ActFunc X shape: \"+str(x_t_1.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n------------D 1------------\")\n",
    "        x_d_1 = self.upconv_1_1(x_t_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "        # print(\"UpConv X shape: \"+str(x_d_1.shape))\n",
    "\n",
    "        x_d_1 = torch.cat([x_d_1, x_e_2], dim=1)    # \n",
    "        # print(\"Cat X shape: \"+str(x_d_1.shape))\n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        # print(\"Padding X shape: \"+str(x_d_1.shape))\n",
    "        x_d_1 = self.conv_d_1_1(x_d_1)              # \n",
    "        # print(\"Conv X shape: \"+str(x_d_1.shape))\n",
    "        x_d_1 = self.act_d_1_1(x_d_1)               # \n",
    "        # print(\"ActFunc X shape: \"+str(x_d_1.shape))\n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        # print(\"Padding X shape: \"+str(x_d_1.shape))\n",
    "        x_d_1 = self.conv_d_1_2(x_d_1)              # \n",
    "        # print(\"Conv X shape: \"+str(x_d_1.shape))\n",
    "        x_d_1 = self.act_d_1_2(x_d_1)               # \n",
    "        # print(\"ActFunc X shape: \"+str(x_d_1.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n------------D 2------------\")\n",
    "        x_d_2 = self.upconv_2_1(x_d_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "        # print(\"UpConv X shape: \"+str(x_d_2.shape))\n",
    "\n",
    "        x_d_2 = torch.cat([x_d_2, x_e_1], dim=1)    # \n",
    "        # print(\"Cat X shape: \"+str(x_d_2.shape))\n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        # print(\"Padding X shape: \"+str(x_d_2.shape))\n",
    "        x_d_2 = self.conv_d_2_1(x_d_2)              # \n",
    "        # print(\"Conv X shape: \"+str(x_d_2.shape))\n",
    "        x_d_2 = self.act_d_2_1(x_d_2)               # \n",
    "        # print(\"ActFunc X shape: \"+str(x_d_2.shape))\n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        # print(\"Padding X shape: \"+str(x_d_2.shape))\n",
    "        x_d_2 = self.conv_d_2_2(x_d_2)              # \n",
    "        # print(\"Conv X shape: \"+str(x_d_2.shape))\n",
    "        x_d_2 = self.act_d_2_2(x_d_2)               # \n",
    "        # print(\"ActFunc X shape: \"+str(x_d_2.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n------------Out------------\")\n",
    "        # x = self.conv_out_1(x_d_2)\n",
    "\n",
    "\n",
    "        x = torch.flatten(x_d_2, 1)\n",
    "        \n",
    "        x = self.act_out_1(x)\n",
    "        x = self.linear_out_1(x)\n",
    "        \n",
    "        x = self.act_out_2(x)\n",
    "        x = self.linear_out_2(x)\n",
    "\n",
    "        # print(\"Output X shape: \"+str(x.shape))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UnetBasedCNNWithDropoutClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(UnetBasedCNNWithDropoutClassifier, self).__init__()\n",
    "\n",
    "        self.input_dropout1 = nn.Dropout(p=0.2)\n",
    "\n",
    "        # First Encode Level\n",
    "        self.padding_e_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.act_e_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_e_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_2 = nn.Conv1d(8, 8, kernel_size=4)\n",
    "        self.act_e_1_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_1_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "\n",
    "        # Second Encode Level        \n",
    "        self.padding_e_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_1 = nn.Conv1d(8, 16, kernel_size=4)\n",
    "        self.act_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_e_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_e_2_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_2_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "        \n",
    "        # Transition Level\n",
    "        self.padding_t_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_1 = nn.Conv1d(16, 32, kernel_size = 4)\n",
    "        self.act_t_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_t_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_2 = nn.Conv1d(32, 32, kernel_size = 4)\n",
    "        self.act_t_1_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # First Decode Level\n",
    "        self.upconv_1_1 = nn.ConvTranspose1d(32, 16, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_1 = nn.Conv1d(32, 16, kernel_size=4)\n",
    "        self.act_d_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_d_1_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # Second Decode Level\n",
    "        self.upconv_2_1 = nn.ConvTranspose1d(16, 8, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_1 = nn.Conv1d(16, 8, kernel_size=4)\n",
    "        self.act_d_2_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_2 = nn.Conv1d(8, 8, kernel_size=4)\n",
    "        self.act_d_2_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # Output Level\n",
    "        self.conv_out_1 = nn.Conv1d(8, nClasses, kernel_size=1)\n",
    "        \n",
    "        \n",
    "        self.output_dropout1 = nn.Dropout(p=0.2)\n",
    "        self.linear_out_1 = nn.Linear(7200, 14400)\n",
    "        self.act_out_1 = nn.ReLU()\n",
    "\n",
    "        \n",
    "        self.output_dropout2 = nn.Dropout(p=0.2)\n",
    "        self.linear_out_2 = nn.Linear(14400, nClasses)\n",
    "        self.act_out_2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # print(\"X shape: \"+str(x.shape))             # X shape: torch.Size([3, 900, 4])\n",
    "\n",
    "        x = x.reshape(x.shape[0],4,-1)              # Reshape X shape: torch.Size([3, 4, 900])\n",
    "        # print(\"Reshape X shape: \"+str(x.shape))\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        x = self.input_dropout1(x)\n",
    "\n",
    "        # print(\"\\n------------E 1-------------\")\n",
    "        x_e_1 = self.padding_e_1_1(x)               # Padding X shape: torch.Size([3, 4, 900])\n",
    "        # print(\"Padding X shape: \"+str(x.shape))\n",
    "        x_e_1 = self.conv_e_1_1(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        # print(\"Conv X shape: \"+str(x_e_1.shape))\n",
    "        x_e_1 = self.act_e_1_1(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        # print(\"ActFunc X shape: \"+str(x_e_1.shape))\n",
    "        \n",
    "        x_e_1 = self.padding_e_1_2(x_e_1)           # Padding X shape: torch.Size([3, 8, 903])\n",
    "        # print(\"Padding X shape: \"+str(x_e_1.shape))\n",
    "        x_e_1 = self.conv_e_1_2(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        # print(\"Conv X shape: \"+str(x_e_1.shape))\n",
    "        x_e_1 = self.act_e_1_2(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        # print(\"ActFunc X shape: \"+str(x_e_1.shape))\n",
    "        \n",
    "        x_e_p_1 = self.avgPool_e_1_1(x_e_1)         # Pool X shape: torch.Size([3, 8, 450])\n",
    "        # print(\"Pool X shape: \"+str(x_e_p_1.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n-----------E 2--------------\")\n",
    "        x_e_2 = self.padding_e_2_1(x_e_p_1)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        # print(\"Padding X shape: \"+str(x_e_2.shape))\n",
    "        x_e_2 = self.conv_e_2_1(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        # print(\"Conv X shape: \"+str(x_e_2.shape))\n",
    "        x_e_2 = self.act_e_2_1(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "        # print(\"ActFunc X shape: \"+str(x_e_2.shape))\n",
    "        \n",
    "        x_e_2 = self.padding_e_2_2(x_e_2)           # Padding X shape: torch.Size([3, 16, 453])\n",
    "        # print(\"Padding X shape: \"+str(x_e_2.shape))\n",
    "        x_e_2 = self.conv_e_2_2(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        # print(\"Conv X shape: \"+str(x_e_2.shape))\n",
    "        x_e_2 = self.act_e_2_2(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "        # print(\"ActFunc X shape: \"+str(x_e_2.shape))\n",
    "\n",
    "        x_e_p_2 = self.avgPool_e_2_1(x_e_2)         # Pool X shape: torch.Size([3, 16, 225])\n",
    "        # print(\"Pool X shape: \"+str(x_e_p_2.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n------------T 1-------------\")\n",
    "        x_t_1 = self.padding_t_1_1(x_e_p_2)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        # print(\"Padding X shape: \"+str(x_t_1.shape))\n",
    "        x_t_1 = self.conv_t_1_1(x_t_1)              # Conv X shape: torch.Size([3, 32, 109])\n",
    "        # print(\"Conv X shape: \"+str(x_t_1.shape))\n",
    "        x_t_1 = self.act_t_1_1(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 109])\n",
    "        # print(\"ActFunc X shape: \"+str(x_t_1.shape))\n",
    "        \n",
    "        x_t_1 = self.padding_t_1_2(x_t_1)           # Padding X shape: torch.Size([3, 8, 453])\n",
    "        # print(\"Padding X shape: \"+str(x_t_1.shape))\n",
    "        x_t_1 = self.conv_t_1_2(x_t_1)              # Conv X shape: torch.Size([3, 32, 106])\n",
    "        # print(\"Conv X shape: \"+str(x_t_1.shape))\n",
    "        x_t_1 = self.act_t_1_2(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 106])\n",
    "        # print(\"ActFunc X shape: \"+str(x_t_1.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n------------D 1------------\")\n",
    "        x_d_1 = self.upconv_1_1(x_t_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "        # print(\"UpConv X shape: \"+str(x_d_1.shape))\n",
    "\n",
    "        x_d_1 = torch.cat([x_d_1, x_e_2], dim=1)    # \n",
    "        # print(\"Cat X shape: \"+str(x_d_1.shape))\n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        # print(\"Padding X shape: \"+str(x_d_1.shape))\n",
    "        x_d_1 = self.conv_d_1_1(x_d_1)              # \n",
    "        # print(\"Conv X shape: \"+str(x_d_1.shape))\n",
    "        x_d_1 = self.act_d_1_1(x_d_1)               # \n",
    "        # print(\"ActFunc X shape: \"+str(x_d_1.shape))\n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        # print(\"Padding X shape: \"+str(x_d_1.shape))\n",
    "        x_d_1 = self.conv_d_1_2(x_d_1)              # \n",
    "        # print(\"Conv X shape: \"+str(x_d_1.shape))\n",
    "        x_d_1 = self.act_d_1_2(x_d_1)               # \n",
    "        # print(\"ActFunc X shape: \"+str(x_d_1.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n------------D 2------------\")\n",
    "        x_d_2 = self.upconv_2_1(x_d_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "        # print(\"UpConv X shape: \"+str(x_d_2.shape))\n",
    "\n",
    "        x_d_2 = torch.cat([x_d_2, x_e_1], dim=1)    # \n",
    "        # print(\"Cat X shape: \"+str(x_d_2.shape))\n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        # print(\"Padding X shape: \"+str(x_d_2.shape))\n",
    "        x_d_2 = self.conv_d_2_1(x_d_2)              # \n",
    "        # print(\"Conv X shape: \"+str(x_d_2.shape))\n",
    "        x_d_2 = self.act_d_2_1(x_d_2)               # \n",
    "        # print(\"ActFunc X shape: \"+str(x_d_2.shape))\n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        # print(\"Padding X shape: \"+str(x_d_2.shape))\n",
    "        x_d_2 = self.conv_d_2_2(x_d_2)              # \n",
    "        # print(\"Conv X shape: \"+str(x_d_2.shape))\n",
    "        x_d_2 = self.act_d_2_2(x_d_2)               # \n",
    "        # print(\"ActFunc X shape: \"+str(x_d_2.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n------------Out------------\")\n",
    "        # x = self.conv_out_1(x_d_2)\n",
    "\n",
    "\n",
    "        x = torch.flatten(x_d_2, 1)\n",
    "        x = self.output_dropout1(x)\n",
    "        \n",
    "        x = self.act_out_1(x)\n",
    "        x = self.linear_out_1(x)\n",
    "        \n",
    "        \n",
    "        x = self.output_dropout2(x)\n",
    "        x = self.act_out_2(x)\n",
    "        x = self.linear_out_2(x)\n",
    "\n",
    "        # print(\"Output X shape: \"+str(x.shape))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UnetBasedCNNWithDilationClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(UnetBasedCNNWithDilationClassifier, self).__init__()\n",
    "\n",
    "        # self.input_dropout1 = nn.Dropout(p=0.2)\n",
    "\n",
    "        # First Encode Level\n",
    "        self.padding_e_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.act_e_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.convd_e_1_1 = nn.Conv1d(4, 8, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "        self.actd_e_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_e_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_e_1_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_1_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "\n",
    "        # Second Encode Level        \n",
    "        self.padding_e_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_1 = nn.Conv1d(16, 32, kernel_size=4)\n",
    "        self.act_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.convd_e_2_1 = nn.Conv1d(16, 32, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "        self.actd_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_e_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_2 = nn.Conv1d(64, 64, kernel_size=4)\n",
    "        self.act_e_2_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_2_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "        \n",
    "        # Transition Level\n",
    "        self.padding_t_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_1 = nn.Conv1d(64, 128, kernel_size = 4)\n",
    "        self.act_t_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_t_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_2 = nn.Conv1d(128, 128, kernel_size = 4)\n",
    "        self.act_t_1_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # First Decode Level\n",
    "        self.upconv_1_1 = nn.ConvTranspose1d(128, 64, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_1 = nn.Conv1d(128, 64, kernel_size=4)\n",
    "        self.act_d_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_2 = nn.Conv1d(64, 64, kernel_size=4)\n",
    "        self.act_d_1_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # Second Decode Level\n",
    "        self.upconv_2_1 = nn.ConvTranspose1d(64, 32, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_1 = nn.Conv1d(48, 24, kernel_size=4)\n",
    "        self.act_d_2_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_2 = nn.Conv1d(24, 24, kernel_size=4)\n",
    "        self.act_d_2_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # Output Level\n",
    "        self.conv_out_1 = nn.Conv1d(24, nClasses, kernel_size=1)\n",
    "        \n",
    "        \n",
    "        # self.output_dropout1 = nn.Dropout(p=0.2)\n",
    "        self.linear_out_1 = nn.Linear(21600, 43200)\n",
    "        self.act_out_1 = nn.ReLU()\n",
    "\n",
    "        \n",
    "        # self.output_dropout2 = nn.Dropout(p=0.2)\n",
    "        self.linear_out_2 = nn.Linear(43200, nClasses)\n",
    "        self.act_out_2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # print(\"X shape: \"+str(x.shape))             # X shape: torch.Size([3, 900, 4])\n",
    "\n",
    "        x = x.reshape(x.shape[0],4,-1)              # Reshape X shape: torch.Size([3, 4, 900])\n",
    "        # print(\"Reshape X shape: \"+str(x.shape))\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        # x = self.input_dropout1(x)\n",
    "\n",
    "        # print(\"\\n------------E 1-------------\")\n",
    "        x_e_1 = self.padding_e_1_1(x)               # Padding X shape: torch.Size([3, 4, 900])\n",
    "        x_e_1 = self.conv_e_1_1(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])        \n",
    "        x_e_1 = self.act_e_1_1(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])        \n",
    "\n",
    "        x_e_1_d = self.convd_e_1_1(x)\n",
    "        x_e_1_d = self.actd_e_1_1(x_e_1_d)\n",
    "        \n",
    "        x_e_1 = torch.cat([x_e_1, x_e_1_d], dim=1)\n",
    "        \n",
    "        x_e_1 = self.padding_e_1_2(x_e_1)           # Padding X shape: torch.Size([3, 8, 903])\n",
    "        x_e_1 = self.conv_e_1_2(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        x_e_1 = self.act_e_1_2(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        \n",
    "        # print(\"X_e_1 shape: \"+str(x_e_1.shape))\n",
    "        x_e_p_1 = self.avgPool_e_1_1(x_e_1)         # Pool X shape: torch.Size([3, 8, 450])\n",
    "        # print(\"Pool X shape: \"+str(x_e_p_1.shape))\n",
    "\n",
    "        # print(\"\\n-----------E 2--------------\")\n",
    "        x_e_2 = self.padding_e_2_1(x_e_p_1)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_e_2 = self.conv_e_2_1(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_1(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "\n",
    "        x_e_2_d = self.convd_e_2_1(x_e_p_1)\n",
    "        x_e_2_d = self.actd_e_2_1(x_e_2_d)        \n",
    "        x_e_2 = torch.cat([x_e_2, x_e_2_d], dim=1)\n",
    "        # print(\"X_e_2 shape: \"+str(x_e_2.shape))\n",
    "        \n",
    "        x_e_2 = self.padding_e_2_2(x_e_2)           # Padding X shape: torch.Size([3, 16, 453])\n",
    "        # print(\"Padding X shape: \"+str(x_e_2.shape))\n",
    "        x_e_2 = self.conv_e_2_2(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        # print(\"Conv X shape: \"+str(x_e_2.shape))\n",
    "        x_e_2 = self.act_e_2_2(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "        # print(\"ActFunc X shape: \"+str(x_e_2.shape))\n",
    "\n",
    "        x_e_p_2 = self.avgPool_e_2_1(x_e_2)         # Pool X shape: torch.Size([3, 16, 225])\n",
    "        # print(\"Pool X shape: \"+str(x_e_p_2.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n------------T 1-------------\")\n",
    "        x_t_1 = self.padding_t_1_1(x_e_p_2)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        # print(\"Padding X shape: \"+str(x_t_1.shape))\n",
    "        x_t_1 = self.conv_t_1_1(x_t_1)              # Conv X shape: torch.Size([3, 32, 109])\n",
    "        # print(\"Conv X shape: \"+str(x_t_1.shape))\n",
    "        x_t_1 = self.act_t_1_1(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 109])\n",
    "        # print(\"ActFunc X shape: \"+str(x_t_1.shape))\n",
    "        \n",
    "        x_t_1 = self.padding_t_1_2(x_t_1)           # Padding X shape: torch.Size([3, 8, 453])\n",
    "        # print(\"Padding X shape: \"+str(x_t_1.shape))\n",
    "        x_t_1 = self.conv_t_1_2(x_t_1)              # Conv X shape: torch.Size([3, 32, 106])\n",
    "        # print(\"Conv X shape: \"+str(x_t_1.shape))\n",
    "        x_t_1 = self.act_t_1_2(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 106])\n",
    "        # print(\"ActFunc X shape: \"+str(x_t_1.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n------------D 1------------\")\n",
    "        x_d_1 = self.upconv_1_1(x_t_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "        # print(\"UpConv X shape: \"+str(x_d_1.shape))\n",
    "\n",
    "        x_d_1 = torch.cat([x_d_1, x_e_2], dim=1)    # \n",
    "        # print(\"Cat X shape: \"+str(x_d_1.shape))\n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        # print(\"Padding X shape: \"+str(x_d_1.shape))\n",
    "        x_d_1 = self.conv_d_1_1(x_d_1)              # \n",
    "        # print(\"Conv X shape: \"+str(x_d_1.shape))\n",
    "        x_d_1 = self.act_d_1_1(x_d_1)               # \n",
    "        # print(\"ActFunc X shape: \"+str(x_d_1.shape))\n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        # print(\"Padding X shape: \"+str(x_d_1.shape))\n",
    "        x_d_1 = self.conv_d_1_2(x_d_1)              # \n",
    "        # print(\"Conv X shape: \"+str(x_d_1.shape))\n",
    "        x_d_1 = self.act_d_1_2(x_d_1)               # \n",
    "        # print(\"ActFunc X shape: \"+str(x_d_1.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n------------D 2------------\")\n",
    "        x_d_2 = self.upconv_2_1(x_d_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "        # print(\"UpConv X shape: \"+str(x_d_2.shape))\n",
    "\n",
    "        x_d_2 = torch.cat([x_d_2, x_e_1], dim=1)    # \n",
    "        # print(\"Cat X shape: \"+str(x_d_2.shape))\n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        # print(\"Padding X shape: \"+str(x_d_2.shape))\n",
    "        x_d_2 = self.conv_d_2_1(x_d_2)              # \n",
    "        # print(\"Conv X shape: \"+str(x_d_2.shape))\n",
    "        x_d_2 = self.act_d_2_1(x_d_2)               # \n",
    "        # print(\"ActFunc X shape: \"+str(x_d_2.shape))\n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        # print(\"Padding X shape: \"+str(x_d_2.shape))\n",
    "        x_d_2 = self.conv_d_2_2(x_d_2)              # \n",
    "        # print(\"Conv X shape: \"+str(x_d_2.shape))\n",
    "        x_d_2 = self.act_d_2_2(x_d_2)               # \n",
    "        # print(\"ActFunc X shape: \"+str(x_d_2.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n------------Out------------\")\n",
    "        # # x = self.conv_out_1(x_d_2)\n",
    "\n",
    "\n",
    "        x = torch.flatten(x_d_2, 1)\n",
    "        # print(\"Flatten X shape: \"+str(x.shape))\n",
    "\n",
    "        # x = self.output_dropout1(x)\n",
    "        # print(\"Dropped X shape: \"+str(x.shape))\n",
    "        x = self.act_out_1(x)\n",
    "        # print(\"Act X shape: \"+str(x.shape))\n",
    "        x = self.linear_out_1(x)\n",
    "        # print(\"Linear X shape: \"+str(x.shape))\n",
    "        \n",
    "        # x = self.output_dropout2(x)\n",
    "        x = self.act_out_2(x)\n",
    "        x = self.linear_out_2(x)\n",
    "\n",
    "        # print(\"Output X shape: \"+str(x.shape))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UnetBasedCNNWithDropoutAndDilationClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(UnetBasedCNNWithDropoutAndDilationClassifier, self).__init__()\n",
    "\n",
    "        self.input_dropout1 = nn.Dropout(p=0.2)\n",
    "\n",
    "        # First Encode Level\n",
    "        self.padding_e_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.act_e_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.convd_e_1_1 = nn.Conv1d(4, 8, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "        self.actd_e_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_e_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_e_1_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_1_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "\n",
    "        # Second Encode Level        \n",
    "        self.padding_e_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_1 = nn.Conv1d(16, 32, kernel_size=4)\n",
    "        self.act_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.convd_e_2_1 = nn.Conv1d(16, 32, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "        self.actd_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_e_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_2 = nn.Conv1d(64, 64, kernel_size=4)\n",
    "        self.act_e_2_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_2_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "        \n",
    "        # Transition Level\n",
    "        self.padding_t_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_1 = nn.Conv1d(64, 128, kernel_size = 4)\n",
    "        self.act_t_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_t_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_2 = nn.Conv1d(128, 128, kernel_size = 4)\n",
    "        self.act_t_1_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # First Decode Level\n",
    "        self.upconv_1_1 = nn.ConvTranspose1d(128, 64, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_1 = nn.Conv1d(128, 64, kernel_size=4)\n",
    "        self.act_d_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_2 = nn.Conv1d(64, 64, kernel_size=4)\n",
    "        self.act_d_1_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # Second Decode Level\n",
    "        self.upconv_2_1 = nn.ConvTranspose1d(64, 32, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_1 = nn.Conv1d(48, 24, kernel_size=4)\n",
    "        self.act_d_2_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_2 = nn.Conv1d(24, 24, kernel_size=4)\n",
    "        self.act_d_2_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # Output Level\n",
    "        self.conv_out_1 = nn.Conv1d(24, nClasses, kernel_size=1)\n",
    "        \n",
    "        \n",
    "        self.output_dropout1 = nn.Dropout(p=0.2)\n",
    "        self.linear_out_1 = nn.Linear(21600, 43200)\n",
    "        self.act_out_1 = nn.ReLU()\n",
    "\n",
    "        \n",
    "        self.output_dropout2 = nn.Dropout(p=0.2)\n",
    "        self.linear_out_2 = nn.Linear(43200, nClasses)\n",
    "        self.act_out_2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # print(\"X shape: \"+str(x.shape))             # X shape: torch.Size([3, 900, 4])\n",
    "\n",
    "        x = x.reshape(x.shape[0],4,-1)              # Reshape X shape: torch.Size([3, 4, 900])\n",
    "        # print(\"Reshape X shape: \"+str(x.shape))\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        x = self.input_dropout1(x)\n",
    "\n",
    "        # print(\"\\n------------E 1-------------\")\n",
    "        x_e_1 = self.padding_e_1_1(x)               # Padding X shape: torch.Size([3, 4, 900])\n",
    "        x_e_1 = self.conv_e_1_1(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])        \n",
    "        x_e_1 = self.act_e_1_1(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])        \n",
    "\n",
    "        x_e_1_d = self.convd_e_1_1(x)\n",
    "        x_e_1_d = self.actd_e_1_1(x_e_1_d)\n",
    "        \n",
    "        x_e_1 = torch.cat([x_e_1, x_e_1_d], dim=1)\n",
    "        \n",
    "        x_e_1 = self.padding_e_1_2(x_e_1)           # Padding X shape: torch.Size([3, 8, 903])\n",
    "        x_e_1 = self.conv_e_1_2(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        x_e_1 = self.act_e_1_2(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        \n",
    "        # print(\"X_e_1 shape: \"+str(x_e_1.shape))\n",
    "        x_e_p_1 = self.avgPool_e_1_1(x_e_1)         # Pool X shape: torch.Size([3, 8, 450])\n",
    "        # print(\"Pool X shape: \"+str(x_e_p_1.shape))\n",
    "\n",
    "        # print(\"\\n-----------E 2--------------\")\n",
    "        x_e_2 = self.padding_e_2_1(x_e_p_1)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_e_2 = self.conv_e_2_1(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_1(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "\n",
    "        x_e_2_d = self.convd_e_2_1(x_e_p_1)\n",
    "        x_e_2_d = self.actd_e_2_1(x_e_2_d)        \n",
    "        x_e_2 = torch.cat([x_e_2, x_e_2_d], dim=1)\n",
    "        # print(\"X_e_2 shape: \"+str(x_e_2.shape))\n",
    "        \n",
    "        x_e_2 = self.padding_e_2_2(x_e_2)           # Padding X shape: torch.Size([3, 16, 453])\n",
    "        # print(\"Padding X shape: \"+str(x_e_2.shape))\n",
    "        x_e_2 = self.conv_e_2_2(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        # print(\"Conv X shape: \"+str(x_e_2.shape))\n",
    "        x_e_2 = self.act_e_2_2(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "        # print(\"ActFunc X shape: \"+str(x_e_2.shape))\n",
    "\n",
    "        x_e_p_2 = self.avgPool_e_2_1(x_e_2)         # Pool X shape: torch.Size([3, 16, 225])\n",
    "        # print(\"Pool X shape: \"+str(x_e_p_2.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n------------T 1-------------\")\n",
    "        x_t_1 = self.padding_t_1_1(x_e_p_2)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        # print(\"Padding X shape: \"+str(x_t_1.shape))\n",
    "        x_t_1 = self.conv_t_1_1(x_t_1)              # Conv X shape: torch.Size([3, 32, 109])\n",
    "        # print(\"Conv X shape: \"+str(x_t_1.shape))\n",
    "        x_t_1 = self.act_t_1_1(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 109])\n",
    "        # print(\"ActFunc X shape: \"+str(x_t_1.shape))\n",
    "        \n",
    "        x_t_1 = self.padding_t_1_2(x_t_1)           # Padding X shape: torch.Size([3, 8, 453])\n",
    "        # print(\"Padding X shape: \"+str(x_t_1.shape))\n",
    "        x_t_1 = self.conv_t_1_2(x_t_1)              # Conv X shape: torch.Size([3, 32, 106])\n",
    "        # print(\"Conv X shape: \"+str(x_t_1.shape))\n",
    "        x_t_1 = self.act_t_1_2(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 106])\n",
    "        # print(\"ActFunc X shape: \"+str(x_t_1.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n------------D 1------------\")\n",
    "        x_d_1 = self.upconv_1_1(x_t_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "        # print(\"UpConv X shape: \"+str(x_d_1.shape))\n",
    "\n",
    "        x_d_1 = torch.cat([x_d_1, x_e_2], dim=1)    # \n",
    "        # print(\"Cat X shape: \"+str(x_d_1.shape))\n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        # print(\"Padding X shape: \"+str(x_d_1.shape))\n",
    "        x_d_1 = self.conv_d_1_1(x_d_1)              # \n",
    "        # print(\"Conv X shape: \"+str(x_d_1.shape))\n",
    "        x_d_1 = self.act_d_1_1(x_d_1)               # \n",
    "        # print(\"ActFunc X shape: \"+str(x_d_1.shape))\n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        # print(\"Padding X shape: \"+str(x_d_1.shape))\n",
    "        x_d_1 = self.conv_d_1_2(x_d_1)              # \n",
    "        # print(\"Conv X shape: \"+str(x_d_1.shape))\n",
    "        x_d_1 = self.act_d_1_2(x_d_1)               # \n",
    "        # print(\"ActFunc X shape: \"+str(x_d_1.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n------------D 2------------\")\n",
    "        x_d_2 = self.upconv_2_1(x_d_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "        # print(\"UpConv X shape: \"+str(x_d_2.shape))\n",
    "\n",
    "        x_d_2 = torch.cat([x_d_2, x_e_1], dim=1)    # \n",
    "        # print(\"Cat X shape: \"+str(x_d_2.shape))\n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        # print(\"Padding X shape: \"+str(x_d_2.shape))\n",
    "        x_d_2 = self.conv_d_2_1(x_d_2)              # \n",
    "        # print(\"Conv X shape: \"+str(x_d_2.shape))\n",
    "        x_d_2 = self.act_d_2_1(x_d_2)               # \n",
    "        # print(\"ActFunc X shape: \"+str(x_d_2.shape))\n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        # print(\"Padding X shape: \"+str(x_d_2.shape))\n",
    "        x_d_2 = self.conv_d_2_2(x_d_2)              # \n",
    "        # print(\"Conv X shape: \"+str(x_d_2.shape))\n",
    "        x_d_2 = self.act_d_2_2(x_d_2)               # \n",
    "        # print(\"ActFunc X shape: \"+str(x_d_2.shape))\n",
    "\n",
    "\n",
    "        # print(\"\\n------------Out------------\")\n",
    "        # # x = self.conv_out_1(x_d_2)\n",
    "\n",
    "\n",
    "        x = torch.flatten(x_d_2, 1)\n",
    "        # print(\"Flatten X shape: \"+str(x.shape))\n",
    "\n",
    "        x = self.output_dropout1(x)\n",
    "        # print(\"Dropped X shape: \"+str(x.shape))\n",
    "        x = self.act_out_1(x)\n",
    "        # print(\"Act X shape: \"+str(x.shape))\n",
    "        x = self.linear_out_1(x)\n",
    "        # print(\"Linear X shape: \"+str(x.shape))\n",
    "        \n",
    "        x = self.output_dropout2(x)\n",
    "        x = self.act_out_2(x)\n",
    "        x = self.linear_out_2(x)\n",
    "\n",
    "        # print(\"Output X shape: \"+str(x.shape))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilevelSimplestCNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses, nPreviousClasses):\n",
    "        super(MultilevelSimplestCNNClassifier, self).__init__()\n",
    "\n",
    "        print(\"nClasses: \"+str(nClasses))\n",
    "        print(\"nPreviousClasses: \"+str(nPreviousClasses))\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "\n",
    "        self.padding2 = nn.CircularPad1d((1,2))\n",
    "        self.conv2 = nn.Conv1d(8, 32, kernel_size=4)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.padding3 = nn.CircularPad1d((1,2))\n",
    "        self.conv3 = nn.Conv1d(32, 128, kernel_size=4)\n",
    "        self.adAvgPool3 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(28800, 28800*2)\n",
    "        self.linear2 = nn.Linear((28800*2)+nPreviousClasses, nClasses)\n",
    "    \n",
    "    def forward(self, x, px):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "        x = self.adAvgPool1(x)\n",
    "\n",
    "        \n",
    "        x = self.conv2(self.padding2(x))\n",
    "        x = self.adAvgPool2(x)\n",
    "\n",
    "        \n",
    "        x = self.conv3(self.padding3(x))\n",
    "        x = self.adAvgPool3(x)\n",
    "        \n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act4(x)\n",
    "        \n",
    "        x = torch.cat([x, px], dim=1)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilevelSimplestCNNClassifier2(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses, nPreviousClasses):\n",
    "        super(MultilevelSimplestCNNClassifier2, self).__init__()\n",
    "\n",
    "        print(\"nClasses: \"+str(nClasses))\n",
    "        print(\"nPreviousClasses: \"+str(nPreviousClasses))\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "\n",
    "        self.padding2 = nn.CircularPad1d((1,2))\n",
    "        self.conv2 = nn.Conv1d(8, 32, kernel_size=4)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.padding3 = nn.CircularPad1d((1,2))\n",
    "        self.conv3 = nn.Conv1d(32, 128, kernel_size=4)\n",
    "        self.adAvgPool3 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(28800, 28800)\n",
    "        self.linear2 = nn.Linear((28800)+nPreviousClasses, 14400)\n",
    "        \n",
    "        self.act5 = nn.ReLU()\n",
    "\n",
    "        self.linear3 = nn.Linear((14400)+nPreviousClasses, nClasses)\n",
    "    \n",
    "    def forward(self, x, px):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "        x = self.adAvgPool1(x)\n",
    "\n",
    "        \n",
    "        x = self.conv2(self.padding2(x))\n",
    "        x = self.adAvgPool2(x)\n",
    "\n",
    "        \n",
    "        x = self.conv3(self.padding3(x))\n",
    "        x = self.adAvgPool3(x)\n",
    "        \n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act4(x)\n",
    "        \n",
    "        x = torch.cat([x, px], dim=1)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = self.act5(x)\n",
    "        \n",
    "        x = torch.cat([x, px], dim=1)\n",
    "\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilevelSimplestCNNClassifier3(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses, nPreviousClasses):\n",
    "        super(MultilevelSimplestCNNClassifier3, self).__init__()\n",
    "\n",
    "        print(\"nClasses: \"+str(nClasses))\n",
    "        print(\"nPreviousClasses: \"+str(nPreviousClasses))\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "\n",
    "        self.padding2 = nn.CircularPad1d((1,2))\n",
    "        self.conv2 = nn.Conv1d(8, 32, kernel_size=4)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.padding3 = nn.CircularPad1d((1,2))\n",
    "        self.conv3 = nn.Conv1d(32, 128, kernel_size=4)\n",
    "        self.adAvgPool3 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "\n",
    "        self.linear1 = nn.Linear(28800, 14400)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear((14400)+nPreviousClasses, (7200+nClasses))\n",
    "        \n",
    "        self.act5 = nn.ReLU()\n",
    "\n",
    "        self.linear3 = nn.Linear((7200+nClasses)+nPreviousClasses, nClasses)\n",
    "    \n",
    "    def forward(self, x, px):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "        x = self.adAvgPool1(x)\n",
    "\n",
    "        \n",
    "        x = self.conv2(self.padding2(x))\n",
    "        x = self.adAvgPool2(x)\n",
    "\n",
    "        \n",
    "        x = self.conv3(self.padding3(x))\n",
    "        x = self.adAvgPool3(x)\n",
    "        \n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act4(x)\n",
    "        \n",
    "        x = torch.cat([x, px], dim=1)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = self.act5(x)\n",
    "        \n",
    "        x = torch.cat([x, px], dim=1)\n",
    "\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilevelSimplestCNNClassifier4(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses, nPreviousClasses):\n",
    "        super(MultilevelSimplestCNNClassifier4, self).__init__()\n",
    "\n",
    "        print(\"nClasses: \"+str(nClasses))\n",
    "        print(\"nPreviousClasses: \"+str(nPreviousClasses))\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "\n",
    "        self.padding2 = nn.CircularPad1d((1,2))\n",
    "        self.conv2 = nn.Conv1d(8, 32, kernel_size=4)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.padding3 = nn.CircularPad1d((1,2))\n",
    "        self.conv3 = nn.Conv1d(32, 128, kernel_size=4)\n",
    "        self.adAvgPool3 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(28800, 7200)\n",
    "        self.linear2 = nn.Linear((7200)+nPreviousClasses, (nClasses*2))\n",
    "        \n",
    "        self.act5 = nn.ReLU()\n",
    "\n",
    "        self.linear3 = nn.Linear((nClasses*2)+nPreviousClasses, nClasses)\n",
    "    \n",
    "    def forward(self, x, px):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "        x = self.adAvgPool1(x)\n",
    "\n",
    "        \n",
    "        x = self.conv2(self.padding2(x))\n",
    "        x = self.adAvgPool2(x)\n",
    "\n",
    "        \n",
    "        x = self.conv3(self.padding3(x))\n",
    "        x = self.adAvgPool3(x)\n",
    "        \n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act4(x)\n",
    "        \n",
    "        x = torch.cat([x, px], dim=1)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = self.act5(x)\n",
    "        \n",
    "        x = torch.cat([x, px], dim=1)\n",
    "\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_levels_ = [\n",
    "    # \"genus\",\n",
    "    # \"species\",\n",
    "    # \"order\", \n",
    "    \"family\", \n",
    "    \"class\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_batch_sizes_ = [\n",
    "    # 64,\n",
    "    # 128,\n",
    "    # 256,\n",
    "    # 512,\n",
    "    # 2048,\n",
    "    \"dynamic\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_epochs_ = [\n",
    "    # 2,\n",
    "    # 5,\n",
    "    # 30,\n",
    "    # 50,\n",
    "    # 100,\n",
    "    # 150,\n",
    "    200,\n",
    "    # 500\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_models_list_ = [\n",
    "    MultilevelSimplestCNNClassifier4,\n",
    "    MultilevelSimplestCNNClassifier3,\n",
    "    MultilevelSimplestCNNClassifier2,\n",
    "    MultilevelSimplestCNNClassifier,\n",
    "    # SimplestCNNClassifier,\n",
    "    # SimpleCNNClassifier,\n",
    "    # SimpleCNNWithDropoutClassifier,\n",
    "    # UnetBasedCNNClassifier,\n",
    "    # UnetBasedCNNWithDilationClassifier,\n",
    "    # UnetBasedCNNWithDropoutClassifier,\n",
    "    # UnetBasedCNNWithDropoutAndDilationClassifier,\n",
    "    # BaseCNNClassifier, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_loss_functions_ = {\n",
    "    \"CrossEntropyLoss\":{\n",
    "        \"function\":nn.CrossEntropyLoss,\n",
    "        \"params\":{},\n",
    "        \"function_params\":{}\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_learning_rates_ = [\n",
    "    # 1e-2,\n",
    "    # 5e-2,\n",
    "    # 1e-3,\n",
    "    # 5e-3,\n",
    "    # 1e-4,\n",
    "    5e-4,\n",
    "    5e-5,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_optimizers_ = [\n",
    "    {\n",
    "        \"optim\":torch.optim.AdamW,\n",
    "        \"params\":{\n",
    "            \"weight_decay\":1e-2,\n",
    "            \"amsgrad\":True\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparams = {\n",
    "    \"levels\": _levels_,\n",
    "    \"batch_size\": _batch_sizes_,\n",
    "    \"epochs\": _epochs_,\n",
    "    \"model\": _models_list_,\n",
    "    \"loss_function\": _loss_functions_,\n",
    "    \"learning_rate\": _learning_rates_,\n",
    "    \"optimizer\": _optimizers_    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Test(\n",
    "        model, \n",
    "        loss_fn, \n",
    "        optimizer, \n",
    "        epochs, \n",
    "        learning_rate, \n",
    "        batch_size, \n",
    "        train_data,\n",
    "        test_data,\n",
    "        id=\"\", \n",
    "        ):\n",
    "    \n",
    "    print(\"Model: \\t\\t\\t\"+(model._get_name() if not model._get_name() == \"OptimizedModule\" else model.__dict__[\"_modules\"][\"_orig_mod\"].__class__.__name__))\n",
    "    print(\"  Loss Func.: \\t\\t\"+loss_fn._get_name())\n",
    "    print(\"  Optimizer: \\t\\t\"+type(optimizer).__name__)\n",
    "    print(\"  Epochs: \\t\\t\"+str(epochs))\n",
    "    print(\"  Learning Rate: \\t\"+str(learning_rate))\n",
    "\n",
    "    print(\"\\nModel Arch: \")\n",
    "    print(str(model))\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    \n",
    "    if torch.cuda.get_device_capability() < (7, 0):\n",
    "        print(\"Exiting because torch.compile is not supported on this device.\")\n",
    "        import sys\n",
    "        sys.exit(0)\n",
    "\n",
    "    epochs_results = []\n",
    "    current = {\n",
    "        \"model\":(model._get_name() if not model._get_name() == \"OptimizedModule\" else model.__dict__[\"_modules\"][\"_orig_mod\"].__class__.__name__),\n",
    "        \"loss_function\":loss_fn._get_name(),\n",
    "        \"epoch\":None,\n",
    "        \"learning_rate\":learning_rate,\n",
    "        \"batch_size\":None,\n",
    "        \"train_size\":None,\n",
    "        \"test_size\":None,\n",
    "        \"optimizer\":type(optimizer).__name__,\n",
    "        \"train_acc\":None,\n",
    "        \"train_loss\":None,\n",
    "        \"test_acc\":None,\n",
    "        \"test_loss\":None,\n",
    "    }\n",
    "\n",
    "    if batch_size == \"dynamic\":\n",
    "        bss = [1000, 500, 250, 250, 500, 1000]\n",
    "    else:\n",
    "        bss = [batch_size]\n",
    "    if len(bss) > epochs:\n",
    "        bss = bss[0:epochs]\n",
    "    print(\"Batch Sizes List: \"+str(bss))\n",
    "    batch_lim = int(epochs/len(bss))\n",
    "    \n",
    "    \n",
    "    t_start = time.time()\n",
    "    \n",
    "    best = {\n",
    "        \"epoch\":0,\n",
    "        \"train_acc\":0,\n",
    "        \"train_loss\":10000000,\n",
    "        \"test_acc\":0,\n",
    "        \"test_loss\":10000000,\n",
    "    }\n",
    "    \n",
    "    train_loader = None\n",
    "    test_loader = None\n",
    "    \n",
    "    # Epochs\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "\n",
    "        if epoch%batch_lim == 0 and len(bss) > 0:\n",
    "            if train_loader:\n",
    "                del train_loader\n",
    "            if test_loader:\n",
    "                del test_loader\n",
    "\n",
    "            batch_size = bss.pop(0)\n",
    "            train_loader, test_loader = loaders_generator(train_data, test_data, batch_size)\n",
    "\n",
    "        print(\"Batch Size: \"+str(batch_size))\n",
    "\n",
    "        # Train --------------------------------------------------------------------------\n",
    "                    \n",
    "        #@torch.compile(fullgraph=False)\n",
    "        fn = torch.compile(optimizer.step)\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "\n",
    "        for batch, (X, prevy, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute prediction and loss\n",
    "            pred = model(X, prevy)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            fn()\n",
    "\n",
    "            # Update results\n",
    "            train_loss += loss.item()\n",
    "            train_acc += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "        # Train results\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(train_loader.dataset)\n",
    "        print(f\"Train: \\n Accuracy: {(100*train_acc):>0.1f}%, Avg loss: {train_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "        # Test\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, prevy, y in test_loader:\n",
    "                pred = model(X, prevy)\n",
    "                test_loss += loss_fn(pred, y).item()\n",
    "                test_acc += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "        # Test results\n",
    "        test_loss /= len(test_loader)\n",
    "        test_acc /= len(test_loader.dataset)\n",
    "        print(f\"Test: \\n Accuracy: {(100*test_acc):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "        # Update Results\n",
    "        if best[\"test_acc\"] < test_acc or (best[\"test_acc\"] == test_acc and best[\"train_acc\"] < train_acc):\n",
    "            best[\"epoch\"] = epoch+1\n",
    "            best[\"test_acc\"] = test_acc\n",
    "            best[\"test_loss\"] = test_loss\n",
    "            best[\"train_acc\"] = train_acc\n",
    "            best[\"train_loss\"] = train_loss\n",
    "\n",
    "            # if test_acc > 0.5:\n",
    "                # torch.save(model.state_dict(), \"/media/stark/Models/Gustavo/\"+train_data.level+\"/\"+str(id)+\"_\"+current[\"model\"]+\".pth\")\n",
    "                                \n",
    "            \n",
    "        \n",
    "        current[\"epoch\"] = epoch+1\n",
    "        current[\"batch_size\"] = batch_size\n",
    "        current[\"train_size\"] = train_loader.dataset.__len__()\n",
    "        current[\"test_size\"] = test_loader.dataset.__len__()\n",
    "        current[\"train_acc\"] = train_acc\n",
    "        current[\"train_loss\"] = train_loss\n",
    "        current[\"test_acc\"] = test_acc\n",
    "        current[\"test_loss\"] = test_loss\n",
    "\n",
    "    \n",
    "        epochs_results.append(current.copy())\n",
    "\n",
    "    pd.DataFrame(epochs_results).to_csv(\"./results/epochs/\"+str(id)+\"__\"+current[\"model\"]+\"_train_test.csv\")\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"Best Epoch:{best['epoch']} \\n\\tAccuracy: {(100*best['test_acc']):>0.1f}%, Avg loss: {best['test_loss']:>8f} \\n\")\n",
    "    print(\"Train and Test execution time: \"+str(format(time.time()-t_start, '.4f'))+\"s\")\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model_ = None\n",
    "_lossfunction_ = None\n",
    "_optimizer_ = None\n",
    "\n",
    "def clear():\n",
    "    global _model_, _lossfunction_, _optimizer_\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    torch.compiler.reset()\n",
    "    torch._dynamo.reset()\n",
    "\n",
    "    if _model_:\n",
    "        del _model_\n",
    "        _model_ = None\n",
    "    if _lossfunction_:\n",
    "        del _lossfunction_\n",
    "        _lossfunction_ = None\n",
    "    if _optimizer_:\n",
    "        del _optimizer_\n",
    "        _optimizer_ = None\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "results = []\n",
    "current = {}\n",
    "\n",
    "id = 0\n",
    "time_id = str(int(time.time()))\n",
    "print(\"Time ID: \"+str(time_id))\n",
    "\n",
    "for level in hiperparams[\"levels\"]:\n",
    "    clear()\n",
    "\n",
    "    train_data = pd.read_csv(\"../new_data/StratifiedSplit/\"+level+\"/train_dataset.csv\")\n",
    "    test_data = pd.read_csv(\"../new_data/StratifiedSplit/\"+level+\"/test_dataset.csv\")\n",
    "    print(level)\n",
    "    print(train_data.shape)\n",
    "    print(test_data.shape)\n",
    "\n",
    "    dataset = MultilevelSequenceDataset(\n",
    "        train=train_data, \n",
    "        test=test_data, \n",
    "        level=level)\n",
    "\n",
    "\n",
    "    for batch_size in hiperparams[\"batch_size\"]:\n",
    "        for epochs in hiperparams[\"epochs\"]:\n",
    "            for model in hiperparams[\"model\"]:\n",
    "                for loss_function_name, loss_function in hiperparams[\"loss_function\"].items():\n",
    "                    for learning_rate in hiperparams[\"learning_rate\"]:\n",
    "                        for optimizer in hiperparams[\"optimizer\"]:\n",
    "                            \n",
    "                            optim = optimizer[\"optim\"]\n",
    "                            optim_params = optimizer[\"params\"] if \"params\" in optimizer.keys() else {}\n",
    "\n",
    "                            current = {\n",
    "                                    \"id\": id,\n",
    "                                    \"start_time\":time.time(),\n",
    "                                    \"end_time\": None,\n",
    "                                    \"level\": level,\n",
    "                                    \"batch_size\": batch_size,\n",
    "                                    \"epochs\": epochs,\n",
    "                                    \"model\": model.__name__,\n",
    "                                    \"loss_function\": loss_function_name+\" (\"+str(loss_function[\"function\"])+\")\",\n",
    "                                    \"learning_rate\": learning_rate,\n",
    "                                    \"optimizer\": optim.__name__+\" (params: \"+str(optim_params)+\")\",\n",
    "                                    \"obs\": \"9:1\",\n",
    "                                    \"error\": None\n",
    "                                }\n",
    "\n",
    "\n",
    "                            try:                                \n",
    "                                clear()\n",
    "                                torch.set_float32_matmul_precision('high')\n",
    "                                \n",
    "                                _model_ = torch.compile(model(dataset.encoded_labels.shape[1], dataset.previous_encoded_labels.shape[1]))\n",
    "                                _lossfunction_ = loss_function[\"function\"](**{func:params[0](*params[1:]) for func,params in loss_function[\"function_params\"].items()})\n",
    "                                _optimizer_ = optim(_model_.parameters(), lr=learning_rate, **optim_params)\n",
    "\n",
    "\n",
    "                                # ---- Run ----\n",
    "                                result = Train_Test(\n",
    "                                    model=_model_,\n",
    "                                    loss_fn=_lossfunction_,\n",
    "                                    optimizer=_optimizer_,\n",
    "                                    epochs=epochs,\n",
    "                                    learning_rate=learning_rate,\n",
    "                                    batch_size=batch_size,\n",
    "                                    train_data=dataset,\n",
    "                                    test_data=dataset.get_test(),\n",
    "                                    id=time_id+\"_\"+str(id),\n",
    "                                    )\n",
    "                                    \n",
    "                                current[\"end_time\"] = time.time()\n",
    "                                current[\"best_epoch\"] = result[\"epoch\"]\n",
    "                                current[\"train_acc_best_epoch\"] = result[\"train_acc\"]\n",
    "                                current[\"train_loss_best_epoch\"] = result[\"train_loss\"]\n",
    "                                current[\"test_acc_best_epoch\"] = result[\"test_acc\"]\n",
    "                                current[\"test_loss_best_epoch\"] = result[\"test_loss\"]\n",
    "\n",
    "                                \n",
    "                                clear()                                \n",
    "                                \n",
    "                            except Exception as e:\n",
    "                                print(e)\n",
    "                                current[\"error\"] = str(e)\n",
    "                            \n",
    "                            results.append(current)\n",
    "                            pd.DataFrame(results).to_csv(\"./results/summarized/\"+str(time_id)+\"_models_train_test_\"+str(len(results))+\".csv\")\n",
    "                            \n",
    "                            id = id+1\n",
    "\n",
    "clear()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gustavo_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
