{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import GradScaler\n",
    "\n",
    "dtype = torch.float\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "torch.get_default_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_bernoulli(seq, prob=0.005):\n",
    "    idx = torch.bernoulli(prob * torch.ones(len(seq))).nonzero().squeeze(dim=1)\n",
    "    s = list(seq)\n",
    "\n",
    "    for i in idx.tolist():\n",
    "        s[i] = \"N\"\n",
    "\n",
    "    return \"\".join(s)\n",
    "\n",
    "def sequences_augmentation(data, level, cat, n):\n",
    "    to_copy = data.loc[data[level] == cat]\n",
    "\n",
    "    new_data = to_copy[0:1]\n",
    "    new_data = new_data.drop(new_data.index[0])\n",
    "\n",
    "    while new_data.shape[0] < n:\n",
    "        qnt = ((n-(new_data.shape[0])) / to_copy.shape[0]).__ceil__()\n",
    "\n",
    "        new_data = pd.concat(([to_copy]*qnt)+[new_data])\n",
    "        new_data[\"truncated_sequence\"] = new_data[\"truncated_sequence\"].apply(augmentation_bernoulli, prob=0.002)\n",
    "        new_data = new_data.drop_duplicates(subset=[\"truncated_sequence\"])\n",
    "    \n",
    "    new_data = new_data[:n-to_copy.shape[0]]\n",
    "    return new_data\n",
    "\n",
    "def data_augmentation(data, level, lower, upper):\n",
    "    class_count = data.groupby(level)[level].count().reset_index(name=\"count\")\n",
    "    \n",
    "    cats = class_count.loc[(class_count[\"count\"] < upper) & (class_count[\"count\"] >= lower)][level].to_list()\n",
    "\n",
    "    clones = sequences_augmentation(data, level, cats[0], upper)\n",
    "    for cat in cats[1:]:\n",
    "        clones = pd.concat([clones, sequences_augmentation(data, level, cat, upper)])\n",
    "\n",
    "    return pd.concat([data, clones])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_map = {\n",
    "    \"A\":[1.0, 0.0, 0.0, 0.0],\n",
    "    \"T\":[0.0, 1.0, 0.0, 0.0],\n",
    "    \"G\":[0.0, 0.0, 1.0, 0.0],\n",
    "    \"C\":[0.0, 0.0, 0.0, 1.0],\n",
    "\n",
    "    'W':[0.5, 0.5, 0.0, 0.0],\n",
    "    'S':[0.0, 0.0, 0.5, 0.5],\n",
    "    'M':[0.5, 0.0, 0.0, 0.5],\n",
    "    'K':[0.0, 0.5, 0.5, 0.0],\n",
    "    'R':[0.5, 0.0, 0.5, 0.0],\n",
    "    'Y':[0.0, 0.5, 0.0, 0.5],\n",
    "    \n",
    "    'B':[0.0, 0.3, 0.3, 0.3],\n",
    "    'D':[0.3, 0.3, 0.3, 0.0],\n",
    "    'H':[0.3, 0.3, 0.0, 0.3],\n",
    "    'V':[0.3, 0.0, 0.3, 0.3],\n",
    "\n",
    "    'N':[0.25, 0.25, 0.25, 0.25],\n",
    "}\n",
    "\n",
    "def encode_sequence(sequence):\n",
    "    encoded_seq = []\n",
    "\n",
    "    for base in sequence:\n",
    "        encoded_seq.append(base_map[base])\n",
    "    \n",
    "    return torch.tensor(encoded_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch dataset object to load Sequences and Classification Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, train, test, level, augmentation=False):\n",
    "\n",
    "        self.classes = pd.concat([train[level], test[level]]).unique().tolist()\n",
    "        self.classes.sort()\n",
    "        self.level = level\n",
    "\n",
    "        if augmentation:\n",
    "            train = data_augmentation(train, level, 10, 500)\n",
    "        \n",
    "        self.labels = train[level]\n",
    "        self.encoded_labels = SequenceDataset.__encoded_labels__(self.classes, self.labels)\n",
    "        self.sequences = SequenceDataset.__sequences__(train)\n",
    "\n",
    "        self.test = SequenceDatasetTest(\n",
    "            labels = test[level],\n",
    "            classes = self.classes,\n",
    "            encoded_labels = SequenceDataset.__encoded_labels__(self.classes, test[level]),\n",
    "            sequences = SequenceDataset.__sequences__(test)\n",
    "            )\n",
    "\n",
    "    def __encoded_labels__(classes, labels):\n",
    "        return torch.nn.functional.one_hot(torch.tensor([classes.index(l) for l in labels]), len(classes)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    def __sequences__(ds):\n",
    "        sequences = []\n",
    "        for _, row in ds.iterrows():\n",
    "            sequences.append(encode_sequence(row[\"truncated_sequence\"]))        \n",
    "        return torch.stack(sequences, dim=0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return   self.sequences[idx], self.encoded_labels[idx]\n",
    "    \n",
    "    def __getitems__(self, ids):\n",
    "        idx = torch.tensor(ids, device=torch.device('cuda:0'))\n",
    "        return   list(zip(torch.index_select(self.sequences, 0, idx), torch.index_select(self.encoded_labels, 0, idx)))\n",
    "    \n",
    "    def get_test(self):\n",
    "        return self.test\n",
    "\n",
    "class SequenceDatasetTest(SequenceDataset):    \n",
    "    def __init__(self, labels, classes, encoded_labels, sequences):\n",
    "        self.labels = labels\n",
    "        self.classes = classes\n",
    "        self.encoded_labels = encoded_labels\n",
    "        self.sequences = sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate PyTorch DataLoader objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaders_generator(ds_train, ds_test, bs = 128):\n",
    "    train_loader = DataLoader(ds_train, batch_size=bs, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "    test_loader = DataLoader(ds_test, batch_size=bs, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple CNN Model with 3 Conv1d layers and 2 fully connected layers\n",
    "# Input (1-Dimension 4-Channels)\n",
    "\n",
    "## Notes:\n",
    "#   - Bad fully connected size\n",
    "#   - Too much VRAM\n",
    "class SimplestCNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "\n",
    "        self.padding2 = nn.CircularPad1d((1,2))\n",
    "        self.conv2 = nn.Conv1d(8, 32, kernel_size=4)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.padding3 = nn.CircularPad1d((1,2))\n",
    "        self.conv3 = nn.Conv1d(32, 128, kernel_size=4)\n",
    "        self.adAvgPool3 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(28800, 28800*2)\n",
    "        self.linear2 = nn.Linear(28800*2, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "        x = self.adAvgPool1(x)\n",
    "\n",
    "        x = self.conv2(self.padding2(x))\n",
    "        x = self.adAvgPool2(x)\n",
    "        \n",
    "        x = self.conv3(self.padding3(x))\n",
    "        x = self.adAvgPool3(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A test of a CNN Model with 3 different Conv1d layers concatenated and 2 fully connected layers\n",
    "# Input (1-Dimension 4-Channels)\n",
    "\n",
    "## Notes:\n",
    "#   - \n",
    "class SimpleCNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimpleCNNClassifier, self).__init__()\n",
    "\n",
    "        self.padding = nn.CircularPad1d((1,2))\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(4, 4, kernel_size=4, groups=4)\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(4, 4, kernel_size=4)        \n",
    "        self.act2 = nn.ReLU()\n",
    "        \n",
    "        self.act3 = nn.ReLU()        \n",
    "        self.conv3 = nn.Conv1d(4, 8, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "        \n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(14400, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "        a = self.conv1(self.padding(x))\n",
    "        a = self.act1(a)        \n",
    "        \n",
    "        b = self.conv2(self.padding(x))\n",
    "        b = self.act2(b)\n",
    "        \n",
    "        c = self.conv3(x)\n",
    "        c = self.act3(c)\n",
    "        \n",
    "        x = torch.flatten(torch.cat([a,b,c], dim=1), 1)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        \n",
    "        x = self.act4(x)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A test of a CNN Model with 3 different Conv1d layers concatenated, 2 fully connected layers, and dropouts\n",
    "# Input (1-Dimension 4-Channels)\n",
    "\n",
    "## Notes:\n",
    "#   - \n",
    "class SimpleCNNWithDropoutClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimpleCNNWithDropoutClassifier, self).__init__()\n",
    "\n",
    "        self.padding = nn.CircularPad1d((1,2))\n",
    "\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.conv1 = nn.Conv1d(4, 4, kernel_size=4, groups=4)\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(4, 4, kernel_size=4)\n",
    "        self.act2 = nn.ReLU()\n",
    "        \n",
    "        self.act3 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(4, 8, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.linear1 = nn.Linear(14400, 7200)\n",
    "\n",
    "        self.dropout3 = nn.Dropout(p=0.2)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "        x = self.dropout1(x)\n",
    "        a = self.conv1(self.padding(x))\n",
    "        a = self.act1(a)\n",
    "        \n",
    "        b = self.conv2(self.padding(x))\n",
    "        b = self.act2(b)\n",
    "        \n",
    "        c = self.conv3(x)\n",
    "        c = self.act3(c)\n",
    "        \n",
    "        x = torch.flatten(torch.cat([a,b,c], dim=1), 1)\n",
    "        \n",
    "        x = self.dropout2(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act4(x)\n",
    "        \n",
    "        x = self.dropout3(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A CNN Model with 2 different Conv1d layers concatenated, 2 fully connected layers\n",
    "# Input (1-Dimension 4-Channels)\n",
    "\n",
    "## Notes:\n",
    "#   - Miss sequential Conv layers\n",
    "class BaseCNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(BaseCNNClassifier, self).__init__()\n",
    "\n",
    "        self.conv1_1 = nn.Conv1d(1, 4, kernel_size=4)\n",
    "        self.conv1_2 = nn.Conv1d(1, 4, kernel_size=4, dilation=2)\n",
    "        self.avgPool = nn.AvgPool1d(4, stride=2)\n",
    "        \n",
    "        self.padding = nn.CircularPad1d((1,2))\n",
    "        \n",
    "        self.act1 = nn.ReLU()\n",
    "        self.act2 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(14392, 14392)\n",
    "        self.linear2 = nn.Linear(14392, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.unsqueeze(torch.flatten(x, start_dim=1), 1)\n",
    "        x = self.padding(x)\n",
    "        \n",
    "        x_1_1 = self.conv1_1(x)\n",
    "        x_1_2 = self.conv1_2(self.padding(x))      \n",
    "\n",
    "        x = torch.cat([x_1_1, x_1_2], dim=1)\n",
    "        x = self.avgPool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.act1(x)\n",
    "        x = self.linear1(x)\n",
    "        \n",
    "        x = self.act2(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A UNet Model with 2 encode+decode levels and 2 fully connected layers\n",
    "# Input (1-Dimension 4-Channels)\n",
    "\n",
    "## Notes:\n",
    "#   - \n",
    "class UnetBasedCNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(UnetBasedCNNClassifier, self).__init__()\n",
    "\n",
    "        # First Encode Level\n",
    "        self.padding_e_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.act_e_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_e_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_2 = nn.Conv1d(8, 8, kernel_size=4)\n",
    "        self.act_e_1_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_1_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "\n",
    "        # Second Encode Level        \n",
    "        self.padding_e_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_1 = nn.Conv1d(8, 16, kernel_size=4)\n",
    "        self.act_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_e_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_e_2_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_2_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "        \n",
    "        # Transition Level\n",
    "        self.padding_t_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_1 = nn.Conv1d(16, 32, kernel_size = 4)\n",
    "        self.act_t_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_t_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_2 = nn.Conv1d(32, 32, kernel_size = 4)\n",
    "        self.act_t_1_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # First Decode Level\n",
    "        self.upconv_1_1 = nn.ConvTranspose1d(32, 16, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_1 = nn.Conv1d(32, 16, kernel_size=4)\n",
    "        self.act_d_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_d_1_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # Second Decode Level\n",
    "        self.upconv_2_1 = nn.ConvTranspose1d(16, 8, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_1 = nn.Conv1d(16, 8, kernel_size=4)\n",
    "        self.act_d_2_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_2 = nn.Conv1d(8, 8, kernel_size=4)\n",
    "        self.act_d_2_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # Output Level\n",
    "        self.conv_out_1 = nn.Conv1d(8, nClasses, kernel_size=1)\n",
    "        \n",
    "        self.linear_out_1 = nn.Linear(7200, 14400)\n",
    "        self.act_out_1 = nn.ReLU()\n",
    "        self.linear_out_2 = nn.Linear(14400, nClasses)\n",
    "        self.act_out_2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.reshape(x.shape[0],4,-1)              # Reshape X shape: torch.Size([3, 4, 900])\n",
    "\n",
    "        # Encoder 1\n",
    "        x_e_1 = self.padding_e_1_1(x)               # Padding X shape: torch.Size([3, 4, 900])\n",
    "        x_e_1 = self.conv_e_1_1(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        x_e_1 = self.act_e_1_1(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        \n",
    "        x_e_1 = self.padding_e_1_2(x_e_1)           # Padding X shape: torch.Size([3, 8, 903])\n",
    "        x_e_1 = self.conv_e_1_2(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        x_e_1 = self.act_e_1_2(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        \n",
    "        x_e_p_1 = self.avgPool_e_1_1(x_e_1)         # Pool X shape: torch.Size([3, 8, 450])\n",
    "\n",
    "\n",
    "        # Encoder 2\n",
    "        x_e_2 = self.padding_e_2_1(x_e_p_1)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_e_2 = self.conv_e_2_1(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_1(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "        \n",
    "        x_e_2 = self.padding_e_2_2(x_e_2)           # Padding X shape: torch.Size([3, 16, 453])\n",
    "        x_e_2 = self.conv_e_2_2(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_2(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "\n",
    "        x_e_p_2 = self.avgPool_e_2_1(x_e_2)         # Pool X shape: torch.Size([3, 16, 225])\n",
    "\n",
    "\n",
    "        # Transition\n",
    "        x_t_1 = self.padding_t_1_1(x_e_p_2)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_t_1 = self.conv_t_1_1(x_t_1)              # Conv X shape: torch.Size([3, 32, 109])\n",
    "        x_t_1 = self.act_t_1_1(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 109])\n",
    "        \n",
    "        x_t_1 = self.padding_t_1_2(x_t_1)           # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_t_1 = self.conv_t_1_2(x_t_1)              # Conv X shape: torch.Size([3, 32, 106])\n",
    "        x_t_1 = self.act_t_1_2(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 106])\n",
    "\n",
    "\n",
    "        # Decode 1\n",
    "        x_d_1 = self.upconv_1_1(x_t_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "\n",
    "        x_d_1 = torch.cat([x_d_1, x_e_2], dim=1)    # \n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        x_d_1 = self.conv_d_1_1(x_d_1)              # \n",
    "        x_d_1 = self.act_d_1_1(x_d_1)               # \n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        x_d_1 = self.conv_d_1_2(x_d_1)              # \n",
    "        x_d_1 = self.act_d_1_2(x_d_1)               # \n",
    "\n",
    "\n",
    "        # Decode 2\n",
    "        x_d_2 = self.upconv_2_1(x_d_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "\n",
    "        x_d_2 = torch.cat([x_d_2, x_e_1], dim=1)    # \n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        x_d_2 = self.conv_d_2_1(x_d_2)              # \n",
    "        x_d_2 = self.act_d_2_1(x_d_2)               # \n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        x_d_2 = self.conv_d_2_2(x_d_2)              # \n",
    "        x_d_2 = self.act_d_2_2(x_d_2)               # \n",
    "\n",
    "\n",
    "        # Output\n",
    "\n",
    "        x = torch.flatten(x_d_2, 1)\n",
    "        \n",
    "        x = self.act_out_1(x)\n",
    "        x = self.linear_out_1(x)\n",
    "        \n",
    "        x = self.act_out_2(x)\n",
    "        x = self.linear_out_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A UNet Model variant with 2 encode+decode levels, 2 fully connected layers, and dropouts\n",
    "# Input (1-Dimension 4-Channels)\n",
    "\n",
    "## Notes:\n",
    "#   - \n",
    "class UnetBasedCNNWithDropoutClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(UnetBasedCNNWithDropoutClassifier, self).__init__()\n",
    "\n",
    "        self.input_dropout1 = nn.Dropout(p=0.2)\n",
    "\n",
    "        # First Encode Level\n",
    "        self.padding_e_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.act_e_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_e_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_2 = nn.Conv1d(8, 8, kernel_size=4)\n",
    "        self.act_e_1_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_1_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "\n",
    "        # Second Encode Level        \n",
    "        self.padding_e_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_1 = nn.Conv1d(8, 16, kernel_size=4)\n",
    "        self.act_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_e_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_e_2_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_2_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "        \n",
    "        # Transition Level\n",
    "        self.padding_t_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_1 = nn.Conv1d(16, 32, kernel_size = 4)\n",
    "        self.act_t_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_t_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_2 = nn.Conv1d(32, 32, kernel_size = 4)\n",
    "        self.act_t_1_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # First Decode Level\n",
    "        self.upconv_1_1 = nn.ConvTranspose1d(32, 16, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_1 = nn.Conv1d(32, 16, kernel_size=4)\n",
    "        self.act_d_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_d_1_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # Second Decode Level\n",
    "        self.upconv_2_1 = nn.ConvTranspose1d(16, 8, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_1 = nn.Conv1d(16, 8, kernel_size=4)\n",
    "        self.act_d_2_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_2 = nn.Conv1d(8, 8, kernel_size=4)\n",
    "        self.act_d_2_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # Output Level\n",
    "        self.conv_out_1 = nn.Conv1d(8, nClasses, kernel_size=1)\n",
    "        \n",
    "        \n",
    "        self.output_dropout1 = nn.Dropout(p=0.2)\n",
    "        self.linear_out_1 = nn.Linear(7200, 14400)\n",
    "        self.act_out_1 = nn.ReLU()\n",
    "\n",
    "        \n",
    "        self.output_dropout2 = nn.Dropout(p=0.2)\n",
    "        self.linear_out_2 = nn.Linear(14400, nClasses)\n",
    "        self.act_out_2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.reshape(x.shape[0],4,-1)              # Reshape X shape: torch.Size([3, 4, 900])\n",
    "        x = self.input_dropout1(x)\n",
    "\n",
    "        x_e_1 = self.padding_e_1_1(x)               # Padding X shape: torch.Size([3, 4, 900])\n",
    "        x_e_1 = self.conv_e_1_1(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        x_e_1 = self.act_e_1_1(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        \n",
    "        x_e_1 = self.padding_e_1_2(x_e_1)           # Padding X shape: torch.Size([3, 8, 903])\n",
    "        x_e_1 = self.conv_e_1_2(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        x_e_1 = self.act_e_1_2(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        \n",
    "        x_e_p_1 = self.avgPool_e_1_1(x_e_1)         # Pool X shape: torch.Size([3, 8, 450])\n",
    "\n",
    "\n",
    "        x_e_2 = self.padding_e_2_1(x_e_p_1)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_e_2 = self.conv_e_2_1(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_1(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "        \n",
    "        x_e_2 = self.padding_e_2_2(x_e_2)           # Padding X shape: torch.Size([3, 16, 453])\n",
    "        x_e_2 = self.conv_e_2_2(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_2(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "\n",
    "        x_e_p_2 = self.avgPool_e_2_1(x_e_2)         # Pool X shape: torch.Size([3, 16, 225])\n",
    "\n",
    "\n",
    "        x_t_1 = self.padding_t_1_1(x_e_p_2)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_t_1 = self.conv_t_1_1(x_t_1)              # Conv X shape: torch.Size([3, 32, 109])\n",
    "        x_t_1 = self.act_t_1_1(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 109])\n",
    "        \n",
    "        x_t_1 = self.padding_t_1_2(x_t_1)           # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_t_1 = self.conv_t_1_2(x_t_1)              # Conv X shape: torch.Size([3, 32, 106])\n",
    "        x_t_1 = self.act_t_1_2(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 106])\n",
    "\n",
    "\n",
    "        x_d_1 = self.upconv_1_1(x_t_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "\n",
    "        x_d_1 = torch.cat([x_d_1, x_e_2], dim=1)    # \n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        x_d_1 = self.conv_d_1_1(x_d_1)              # \n",
    "        x_d_1 = self.act_d_1_1(x_d_1)               # \n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        x_d_1 = self.conv_d_1_2(x_d_1)              # \n",
    "        x_d_1 = self.act_d_1_2(x_d_1)               # \n",
    "\n",
    "\n",
    "        x_d_2 = self.upconv_2_1(x_d_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "\n",
    "        x_d_2 = torch.cat([x_d_2, x_e_1], dim=1)    # \n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        x_d_2 = self.conv_d_2_1(x_d_2)              # \n",
    "        x_d_2 = self.act_d_2_1(x_d_2)               # \n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        x_d_2 = self.conv_d_2_2(x_d_2)              # \n",
    "        x_d_2 = self.act_d_2_2(x_d_2)               # \n",
    "\n",
    "\n",
    "        x = torch.flatten(x_d_2, 1)\n",
    "        x = self.output_dropout1(x)\n",
    "        \n",
    "        x = self.act_out_1(x)\n",
    "        x = self.linear_out_1(x)\n",
    "        \n",
    "        x = self.output_dropout2(x)\n",
    "        x = self.act_out_2(x)\n",
    "        x = self.linear_out_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A UNet Model with 2 encode(with dilation)+decode levels and 2 fully connected layers\n",
    "# Input (1-Dimension 4-Channels)\n",
    "\n",
    "## Notes:\n",
    "#   - \n",
    "class UnetBasedCNNWithDilationClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(UnetBasedCNNWithDilationClassifier, self).__init__()\n",
    "\n",
    "        # First Encode Level\n",
    "        self.padding_e_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.act_e_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.convd_e_1_1 = nn.Conv1d(4, 8, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "        self.actd_e_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_e_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_e_1_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_1_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "        # Second Encode Level        \n",
    "        self.padding_e_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_1 = nn.Conv1d(16, 32, kernel_size=4)\n",
    "        self.act_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.convd_e_2_1 = nn.Conv1d(16, 32, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "        self.actd_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_e_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_2 = nn.Conv1d(64, 64, kernel_size=4)\n",
    "        self.act_e_2_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_2_1 = nn.AvgPool1d(2, stride=2)\n",
    "        \n",
    "        # Transition Level\n",
    "        self.padding_t_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_1 = nn.Conv1d(64, 128, kernel_size = 4)\n",
    "        self.act_t_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_t_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_2 = nn.Conv1d(128, 128, kernel_size = 4)\n",
    "        self.act_t_1_2 = nn.ReLU()\n",
    "\n",
    "        # First Decode Level\n",
    "        self.upconv_1_1 = nn.ConvTranspose1d(128, 64, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_1 = nn.Conv1d(128, 64, kernel_size=4)\n",
    "        self.act_d_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_2 = nn.Conv1d(64, 64, kernel_size=4)\n",
    "        self.act_d_1_2 = nn.ReLU()\n",
    "\n",
    "        # Second Decode Level\n",
    "        self.upconv_2_1 = nn.ConvTranspose1d(64, 32, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_1 = nn.Conv1d(48, 24, kernel_size=4)\n",
    "        self.act_d_2_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_2 = nn.Conv1d(24, 24, kernel_size=4)\n",
    "        self.act_d_2_2 = nn.ReLU()\n",
    "\n",
    "        # Output Level\n",
    "        self.conv_out_1 = nn.Conv1d(24, nClasses, kernel_size=1)\n",
    "        \n",
    "        self.linear_out_1 = nn.Linear(21600, 7200)\n",
    "        self.act_out_1 = nn.ReLU()\n",
    "\n",
    "        self.linear_out_2 = nn.Linear(7200, nClasses)\n",
    "        self.act_out_2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.reshape(x.shape[0],4,-1)              # Reshape X shape: torch.Size([3, 4, 900])\n",
    "\n",
    "        # Encoder 1\n",
    "        x_e_1 = self.padding_e_1_1(x)               # Padding X shape: torch.Size([3, 4, 900])\n",
    "        x_e_1 = self.conv_e_1_1(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])        \n",
    "        x_e_1 = self.act_e_1_1(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])        \n",
    "\n",
    "        x_e_1_d = self.convd_e_1_1(x)\n",
    "        x_e_1_d = self.actd_e_1_1(x_e_1_d)\n",
    "        \n",
    "        x_e_1 = torch.cat([x_e_1, x_e_1_d], dim=1)\n",
    "        \n",
    "        x_e_1 = self.padding_e_1_2(x_e_1)           # Padding X shape: torch.Size([3, 8, 903])\n",
    "        x_e_1 = self.conv_e_1_2(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        x_e_1 = self.act_e_1_2(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        \n",
    "        x_e_p_1 = self.avgPool_e_1_1(x_e_1)         # Pool X shape: torch.Size([3, 8, 450])\n",
    "\n",
    "        # Encoder 2\n",
    "        x_e_2 = self.padding_e_2_1(x_e_p_1)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_e_2 = self.conv_e_2_1(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_1(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "\n",
    "        x_e_2_d = self.convd_e_2_1(x_e_p_1)\n",
    "        x_e_2_d = self.actd_e_2_1(x_e_2_d)        \n",
    "        x_e_2 = torch.cat([x_e_2, x_e_2_d], dim=1)\n",
    "        \n",
    "        x_e_2 = self.padding_e_2_2(x_e_2)           # Padding X shape: torch.Size([3, 16, 453])\n",
    "        x_e_2 = self.conv_e_2_2(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_2(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "\n",
    "        x_e_p_2 = self.avgPool_e_2_1(x_e_2)         # Pool X shape: torch.Size([3, 16, 225])\n",
    "\n",
    "\n",
    "        # Transition\n",
    "        x_t_1 = self.padding_t_1_1(x_e_p_2)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_t_1 = self.conv_t_1_1(x_t_1)              # Conv X shape: torch.Size([3, 32, 109])\n",
    "        x_t_1 = self.act_t_1_1(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 109])\n",
    "        \n",
    "        x_t_1 = self.padding_t_1_2(x_t_1)           # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_t_1 = self.conv_t_1_2(x_t_1)              # Conv X shape: torch.Size([3, 32, 106])\n",
    "        x_t_1 = self.act_t_1_2(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 106])\n",
    "\n",
    "\n",
    "        # Decode 1\n",
    "        x_d_1 = self.upconv_1_1(x_t_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "\n",
    "        x_d_1 = torch.cat([x_d_1, x_e_2], dim=1)    # \n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        x_d_1 = self.conv_d_1_1(x_d_1)              # \n",
    "        x_d_1 = self.act_d_1_1(x_d_1)               # \n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        x_d_1 = self.conv_d_1_2(x_d_1)              # \n",
    "        x_d_1 = self.act_d_1_2(x_d_1)               # \n",
    "\n",
    "\n",
    "        # Decode 2\n",
    "        x_d_2 = self.upconv_2_1(x_d_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "\n",
    "        x_d_2 = torch.cat([x_d_2, x_e_1], dim=1)    # \n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        x_d_2 = self.conv_d_2_1(x_d_2)              # \n",
    "        x_d_2 = self.act_d_2_1(x_d_2)               # \n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        x_d_2 = self.conv_d_2_2(x_d_2)              # \n",
    "        x_d_2 = self.act_d_2_2(x_d_2)               # \n",
    "\n",
    "\n",
    "        # Output\n",
    "        x = torch.flatten(x_d_2, 1)\n",
    "\n",
    "        x = self.act_out_1(x)\n",
    "        x = self.linear_out_1(x)\n",
    "        \n",
    "        x = self.act_out_2(x)\n",
    "        x = self.linear_out_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A UNet Model variant with 2 encode(with dilation)+decode levels, 2 fully connected layers, and dropouts\n",
    "# Input (1-Dimension 4-Channels)\n",
    "\n",
    "## Notes:\n",
    "#   - \n",
    "class UnetBasedCNNWithDropoutAndDilationClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(UnetBasedCNNWithDropoutAndDilationClassifier, self).__init__()\n",
    "\n",
    "        self.input_dropout1 = nn.Dropout(p=0.2)\n",
    "\n",
    "        # First Encode Level\n",
    "        self.padding_e_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.act_e_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.convd_e_1_1 = nn.Conv1d(4, 8, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "        self.actd_e_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_e_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_e_1_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_1_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "        # Second Encode Level        \n",
    "        self.padding_e_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_1 = nn.Conv1d(16, 32, kernel_size=4)\n",
    "        self.act_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.convd_e_2_1 = nn.Conv1d(16, 32, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "        self.actd_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_e_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_2 = nn.Conv1d(64, 64, kernel_size=4)\n",
    "        self.act_e_2_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_2_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "        # Transition Level\n",
    "        self.padding_t_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_1 = nn.Conv1d(64, 128, kernel_size = 4)\n",
    "        self.act_t_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_t_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_2 = nn.Conv1d(128, 128, kernel_size = 4)\n",
    "        self.act_t_1_2 = nn.ReLU()\n",
    "\n",
    "        # First Decode Level\n",
    "        self.upconv_1_1 = nn.ConvTranspose1d(128, 64, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_1 = nn.Conv1d(128, 64, kernel_size=4)\n",
    "        self.act_d_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_2 = nn.Conv1d(64, 64, kernel_size=4)\n",
    "        self.act_d_1_2 = nn.ReLU()\n",
    "\n",
    "        # Second Decode Level\n",
    "        self.upconv_2_1 = nn.ConvTranspose1d(64, 32, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_1 = nn.Conv1d(48, 24, kernel_size=4)\n",
    "        self.act_d_2_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_2 = nn.Conv1d(24, 24, kernel_size=4)\n",
    "        self.act_d_2_2 = nn.ReLU()\n",
    "\n",
    "        # Output Level\n",
    "        self.conv_out_1 = nn.Conv1d(24, nClasses, kernel_size=1)\n",
    "        \n",
    "        self.output_dropout1 = nn.Dropout(p=0.2)\n",
    "        self.linear_out_1 = nn.Linear(21600, 43200)\n",
    "        self.act_out_1 = nn.ReLU()\n",
    "\n",
    "        self.output_dropout2 = nn.Dropout(p=0.2)\n",
    "        self.linear_out_2 = nn.Linear(43200, nClasses)\n",
    "        self.act_out_2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0],4,-1)              # Reshape X shape: torch.Size([3, 4, 900])\n",
    "\n",
    "        x = self.input_dropout1(x)\n",
    "\n",
    "        # Encode 1\n",
    "        x_e_1 = self.padding_e_1_1(x)               # Padding X shape: torch.Size([3, 4, 900])\n",
    "        x_e_1 = self.conv_e_1_1(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])        \n",
    "        x_e_1 = self.act_e_1_1(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])        \n",
    "\n",
    "        x_e_1_d = self.convd_e_1_1(x)\n",
    "        x_e_1_d = self.actd_e_1_1(x_e_1_d)\n",
    "        \n",
    "        x_e_1 = torch.cat([x_e_1, x_e_1_d], dim=1)\n",
    "        \n",
    "        x_e_1 = self.padding_e_1_2(x_e_1)           # Padding X shape: torch.Size([3, 8, 903])\n",
    "        x_e_1 = self.conv_e_1_2(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        x_e_1 = self.act_e_1_2(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        \n",
    "        x_e_p_1 = self.avgPool_e_1_1(x_e_1)         # Pool X shape: torch.Size([3, 8, 450])\n",
    "\n",
    "        # Encode 2\n",
    "        x_e_2 = self.padding_e_2_1(x_e_p_1)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_e_2 = self.conv_e_2_1(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_1(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "\n",
    "        x_e_2_d = self.convd_e_2_1(x_e_p_1)\n",
    "        x_e_2_d = self.actd_e_2_1(x_e_2_d)        \n",
    "        x_e_2 = torch.cat([x_e_2, x_e_2_d], dim=1)\n",
    "        \n",
    "        x_e_2 = self.padding_e_2_2(x_e_2)           # Padding X shape: torch.Size([3, 16, 453])\n",
    "        x_e_2 = self.conv_e_2_2(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_2(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "\n",
    "        x_e_p_2 = self.avgPool_e_2_1(x_e_2)         # Pool X shape: torch.Size([3, 16, 225])\n",
    "\n",
    "        # Transition\n",
    "        x_t_1 = self.padding_t_1_1(x_e_p_2)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_t_1 = self.conv_t_1_1(x_t_1)              # Conv X shape: torch.Size([3, 32, 109])\n",
    "        x_t_1 = self.act_t_1_1(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 109])\n",
    "        \n",
    "        x_t_1 = self.padding_t_1_2(x_t_1)           # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_t_1 = self.conv_t_1_2(x_t_1)              # Conv X shape: torch.Size([3, 32, 106])\n",
    "        x_t_1 = self.act_t_1_2(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 106])\n",
    "\n",
    "        # Decode 1\n",
    "        x_d_1 = self.upconv_1_1(x_t_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "\n",
    "        x_d_1 = torch.cat([x_d_1, x_e_2], dim=1)    # \n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        x_d_1 = self.conv_d_1_1(x_d_1)              # \n",
    "        x_d_1 = self.act_d_1_1(x_d_1)               # \n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        x_d_1 = self.conv_d_1_2(x_d_1)              # \n",
    "        x_d_1 = self.act_d_1_2(x_d_1)               # \n",
    "\n",
    "        # Decode 2\n",
    "        x_d_2 = self.upconv_2_1(x_d_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "\n",
    "        x_d_2 = torch.cat([x_d_2, x_e_1], dim=1)    # \n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        x_d_2 = self.conv_d_2_1(x_d_2)              # \n",
    "        x_d_2 = self.act_d_2_1(x_d_2)               # \n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        x_d_2 = self.conv_d_2_2(x_d_2)              # \n",
    "        x_d_2 = self.act_d_2_2(x_d_2)               # \n",
    "\n",
    "        # Output\n",
    "        x = torch.flatten(x_d_2, 1)\n",
    "\n",
    "        x = self.output_dropout1(x)\n",
    "        x = self.act_out_1(x)\n",
    "        x = self.linear_out_1(x)\n",
    "        \n",
    "        x = self.output_dropout2(x)\n",
    "        x = self.act_out_2(x)\n",
    "        x = self.linear_out_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporary models tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier0(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier0, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "\n",
    "        self.padding2 = nn.CircularPad1d((1,2))\n",
    "        self.conv2 = nn.Conv1d(8, 32, kernel_size=4)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.padding3 = nn.CircularPad1d((1,2))\n",
    "        self.conv3 = nn.Conv1d(32, 128, kernel_size=4)\n",
    "        self.adAvgPool3 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(28800, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "        x = self.adAvgPool1(x)\n",
    "\n",
    "        x = self.conv2(self.padding2(x))\n",
    "        x = self.adAvgPool2(x)\n",
    "        \n",
    "        x = self.conv3(self.padding3(x))\n",
    "        x = self.adAvgPool3(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier0_1layer(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier0_1layer, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 32, kernel_size=3)\n",
    "        \n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(28832, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "      \n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier0_1layerk2(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier0_1layerk2, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 32, kernel_size=2)\n",
    "        \n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(28864, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "      \n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier0_1layerk4(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier0_1layerk4, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 32, kernel_size=4)\n",
    "        \n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(28800, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "      \n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier0_1layer16(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier0_1layer16, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 16, kernel_size=3)\n",
    "        \n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(14416, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "      \n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier0_1layerGELU(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier0_1layerGELU, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 32, kernel_size=3)\n",
    "        \n",
    "        self.act1 = nn.GELU()\n",
    "\n",
    "        self.linear1 = nn.Linear(28832, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "      \n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier0_1layer64c(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier0_1layer64c, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 64, kernel_size=3)\n",
    "        \n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(57664, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "      \n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier0_1layerPooling(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier0_1layerPooling, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 32, kernel_size=3)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "        \n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(14400, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "        x = self.adAvgPool1(x)\n",
    "      \n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier0_1layer64cPooling(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier0_1layer64cPooling, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 64, kernel_size=3)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "        \n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(28800, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "        x = self.adAvgPool1(x)\n",
    "      \n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier_2layers(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier_2layers, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 16, kernel_size=4)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "\n",
    "        self.padding2 = nn.CircularPad1d((1,2))\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=4)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(7200, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "        x = self.adAvgPool1(x)\n",
    "\n",
    "        x = self.conv2(self.padding2(x))\n",
    "        x = self.adAvgPool2(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier_2layers_concat(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier_2layers_concat, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 16, kernel_size=4)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "\n",
    "        self.padding2 = nn.CircularPad1d((1,2))\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=4)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(14400, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "        x1 = self.adAvgPool1(x)\n",
    "\n",
    "        x = self.conv2(self.padding2(x1))\n",
    "        x2 = self.adAvgPool2(x)\n",
    "        \n",
    "        # x = torch.flatten(x, 1)\n",
    "        x1 = torch.flatten(x1, 1)\n",
    "        x2 = torch.flatten(x2, 1)\n",
    "\n",
    "        x = torch.cat([x1,x2], dim=1)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=4):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        # Padding to maintain input size\n",
    "        self.padding = nn.CircularPad1d((1,2))\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        \n",
    "        # Activation\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Store the input for the residual connection\n",
    "        residual = x\n",
    "        \n",
    "        # Main path\n",
    "        out = self.padding(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        residual = self.shortcut(residual)\n",
    "        \n",
    "        # Add residual connection\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class SimplestCNNClassifier_2layers_Residual(nn.Module):\n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier_2layers_Residual, self).__init__()\n",
    "        \n",
    "        # Residual blocks with adaptive pooling\n",
    "        self.residual_block1 = ResidualBlock(4, 16)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "        \n",
    "        self.residual_block2 = ResidualBlock(16, 32)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "        \n",
    "        # Activation and fully connected layers\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        # Calculate the input size for linear layers\n",
    "        # You might need to adjust this based on your specific input dimensions\n",
    "        self.linear1 = nn.Linear(7200, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Move channel dimension\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "        \n",
    "        # First residual block\n",
    "        x = self.residual_block1(x)\n",
    "        x = self.adAvgPool1(x)\n",
    "        \n",
    "        # Second residual block\n",
    "        x = self.residual_block2(x)\n",
    "        x = self.adAvgPool2(x)\n",
    "        \n",
    "        # Flatten and fully connected layers\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier_3layers_Residual(nn.Module):\n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier_3layers_Residual, self).__init__()\n",
    "        \n",
    "        # Residual blocks with adaptive pooling\n",
    "        self.residual_block1 = ResidualBlock(4, 16)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "        \n",
    "        self.residual_block2 = ResidualBlock(16, 32)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "        \n",
    "        self.residual_block3 = ResidualBlock(32, 64)\n",
    "        self.adAvgPool3 = nn.AdaptiveAvgPool1d(112)\n",
    "        \n",
    "        # Activation and fully connected layers\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        # Calculate the input size for linear layers\n",
    "        # You might need to adjust this based on your specific input dimensions\n",
    "        self.linear1 = nn.Linear(14400, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Move channel dimension\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "        \n",
    "        # First residual block\n",
    "        x = self.residual_block1(x)\n",
    "        x = self.adAvgPool1(x)\n",
    "        \n",
    "        # Second residual block\n",
    "        x = self.residual_block2(x)\n",
    "        x = self.adAvgPool2(x)\n",
    "        \n",
    "        # Third residual block\n",
    "        x = self.residual_block3(x)\n",
    "        \n",
    "        # Flatten and fully connected layers\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier1(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier1, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "\n",
    "        self.padding2 = nn.CircularPad1d((1,2))\n",
    "        self.conv2 = nn.Conv1d(8, 32, kernel_size=4)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.padding3 = nn.CircularPad1d((1,2))\n",
    "        self.conv3 = nn.Conv1d(32, 128, kernel_size=4)\n",
    "        self.adAvgPool3 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.linear1 = nn.Linear(28800, 14400)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(14400, 7200)\n",
    "        self.act5 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "        x = self.adAvgPool1(x)\n",
    "\n",
    "        x = self.conv2(self.padding2(x))\n",
    "        x = self.adAvgPool2(x)\n",
    "        \n",
    "        x = self.conv3(self.padding3(x))\n",
    "        x = self.adAvgPool3(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.act5(x)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier2(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier2, self).__init__()\n",
    "        \n",
    "        # First convolutional layer\n",
    "        # Input: (batch_size, 1, 4, 900)\n",
    "        self.padding1 = nn.CircularPad2d((1, 2, 1, 1))\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 4), stride=1)\n",
    "        # Output: (batch_size, 8, 900, 4)\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        self.padding2 = nn.CircularPad2d((1, 2, 1, 1))\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 4), stride=1)\n",
    "        # Output: (batch_size, 16, 4, 900)\n",
    "        \n",
    "        # Third convolutional layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 4), stride=1, padding=(1, 0), padding_mode=\"circular\")\n",
    "        # Output: (batch_size, 32, 1, 900)\n",
    "        \n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear((32 * 1 * 900 ), (nClasses*2))\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        self.fc2 = nn.Linear((nClasses*2), nClasses)\n",
    "        \n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x,1)\n",
    "\n",
    "        # Convolutional layers\n",
    "        x = self.padding1(x)\n",
    "        x = self.relu(self.conv1(x))\n",
    "\n",
    "        x = self.padding2(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        \n",
    "        x = self.relu(self.conv3(x))\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.relu(self.fc1(self.dropout1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier3(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier3, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "\n",
    "        self.padding2 = nn.CircularPad1d((1,2))\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=4)\n",
    "\n",
    "        self.padding3 = nn.CircularPad1d((1,2))\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=4)\n",
    "\n",
    "        self.linear1 = nn.Linear(28800, 7200)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "        x = self.conv1(self.padding1(x))\n",
    "        x = self.conv2(self.padding2(x))        \n",
    "        x = self.conv3(self.padding3(x))\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier4(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier4, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 8, kernel_size=3)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "\n",
    "        self.padding2 = nn.CircularPad1d((1,2))\n",
    "        self.conv2 = nn.Conv1d(8, 32, kernel_size=3)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.padding3 = nn.CircularPad1d((1,2))\n",
    "        self.conv3 = nn.Conv1d(32, 128, kernel_size=3)\n",
    "        self.adAvgPool3 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.act4 = nn.GELU()\n",
    "\n",
    "        self.linear1 = nn.Linear(28800, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "        x = self.adAvgPool1(x)\n",
    "\n",
    "        x = self.conv2(self.padding2(x))\n",
    "        x = self.adAvgPool2(x)\n",
    "        \n",
    "        x = self.conv3(self.padding3(x))\n",
    "        x = self.adAvgPool3(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier5(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier5, self).__init__()\n",
    "        \n",
    "        # First convolutional layer\n",
    "        # Input: (batch_size, 1, 4, 900)\n",
    "        self.padding1 = nn.CircularPad2d((1, 2, 1, 1))\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 4), stride=1)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool2d(output_size=(450, 4))\n",
    "        # Output: (batch_size, 8, 450, 4)\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        self.padding2 = nn.CircularPad2d((1, 2, 1, 1))\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 4), stride=1)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool2d(output_size=(225, 4))\n",
    "        # Output: (batch_size, 16, 4, 900)\n",
    "        \n",
    "        # Third convolutional layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 4), stride=1, padding=(1, 0), padding_mode=\"circular\")\n",
    "        # Output: (batch_size, 32, 1, 900)\n",
    "        \n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear(64800, 7200)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        self.fc2 = nn.Linear(7200, nClasses)\n",
    "        \n",
    "        # Activation function\n",
    "        self.act = nn.GELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x,1)\n",
    "\n",
    "        # Convolutional layers\n",
    "        x1 = self.padding1(x)\n",
    "        x1 = self.act(self.conv1(x1))\n",
    "        # print(x1.shape)\n",
    "        x = self.adAvgPool1(x1)\n",
    "        # print(x1.shape)\n",
    "\n",
    "        x2 = self.padding2(x)\n",
    "        x2 = self.act(self.conv2(x2))\n",
    "        # print(x2.shape)\n",
    "        x = self.adAvgPool2(x2)\n",
    "        # print(x2.shape)\n",
    "        \n",
    "        x = self.act(self.conv3(x))\n",
    "        # print(x.shape)\n",
    "\n",
    "\n",
    "        # x = torch.cat([x, x1, x2], dim=1)\n",
    "        # print(\"cat\")\n",
    "        \n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        # print(x1.shape)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "        # print(x2.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = torch.cat([x,x1,x2], dim=1)\n",
    "        # print(x.shape)\n",
    "\n",
    "        # Flatten\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.act(self.fc1(self.dropout1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier5_1layer(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier5_1layer, self).__init__()\n",
    "        \n",
    "        # First convolutional layer\n",
    "        # Input: (batch_size, 1, 4, 900)\n",
    "        self.padding1 = nn.CircularPad2d((1, 2, 1, 1))\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 4), stride=1)\n",
    "        # Output: (batch_size, 8, 450, 4)\n",
    "        \n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear(115200, 7200)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        self.fc2 = nn.Linear(7200, nClasses)\n",
    "        \n",
    "        # Activation function\n",
    "        self.act = nn.GELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x,1)\n",
    "\n",
    "        # Convolutional layers\n",
    "        x = self.padding1(x)\n",
    "        x = self.act(self.conv1(x))\n",
    "        # print(x.shape)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.act(self.fc1(self.dropout1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier5_1layer64c(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier5_1layer64c, self).__init__()\n",
    "        \n",
    "        # First convolutional layer\n",
    "        # Input: (batch_size, 1, 4, 900)\n",
    "        self.padding1 = nn.CircularPad2d((1, 2, 1, 1))\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3, 4), stride=1)\n",
    "        # Output: (batch_size, 8, 450, 4)\n",
    "        \n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear(230400, 7200)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        self.fc2 = nn.Linear(7200, nClasses)\n",
    "        \n",
    "        # Activation function\n",
    "        self.act = nn.GELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x,1)\n",
    "\n",
    "        # Convolutional layers\n",
    "        x = self.padding1(x)\n",
    "        x = self.act(self.conv1(x))\n",
    "        # print(x.shape)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.act(self.fc1(self.dropout1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier5_1layerPooling(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier5_1layerPooling, self).__init__()\n",
    "        \n",
    "        # First convolutional layer\n",
    "        # Input: (batch_size, 1, 4, 900)\n",
    "        self.padding1 = nn.CircularPad2d((1, 2, 1, 1))\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 4), stride=1)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool2d(output_size=(450, 4))\n",
    "        # Output: (batch_size, 8, 450, 4)\n",
    "        \n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear(57600, 7200)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        self.fc2 = nn.Linear(7200, nClasses)\n",
    "        \n",
    "        # Activation function\n",
    "        self.act = nn.GELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x,1)\n",
    "\n",
    "        # Convolutional layers\n",
    "        x = self.padding1(x)\n",
    "        x = self.act(self.conv1(x))\n",
    "        # print(x.shape)\n",
    "        x = self.adAvgPool1(x)\n",
    "        # print(x1.shape)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.act(self.fc1(self.dropout1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier5_1layerPooling64c(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier5_1layerPooling64c, self).__init__()\n",
    "        \n",
    "        # First convolutional layer\n",
    "        # Input: (batch_size, 1, 4, 900)\n",
    "        self.padding1 = nn.CircularPad2d((1, 2, 1, 1))\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3, 4), stride=1)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool2d(output_size=(450, 4))\n",
    "        # Output: (batch_size, 8, 450, 4)\n",
    "        \n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear(115200, 7200)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        self.fc2 = nn.Linear(7200, nClasses)\n",
    "        \n",
    "        # Activation function\n",
    "        self.act = nn.GELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x,1)\n",
    "\n",
    "        # Convolutional layers\n",
    "        x = self.padding1(x)\n",
    "        x = self.act(self.conv1(x))\n",
    "        # print(x.shape)\n",
    "        x = self.adAvgPool1(x)\n",
    "        # print(x1.shape)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.act(self.fc1(self.dropout1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A test of a CNN Model\n",
    "# Input (1-Dimension 4-Channels)\n",
    "\n",
    "## Notes:\n",
    "#   - \n",
    "class SimpleCNNClassifier1(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimpleCNNClassifier1, self).__init__()\n",
    "\n",
    "        self.padding = nn.CircularPad1d((1,2))\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(4, 4, kernel_size=4, groups=4)\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        self.conv1_1 = nn.Conv1d(4, 8, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "        self.act1_1 = nn.ReLU()        \n",
    "        \n",
    "        self.conv2 = nn.Conv1d(12, 24, kernel_size=4)        \n",
    "        self.act2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(24, 32, kernel_size=4)        \n",
    "        self.act3 = nn.ReLU()\n",
    "\n",
    "        self.conv4 = nn.Conv1d(32, 64, kernel_size=4)        \n",
    "        self.act4 = nn.ReLU()        \n",
    "        \n",
    "        self.act5 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(57600, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        a = self.conv1(self.padding(x))\n",
    "        a = self.act1(a)        \n",
    "        # print(a.shape)\n",
    "        \n",
    "        b = self.conv1_1((x))\n",
    "        b = self.act1_1(b)\n",
    "        # print(b.shape)\n",
    "        \n",
    "        x = torch.cat([a,b], dim=1)\n",
    "        # print(x.shape)\n",
    "\n",
    "        \n",
    "        x = self.conv2(self.padding(x))\n",
    "        x = self.act2(x)        \n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.conv3(self.padding(x))\n",
    "        x = self.act3(x)        \n",
    "        # print(x.shape)\n",
    "        \n",
    "        x = self.conv4(self.padding(x))\n",
    "        x = self.act4(x)        \n",
    "        # print(x.shape)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        # print(x.shape)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        \n",
    "        x = self.act5(x)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [\n",
    "    # \"class\", \n",
    "    \"species\",\n",
    "    # \"family\", \n",
    "\n",
    "    \"genus\",\n",
    "    # \"order\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [\n",
    "    # 64,\n",
    "    # 128,\n",
    "    # 256,\n",
    "    # 512,\n",
    "    # 2048,\n",
    "    # 10000,\n",
    "    \"dynamic\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [\n",
    "    # 1,\n",
    "    # 2,\n",
    "    # 5,\n",
    "    # 20,\n",
    "    # 50,\n",
    "    # 100,\n",
    "    # 150,\n",
    "    # 200,\n",
    "    # 300,\n",
    "    500\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [\n",
    "    # SimplestCNNClassifier,\n",
    "    # SimpleCNNClassifier,\n",
    "    # SimpleCNNWithDropoutClassifier,\n",
    "    # BaseCNNClassifier,\n",
    "    # UnetBasedCNNClassifier,\n",
    "    # UnetBasedCNNWithDropoutClassifier,\n",
    "    # UnetBasedCNNWithDilationClassifier,\n",
    "    # UnetBasedCNNWithDropoutAndDilationClassifier,\n",
    "    SimplestCNNClassifier_3layers_Residual,\n",
    "    \n",
    "    SimplestCNNClassifier0,\n",
    "    # SimplestCNNClassifier1,\n",
    "    # SimplestCNNClassifier2,\n",
    "    # SimplestCNNClassifier3,\n",
    "    SimplestCNNClassifier5,\n",
    "    # SimpleCNNClassifier1,\n",
    "\n",
    "    # SimplestCNNClassifier0_1layer16,\n",
    "    # SimplestCNNClassifier0_1layerk4,\n",
    "    SimplestCNNClassifier0_1layerk2,\n",
    "\n",
    "    # SimplestCNNClassifier0_1layer,\n",
    "    SimplestCNNClassifier0_1layerPooling,\n",
    "    # SimplestCNNClassifier0_1layerGELU,\n",
    "    # SimplestCNNClassifier0_1layer64c,\n",
    "    # SimplestCNNClassifier0_1layer64cPooling,\n",
    "    SimplestCNNClassifier5_1layer,\n",
    "    # # SimplestCNNClassifier5_1layer64c,\n",
    "    # # SimplestCNNClassifier5_1layerPooling,\n",
    "    # # SimplestCNNClassifier5_1layerPooling64c,\n",
    "\n",
    "    SimplestCNNClassifier_2layers,\n",
    "    SimplestCNNClassifier_2layers_Residual,\n",
    "    # SimplestCNNClassifier_2layers_concat,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_functions = {\n",
    "    \"CrossEntropyLoss\":{\n",
    "        \"function\":nn.CrossEntropyLoss,\n",
    "        \"params\":{},\n",
    "        \"function_params\":{}\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [\n",
    "    # 1e-2,\n",
    "    # 5e-2,\n",
    "    1e-3,\n",
    "    # 5e-3,\n",
    "    # 1e-4,\n",
    "    # 5e-4,\n",
    "    # 1e-4,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [\n",
    "    \n",
    "    {\n",
    "        \"optim\":torch.optim.AdamW,\n",
    "        \"params\":{\n",
    "            \"weight_decay\":1.0,\n",
    "            \"amsgrad\":True\n",
    "        }\n",
    "    },\n",
    "    # {\n",
    "    #     \"optim\":torch.optim.AdamW,\n",
    "    #     \"params\":{\n",
    "    #         \"weight_decay\":1.0,\n",
    "    #         \"amsgrad\":False\n",
    "    #     }\n",
    "    # },\n",
    "    \n",
    "    # {\n",
    "    #     \"optim\":torch.optim.AdamW,\n",
    "    #     \"params\":{\n",
    "    #         \"weight_decay\":1e-1,\n",
    "    #         \"amsgrad\":True\n",
    "    #     }\n",
    "    # },\n",
    "\n",
    "    # {\n",
    "    #     \"optim\":torch.optim.AdamW,\n",
    "    #     \"params\":{\n",
    "    #         \"weight_decay\":1e-3,\n",
    "    #         \"amsgrad\":True\n",
    "    #     }\n",
    "    # },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparams = {\n",
    "    \"batch_size\": batch_sizes,\n",
    "    \"epochs\": epochs,\n",
    "    \"model\": models_list,\n",
    "    \"loss_function\": loss_functions,\n",
    "    \"learning_rate\": learning_rates,\n",
    "    \"optimizer\": optimizers    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Test(model, loss_fn, optimizer, epochs, learning_rate, batch_size, train_data,test_data,id=\"\"):\n",
    "    \n",
    "    print(\"Model: \\t\\t\\t\"+(model._get_name() if not model._get_name() == \"OptimizedModule\" else model.__dict__[\"_modules\"][\"_orig_mod\"].__class__.__name__))\n",
    "    print(\"  Loss Func.: \\t\\t\"+loss_fn._get_name())\n",
    "    print(\"  Optimizer: \\t\\t\"+type(optimizer).__name__)\n",
    "    print(\"  Epochs: \\t\\t\"+str(epochs))\n",
    "    print(\"  Learning Rate: \\t\"+str(learning_rate))\n",
    "\n",
    "    print(\"\\nModel Arch: \")\n",
    "    print(str(model))\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    # Test CUDA compatibility\n",
    "    if torch.cuda.get_device_capability() < (7, 0):\n",
    "        print(\"Exiting because torch.compile is not supported on this device.\")\n",
    "        import sys\n",
    "        sys.exit(0)\n",
    "\n",
    "\n",
    "    epochs_results = []\n",
    "    current = {\n",
    "        \"model\":(model._get_name() if not model._get_name() == \"OptimizedModule\" else model.__dict__[\"_modules\"][\"_orig_mod\"].__class__.__name__),\n",
    "        \"loss_function\":loss_fn._get_name(),\n",
    "        \"epoch\":None,\n",
    "        \"learning_rate\":learning_rate,\n",
    "        \"batch_size\":None,\n",
    "        \"train_size\":None,\n",
    "        \"test_size\":None,\n",
    "        \"optimizer\":type(optimizer).__name__,\n",
    "        \"train_acc\":None,\n",
    "        \"train_loss\":None,\n",
    "        \"test_acc\":None,\n",
    "        \"test_loss\":None,\n",
    "    }\n",
    "\n",
    "    # Prepare batch sizes to use\n",
    "    if batch_size == \"dynamic\":\n",
    "        bss = [10000, 10000, 64, 10000, 10000, 64, 10000]\n",
    "    else:\n",
    "        bss = [batch_size]\n",
    "    if len(bss) > epochs:\n",
    "        bss = bss[0:epochs]\n",
    "    print(\"Batch Sizes List: \"+str(bss))\n",
    "    batch_lim = int(epochs/len(bss))\n",
    "    \n",
    "    \n",
    "    t_start = time.time()\n",
    "    best = {\n",
    "        \"epoch\":0,\n",
    "        \"train_acc\":0,\n",
    "        \"train_loss\":10000000,\n",
    "        \"test_acc\":0,\n",
    "        \"test_loss\":10000000,\n",
    "    }\n",
    "    \n",
    "    train_loader = None\n",
    "    test_loader = None\n",
    "    \n",
    "    # Epochs\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "\n",
    "        # Create DataLoaders with current batch size\n",
    "        if epoch%batch_lim == 0 and len(bss) > 0:\n",
    "            if train_loader:\n",
    "                del train_loader\n",
    "            if test_loader:\n",
    "                del test_loader\n",
    "\n",
    "            batch_size = bss.pop(0)\n",
    "            train_loader, test_loader = loaders_generator(train_data, test_data, batch_size)\n",
    "\n",
    "        print(\"Batch Size: \"+str(batch_size))\n",
    "        \n",
    "        \n",
    "        # Train Phase\n",
    "\n",
    "        # Compile optimizer function\n",
    "        fn = torch.compile(optimizer.step)\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "\n",
    "        # Run train over the batches\n",
    "        for batch, (X, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            # Compute prediction and loss\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            fn()\n",
    "\n",
    "            # Update results\n",
    "            train_loss += loss.item()\n",
    "            train_acc += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "        # Train results\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(train_loader.dataset)\n",
    "        print(f\"Train Error: \\n Accuracy: {(100*train_acc):>0.1f}%, Avg loss: {train_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "        # Test Phase\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_loader:\n",
    "                pred = model(X)\n",
    "                test_loss += loss_fn(pred, y).item()\n",
    "                test_acc += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "        # Test results\n",
    "        test_loss /= len(test_loader)\n",
    "        test_acc /= len(test_loader.dataset)\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*test_acc):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "        # Update Results\n",
    "        if best[\"test_acc\"] < test_acc or (best[\"test_acc\"] == test_acc and best[\"train_acc\"] < train_acc):\n",
    "            best[\"epoch\"] = epoch+1\n",
    "            best[\"test_acc\"] = test_acc\n",
    "            best[\"test_loss\"] = test_loss\n",
    "            best[\"train_acc\"] = train_acc\n",
    "            best[\"train_loss\"] = train_loss\n",
    "\n",
    "            # If accuracy over 50%, export the current best treined model\n",
    "            if test_acc > 0.5:\n",
    "                torch.save(model.state_dict(), \"/media/stark/Models/Gustavo/\"+train_data.level+\"/\"+str(id)+\"_\"+current[\"model\"]+\".pth\")\n",
    "                                \n",
    "                    \n",
    "        current[\"epoch\"] = epoch+1\n",
    "        current[\"batch_size\"] = batch_size\n",
    "        current[\"train_size\"] = train_loader.dataset.__len__()\n",
    "        current[\"test_size\"] = test_loader.dataset.__len__()\n",
    "        current[\"train_acc\"] = train_acc\n",
    "        current[\"train_loss\"] = train_loss\n",
    "        current[\"test_acc\"] = test_acc\n",
    "        current[\"test_loss\"] = test_loss\n",
    "\n",
    "        epochs_results.append(current.copy())\n",
    "\n",
    "    # Save Train/Test iteration information\n",
    "    pd.DataFrame(epochs_results).to_csv(\"./results/epochs/\"+str(id)+\"__\"+current[\"model\"]+\"_train_test.csv\")\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"Best Epoch:{best['epoch']} \\n\\tAccuracy: {(100*best['test_acc']):>0.1f}%, Avg loss: {best['test_loss']:>8f} \\n\")\n",
    "    print(\"Train and Test execution time: \"+str(format(time.time()-t_start, '.4f'))+\"s\")\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Test(model, loss_fn, optimizer, epochs, learning_rate, batch_size, train_data,test_data,id=\"\"):\n",
    "    \n",
    "    print(\"Model: \\t\\t\\t\"+(model._get_name() if not model._get_name() == \"OptimizedModule\" else model.__dict__[\"_modules\"][\"_orig_mod\"].__class__.__name__))\n",
    "    print(\"  Loss Func.: \\t\\t\"+loss_fn._get_name())\n",
    "    print(\"  Optimizer: \\t\\t\"+type(optimizer).__name__)\n",
    "    print(\"  Epochs: \\t\\t\"+str(epochs))\n",
    "    print(\"  Learning Rate: \\t\"+str(learning_rate))\n",
    "\n",
    "    print(\"\\nModel Arch: \")\n",
    "    print(str(model))\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    # Test CUDA compatibility\n",
    "    if torch.cuda.get_device_capability() < (7, 0):\n",
    "        print(\"Exiting because torch.compile is not supported on this device.\")\n",
    "        import sys\n",
    "        sys.exit(0)\n",
    "\n",
    "\n",
    "    epochs_results = []\n",
    "    current = {\n",
    "        \"model\":(model._get_name() if not model._get_name() == \"OptimizedModule\" else model.__dict__[\"_modules\"][\"_orig_mod\"].__class__.__name__),\n",
    "        \"loss_function\":loss_fn._get_name(),\n",
    "        \"epoch\":None,\n",
    "        \"learning_rate\":learning_rate,\n",
    "        \"batch_size\":None,\n",
    "        \"train_size\":None,\n",
    "        \"test_size\":None,\n",
    "        \"optimizer\":type(optimizer).__name__,\n",
    "        \"train_acc\":None,\n",
    "        \"train_loss\":None,\n",
    "        \"test_acc\":None,\n",
    "        \"test_loss\":None,\n",
    "    }\n",
    "\n",
    "    # Prepare batch sizes to use\n",
    "    if batch_size == \"dynamic\":\n",
    "        bss = [10000, 10000, 10000, 10000, 128, 10000, 10000, 10000, 10000]\n",
    "    else:\n",
    "        bss = [batch_size]\n",
    "    if len(bss) > epochs:\n",
    "        bss = bss[0:epochs]\n",
    "    print(\"Batch Sizes List: \"+str(bss))\n",
    "    batch_lim = int(epochs/len(bss))\n",
    "    \n",
    "    \n",
    "    t_start = time.time()\n",
    "    best = {\n",
    "        \"epoch\":0,\n",
    "        \"train_acc\":0,\n",
    "        \"train_loss\":10000000,\n",
    "        \"test_acc\":0,\n",
    "        \"test_loss\":10000000,\n",
    "    }\n",
    "    \n",
    "    train_loader = None\n",
    "    test_loader = None\n",
    "    \n",
    "    \n",
    "    scaler = GradScaler(device=device)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=10,  # First restart\n",
    "        T_mult=2,  # Period multiplier\n",
    "        eta_min=1e-8,  # Minimum learning rate\n",
    "    )\n",
    "\n",
    "    # Epochs\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "\n",
    "        # Create DataLoaders with current batch size\n",
    "        if epoch%batch_lim == 0 and len(bss) > 0:\n",
    "            if train_loader:\n",
    "                del train_loader\n",
    "            if test_loader:\n",
    "                del test_loader\n",
    "\n",
    "            batch_size = bss.pop(0)\n",
    "            train_loader, test_loader = loaders_generator(train_data, test_data, batch_size)\n",
    "\n",
    "        print(\"Batch Size: \"+str(batch_size))\n",
    "        \n",
    "        \n",
    "        # Train Phase\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "\n",
    "        # Run train over the batches\n",
    "        optimizer.zero_grad()\n",
    "        for batch, (X, y) in enumerate(train_loader):\n",
    "            with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "                # Compute prediction and loss\n",
    "                pred = model(X)\n",
    "                loss = loss_fn(pred, y)\n",
    "                \n",
    "            # Backpropagation\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # Gradien clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            # Update the learning rate\n",
    "            scheduler.step(epoch + batch / len(train_loader))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Update results\n",
    "            train_loss += loss.item()\n",
    "            train_acc += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "        # Train results\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(train_loader.dataset)\n",
    "        print(\"Last Learning Rate: \"+str(scheduler.get_last_lr()[0]))\n",
    "        print(f\"Train Error: \\n Accuracy: {(100*train_acc):>0.1f}%, Avg loss: {train_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "        # Test Phase\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_loader:\n",
    "                pred = model(X)\n",
    "                test_loss += loss_fn(pred, y).item()\n",
    "                test_acc += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "        # Test results\n",
    "        test_loss /= len(test_loader)\n",
    "        test_acc /= len(test_loader.dataset)\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*test_acc):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "        # Update Results\n",
    "        if best[\"test_acc\"] < test_acc or (best[\"test_acc\"] == test_acc and best[\"train_acc\"] < train_acc):\n",
    "            best[\"epoch\"] = epoch+1\n",
    "            best[\"test_acc\"] = test_acc\n",
    "            best[\"test_loss\"] = test_loss\n",
    "            best[\"train_acc\"] = train_acc\n",
    "            best[\"train_loss\"] = train_loss\n",
    "\n",
    "            # If accuracy over 50%, export the current best treined model\n",
    "            if test_acc > 0.5:\n",
    "                torch.save(model.state_dict(), \"/media/stark/Models/Gustavo/\"+train_data.level+\"/\"+str(id)+\"_\"+current[\"model\"]+\".pth\")\n",
    "                                \n",
    "                    \n",
    "        current[\"epoch\"] = epoch+1\n",
    "        current[\"batch_size\"] = batch_size\n",
    "        current[\"learning_rate\"] = scheduler.get_last_lr()[0]\n",
    "        current[\"train_size\"] = train_loader.dataset.__len__()\n",
    "        current[\"test_size\"] = test_loader.dataset.__len__()\n",
    "        current[\"train_acc\"] = train_acc\n",
    "        current[\"train_loss\"] = train_loss\n",
    "        current[\"test_acc\"] = test_acc\n",
    "        current[\"test_loss\"] = test_loss\n",
    "\n",
    "        epochs_results.append(current.copy())\n",
    "\n",
    "    # Save Train/Test iteration information\n",
    "    pd.DataFrame(epochs_results).to_csv(\"./results/epochs/\"+str(id)+\"__\"+current[\"model\"]+\"_train_test.csv\")\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"Best Epoch:{best['epoch']} \\n\\tAccuracy: {(100*best['test_acc']):>0.1f}%, Avg loss: {best['test_loss']:>8f} \\n\")\n",
    "    print(\"Train and Test execution time: \"+str(format(time.time()-t_start, '.4f'))+\"s\")\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Global references\n",
    "_model_ = None\n",
    "_lossfunction_ = None\n",
    "_optimizer_ = None\n",
    "\n",
    "# Function to clean cache\n",
    "def clear():\n",
    "    global _model_, _lossfunction_, _optimizer_\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    torch.compiler.reset()\n",
    "    torch._dynamo.reset()\n",
    "\n",
    "    if _model_:\n",
    "        del _model_\n",
    "        _model_ = None\n",
    "    if _lossfunction_:\n",
    "        del _lossfunction_\n",
    "        _lossfunction_ = None\n",
    "    if _optimizer_:\n",
    "        del _optimizer_\n",
    "        _optimizer_ = None\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "results = []\n",
    "current = {}\n",
    "\n",
    "id = 0\n",
    "time_id = str(int(time.time()))\n",
    "print(\"Time ID: \"+str(time_id))\n",
    "\n",
    "for level in levels:\n",
    "    for augmentation in [True, False]:\n",
    "        clear()\n",
    "\n",
    "        # Load train and test datasets\n",
    "        train_data = pd.read_csv(\"../new_data/StratifiedSplit/\"+level+\"/train_dataset.csv\")#[0:1000]\n",
    "        test_data = pd.read_csv(\"../new_data/StratifiedSplit/\"+level+\"/test_dataset.csv\")#[0:1000]\n",
    "        print(level)\n",
    "        print(train_data.shape)\n",
    "        print(test_data.shape)\n",
    "\n",
    "        dataset = SequenceDataset(\n",
    "            train=train_data, \n",
    "            test=test_data, \n",
    "            level=level, \n",
    "            augmentation=augmentation)\n",
    "        \n",
    "        print(dataset.__len__())\n",
    "        print(dataset.test.__len__())\n",
    "\n",
    "\n",
    "        for batch_size in hiperparams[\"batch_size\"]:\n",
    "            for epochs in hiperparams[\"epochs\"]:\n",
    "                for model in hiperparams[\"model\"]:\n",
    "                    for loss_function_name, loss_function in hiperparams[\"loss_function\"].items():\n",
    "                        for learning_rate in hiperparams[\"learning_rate\"]:\n",
    "                            for optimizer in hiperparams[\"optimizer\"]:\n",
    "                                \n",
    "                                optim = optimizer[\"optim\"]\n",
    "                                optim_params = optimizer[\"params\"] if \"params\" in optimizer.keys() else {}\n",
    "\n",
    "                                current = {\n",
    "                                        \"id\": id,\n",
    "                                        \"start_time\":time.time(),\n",
    "                                        \"end_time\": None,\n",
    "                                        \"level\": level,\n",
    "                                        \"augmentation\": augmentation,\n",
    "                                        \"batch_size\": batch_size,\n",
    "                                        \"epochs\": epochs,\n",
    "                                        \"model\": model.__name__,\n",
    "                                        \"loss_function\": loss_function_name+\" (\"+str(loss_function[\"function\"])+\")\",\n",
    "                                        \"learning_rate\": learning_rate,\n",
    "                                        \"optimizer\": optim.__name__+\" (params: \"+str(optim_params)+\")\",\n",
    "                                        \"obs\": \"9:1\",\n",
    "                                        \"error\": None\n",
    "                                    }\n",
    "\n",
    "\n",
    "                                try:                                \n",
    "                                    clear()\n",
    "\n",
    "                                    # Change precision to improve model performance \n",
    "                                    torch.set_float32_matmul_precision('high')\n",
    "                                    \n",
    "                                    # Initialize a compiled model, loss function, and optimizer\n",
    "                                    _model_ = torch.compile(model(dataset.encoded_labels.shape[1]))\n",
    "                                    _lossfunction_ = loss_function[\"function\"](**{func:params[0](*params[1:]) for func,params in loss_function[\"function_params\"].items()})\n",
    "                                    _optimizer_ = optim(_model_.parameters(), lr=learning_rate, **optim_params)\n",
    "\n",
    "\n",
    "                                    # Runt Train-Test\n",
    "                                    result = Train_Test(\n",
    "                                        model=_model_,\n",
    "                                        loss_fn=_lossfunction_,\n",
    "                                        optimizer=_optimizer_,\n",
    "                                        epochs=epochs,\n",
    "                                        learning_rate=learning_rate,\n",
    "                                        batch_size=batch_size,\n",
    "                                        train_data=dataset,\n",
    "                                        test_data=dataset.get_test(),\n",
    "                                        id=time_id+\"_\"+str(id),\n",
    "                                        )\n",
    "                                        \n",
    "                                    current[\"end_time\"] = time.time()\n",
    "                                    current[\"best_epoch\"] = result[\"epoch\"]\n",
    "                                    current[\"train_acc_best_epoch\"] = result[\"train_acc\"]\n",
    "                                    current[\"train_loss_best_epoch\"] = result[\"train_loss\"]\n",
    "                                    current[\"test_acc_best_epoch\"] = result[\"test_acc\"]\n",
    "                                    current[\"test_loss_best_epoch\"] = result[\"test_loss\"]\n",
    "\n",
    "                                    clear()                                \n",
    "                                    \n",
    "                                except Exception as e:\n",
    "                                    print(e)\n",
    "                                    current[\"error\"] = str(e)\n",
    "                                \n",
    "                                # Save the results\n",
    "                                results.append(current)\n",
    "                                pd.DataFrame(results).to_csv(\"./results/summarized/\"+str(time_id)+\"_models_train_test_\"+str(len(results))+\".csv\")\n",
    "                                \n",
    "                                id = id+1\n",
    "\n",
    "clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>train_acc_best_epoch</th>\n",
       "      <th>test_acc_best_epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier_2layers_Residual</td>\n",
       "      <td>0.001</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.997202</td>\n",
       "      <td>0.950846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier_2layers_Residual</td>\n",
       "      <td>0.001</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.998659</td>\n",
       "      <td>0.950279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier_2layers_Residual</td>\n",
       "      <td>0.001</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.998910</td>\n",
       "      <td>0.949632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier_2layers_Residual</td>\n",
       "      <td>0.001</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.997113</td>\n",
       "      <td>0.946473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier_2layers</td>\n",
       "      <td>0.001</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.999199</td>\n",
       "      <td>0.945421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier_2layers</td>\n",
       "      <td>0.001</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.999307</td>\n",
       "      <td>0.944935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier_2layers</td>\n",
       "      <td>0.001</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.999100</td>\n",
       "      <td>0.944773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier_2layers</td>\n",
       "      <td>0.001</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.999468</td>\n",
       "      <td>0.943882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.943153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier_2layers_concat</td>\n",
       "      <td>0.001</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.999118</td>\n",
       "      <td>0.942424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier_2layers_concat</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.999326</td>\n",
       "      <td>0.942182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier_2layers_concat</td>\n",
       "      <td>0.001</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.999136</td>\n",
       "      <td>0.941777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>291.0</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.940643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>150</td>\n",
       "      <td>SimplestCNNClassifier_2layers_concat</td>\n",
       "      <td>0.001</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.998570</td>\n",
       "      <td>0.940562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.939752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.935946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>0.929306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier0_1layerPooling</td>\n",
       "      <td>0.001</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>0.909142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier0_1layerPooling</td>\n",
       "      <td>0.001</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.908090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier0_1layer64cPooling</td>\n",
       "      <td>0.001</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.907604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>SimplestCNNClassifier0_1layerPooling</td>\n",
       "      <td>0.001</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.902583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>248.0</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.899911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>SimplestCNNClassifier0_1layer64cPooling</td>\n",
       "      <td>0.001</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.999730</td>\n",
       "      <td>0.894809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>class</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>SimplestCNNClassifier5_1layerPooling</td>\n",
       "      <td>0.001</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>0.887440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier0_1layerk4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>0.875941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier0_1layerGELU</td>\n",
       "      <td>0.001</td>\n",
       "      <td>279.0</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>0.871407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier0_1layer</td>\n",
       "      <td>0.001</td>\n",
       "      <td>276.0</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.869625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier0_1layer</td>\n",
       "      <td>0.001</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.868410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier0_1layer16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>237.0</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.867844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier0_1layer64c</td>\n",
       "      <td>0.001</td>\n",
       "      <td>298.0</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.867196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier0_1layer16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>262.0</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.867034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier0_1layerk4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.865495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier0_1layerk2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.862661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>300</td>\n",
       "      <td>SimplestCNNClassifier0_1layerk2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.857964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>class</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>SimplestCNNClassifier5_1layer</td>\n",
       "      <td>0.001</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.856345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>SimplestCNNClassifier0_1layer</td>\n",
       "      <td>0.001</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.999811</td>\n",
       "      <td>0.846708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>SimplestCNNClassifier0_1layer64c</td>\n",
       "      <td>0.001</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.999748</td>\n",
       "      <td>0.846627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    level batch_size  epochs                                    model  \\\n",
       "id                                                                      \n",
       "8   class    dynamic     150   SimplestCNNClassifier_2layers_Residual   \n",
       "9   class    dynamic     150   SimplestCNNClassifier_2layers_Residual   \n",
       "3   class    dynamic     150   SimplestCNNClassifier_2layers_Residual   \n",
       "2   class    dynamic     150   SimplestCNNClassifier_2layers_Residual   \n",
       "6   class    dynamic     150            SimplestCNNClassifier_2layers   \n",
       "0   class    dynamic     150            SimplestCNNClassifier_2layers   \n",
       "7   class    dynamic     150            SimplestCNNClassifier_2layers   \n",
       "1   class    dynamic     150            SimplestCNNClassifier_2layers   \n",
       "0   class    dynamic     300                   SimplestCNNClassifier0   \n",
       "10  class    dynamic     150     SimplestCNNClassifier_2layers_concat   \n",
       "4   class    dynamic     150     SimplestCNNClassifier_2layers_concat   \n",
       "11  class    dynamic     150     SimplestCNNClassifier_2layers_concat   \n",
       "4   class    dynamic     300                   SimplestCNNClassifier5   \n",
       "5   class    dynamic     150     SimplestCNNClassifier_2layers_concat   \n",
       "2   class    dynamic     300                   SimplestCNNClassifier1   \n",
       "3   class    dynamic     300                   SimplestCNNClassifier1   \n",
       "1   class    dynamic     300                   SimplestCNNClassifier0   \n",
       "4   class    dynamic     300     SimplestCNNClassifier0_1layerPooling   \n",
       "12  class    dynamic     300     SimplestCNNClassifier0_1layerPooling   \n",
       "7   class    dynamic     300  SimplestCNNClassifier0_1layer64cPooling   \n",
       "1   class      10000     200     SimplestCNNClassifier0_1layerPooling   \n",
       "5   class    dynamic     300                   SimplestCNNClassifier5   \n",
       "4   class      10000     200  SimplestCNNClassifier0_1layer64cPooling   \n",
       "7   class      10000     200     SimplestCNNClassifier5_1layerPooling   \n",
       "1   class    dynamic     300          SimplestCNNClassifier0_1layerk4   \n",
       "5   class    dynamic     300        SimplestCNNClassifier0_1layerGELU   \n",
       "11  class    dynamic     300            SimplestCNNClassifier0_1layer   \n",
       "3   class    dynamic     300            SimplestCNNClassifier0_1layer   \n",
       "0   class    dynamic     300          SimplestCNNClassifier0_1layer16   \n",
       "6   class    dynamic     300         SimplestCNNClassifier0_1layer64c   \n",
       "8   class    dynamic     300          SimplestCNNClassifier0_1layer16   \n",
       "9   class    dynamic     300          SimplestCNNClassifier0_1layerk4   \n",
       "10  class    dynamic     300          SimplestCNNClassifier0_1layerk2   \n",
       "2   class    dynamic     300          SimplestCNNClassifier0_1layerk2   \n",
       "5   class      10000     200            SimplestCNNClassifier5_1layer   \n",
       "0   class      10000     200            SimplestCNNClassifier0_1layer   \n",
       "3   class      10000     200         SimplestCNNClassifier0_1layer64c   \n",
       "\n",
       "    learning_rate  best_epoch  train_acc_best_epoch  test_acc_best_epoch  \n",
       "id                                                                        \n",
       "8           0.001       141.0              0.997202             0.950846  \n",
       "9           0.001       148.0              0.998659             0.950279  \n",
       "3           0.001       134.0              0.998910             0.949632  \n",
       "2           0.001       129.0              0.997113             0.946473  \n",
       "6           0.001       119.0              0.999199             0.945421  \n",
       "0           0.001       109.0              0.999307             0.944935  \n",
       "7           0.001        99.0              0.999100             0.944773  \n",
       "1           0.001       101.0              0.999468             0.943882  \n",
       "0           0.001       210.0              0.999962             0.943153  \n",
       "10          0.001       104.0              0.999118             0.942424  \n",
       "4           0.001       100.0              0.999326             0.942182  \n",
       "11          0.001        96.0              0.999136             0.941777  \n",
       "4           0.001       291.0              0.999929             0.940643  \n",
       "5           0.001        87.0              0.998570             0.940562  \n",
       "2           0.001       198.0              0.999942             0.939752  \n",
       "3           0.001       189.0              0.999981             0.935946  \n",
       "1           0.001       112.0              0.999788             0.929306  \n",
       "4           0.001       258.0              0.999910             0.909142  \n",
       "12          0.001       140.0              0.999847             0.908090  \n",
       "7           0.001       146.0              0.999942             0.907604  \n",
       "1           0.001       172.0              0.999820             0.902583  \n",
       "5           0.001       248.0              0.999929             0.899911  \n",
       "4           0.001       175.0              0.999730             0.894809  \n",
       "7           0.001       195.0              0.999838             0.887440  \n",
       "1           0.001       240.0              0.999910             0.875941  \n",
       "5           0.001       279.0              0.999910             0.871407  \n",
       "11          0.001       276.0              0.999892             0.869625  \n",
       "3           0.001       284.0              0.999904             0.868410  \n",
       "0           0.001       237.0              0.999897             0.867844  \n",
       "6           0.001       298.0              0.999929             0.867196  \n",
       "8           0.001       262.0              0.999874             0.867034  \n",
       "9           0.001       263.0              0.999874             0.865495  \n",
       "10          0.001       274.0              0.999892             0.862661  \n",
       "2           0.001       263.0              0.999904             0.857964  \n",
       "5           0.001       114.0              0.999892             0.856345  \n",
       "0           0.001       153.0              0.999811             0.846708  \n",
       "3           0.001       169.0              0.999748             0.846627  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = [\n",
    "pd.read_csv(\"/home/stark/Members/Gustavo/Masters/CNN/results/summarized/1732584865_models_train_test_13.csv\", index_col=\"id\", usecols=['id','level', 'batch_size', 'epochs','model', 'learning_rate', 'error', 'best_epoch', 'train_acc_best_epoch','test_acc_best_epoch']),\n",
    "pd.read_csv(\"/home/stark/Members/Gustavo/Masters/CNN/results/summarized/1732571273_models_train_test_9.csv\", index_col=\"id\", usecols=['id','level', 'batch_size', 'epochs','model', 'learning_rate', 'error', 'best_epoch', 'train_acc_best_epoch','test_acc_best_epoch']),\n",
    "pd.read_csv(\"/home/stark/Members/Gustavo/Masters/CNN/results/summarized/1732649724_models_train_test_12.csv\", index_col=\"id\", usecols=['id','level', 'batch_size', 'epochs','model', 'learning_rate', 'error', 'best_epoch', 'train_acc_best_epoch','test_acc_best_epoch']),\n",
    "pd.read_csv(\"/home/stark/Members/Gustavo/Masters/CNN/results/summarized/1732491598_models_train_test_6.csv\", index_col=\"id\", usecols=['id','level', 'batch_size', 'epochs','model', 'learning_rate', 'error', 'best_epoch', 'train_acc_best_epoch','test_acc_best_epoch']),\n",
    "]\n",
    "\n",
    "rs = pd.concat(rs)\n",
    "rs.loc[rs[\"error\"].isna()].drop(columns=[\"error\"]).sort_values(by=[\"level\", \"test_acc_best_epoch\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>level</th>\n",
    "      <th>batch_size</th>\n",
    "      <th>epochs</th>\n",
    "      <th>model</th>\n",
    "      <th>learning_rate</th>\n",
    "      <th>best_epoch</th>\n",
    "      <th>train_acc_best_epoch</th>\n",
    "      <th>test_acc_best_epoch</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>id</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>8</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>150</td>\n",
    "      <td>SimplestCNNClassifier_2layers_Residual</td>\n",
    "      <td>0.001</td>\n",
    "      <td>141.0</td>\n",
    "      <td>0.997202</td>\n",
    "      <td>0.950846</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>9</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>150</td>\n",
    "      <td>SimplestCNNClassifier_2layers_Residual</td>\n",
    "      <td>0.001</td>\n",
    "      <td>148.0</td>\n",
    "      <td>0.998659</td>\n",
    "      <td>0.950279</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>150</td>\n",
    "      <td>SimplestCNNClassifier_2layers_Residual</td>\n",
    "      <td>0.001</td>\n",
    "      <td>134.0</td>\n",
    "      <td>0.998910</td>\n",
    "      <td>0.949632</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>150</td>\n",
    "      <td>SimplestCNNClassifier_2layers_Residual</td>\n",
    "      <td>0.001</td>\n",
    "      <td>129.0</td>\n",
    "      <td>0.997113</td>\n",
    "      <td>0.946473</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>6</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>150</td>\n",
    "      <td>SimplestCNNClassifier_2layers</td>\n",
    "      <td>0.001</td>\n",
    "      <td>119.0</td>\n",
    "      <td>0.999199</td>\n",
    "      <td>0.945421</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>150</td>\n",
    "      <td>SimplestCNNClassifier_2layers</td>\n",
    "      <td>0.001</td>\n",
    "      <td>109.0</td>\n",
    "      <td>0.999307</td>\n",
    "      <td>0.944935</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>7</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>150</td>\n",
    "      <td>SimplestCNNClassifier_2layers</td>\n",
    "      <td>0.001</td>\n",
    "      <td>99.0</td>\n",
    "      <td>0.999100</td>\n",
    "      <td>0.944773</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>150</td>\n",
    "      <td>SimplestCNNClassifier_2layers</td>\n",
    "      <td>0.001</td>\n",
    "      <td>101.0</td>\n",
    "      <td>0.999468</td>\n",
    "      <td>0.943882</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier0</td>\n",
    "      <td>0.001</td>\n",
    "      <td>210.0</td>\n",
    "      <td>0.999962</td>\n",
    "      <td>0.943153</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>10</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>150</td>\n",
    "      <td>SimplestCNNClassifier_2layers_concat</td>\n",
    "      <td>0.001</td>\n",
    "      <td>104.0</td>\n",
    "      <td>0.999118</td>\n",
    "      <td>0.942424</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>150</td>\n",
    "      <td>SimplestCNNClassifier_2layers_concat</td>\n",
    "      <td>0.001</td>\n",
    "      <td>100.0</td>\n",
    "      <td>0.999326</td>\n",
    "      <td>0.942182</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>11</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>150</td>\n",
    "      <td>SimplestCNNClassifier_2layers_concat</td>\n",
    "      <td>0.001</td>\n",
    "      <td>96.0</td>\n",
    "      <td>0.999136</td>\n",
    "      <td>0.941777</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier5</td>\n",
    "      <td>0.001</td>\n",
    "      <td>291.0</td>\n",
    "      <td>0.999929</td>\n",
    "      <td>0.940643</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>150</td>\n",
    "      <td>SimplestCNNClassifier_2layers_concat</td>\n",
    "      <td>0.001</td>\n",
    "      <td>87.0</td>\n",
    "      <td>0.998570</td>\n",
    "      <td>0.940562</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier1</td>\n",
    "      <td>0.001</td>\n",
    "      <td>198.0</td>\n",
    "      <td>0.999942</td>\n",
    "      <td>0.939752</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier1</td>\n",
    "      <td>0.001</td>\n",
    "      <td>189.0</td>\n",
    "      <td>0.999981</td>\n",
    "      <td>0.935946</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier0</td>\n",
    "      <td>0.001</td>\n",
    "      <td>112.0</td>\n",
    "      <td>0.999788</td>\n",
    "      <td>0.929306</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier0_1layerPooling</td>\n",
    "      <td>0.001</td>\n",
    "      <td>258.0</td>\n",
    "      <td>0.999910</td>\n",
    "      <td>0.909142</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>12</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier0_1layerPooling</td>\n",
    "      <td>0.001</td>\n",
    "      <td>140.0</td>\n",
    "      <td>0.999847</td>\n",
    "      <td>0.908090</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>7</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier0_1layer64cPooling</td>\n",
    "      <td>0.001</td>\n",
    "      <td>146.0</td>\n",
    "      <td>0.999942</td>\n",
    "      <td>0.907604</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>class</td>\n",
    "      <td>10000</td>\n",
    "      <td>200</td>\n",
    "      <td>SimplestCNNClassifier0_1layerPooling</td>\n",
    "      <td>0.001</td>\n",
    "      <td>172.0</td>\n",
    "      <td>0.999820</td>\n",
    "      <td>0.902583</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier5</td>\n",
    "      <td>0.001</td>\n",
    "      <td>248.0</td>\n",
    "      <td>0.999929</td>\n",
    "      <td>0.899911</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>class</td>\n",
    "      <td>10000</td>\n",
    "      <td>200</td>\n",
    "      <td>SimplestCNNClassifier0_1layer64cPooling</td>\n",
    "      <td>0.001</td>\n",
    "      <td>175.0</td>\n",
    "      <td>0.999730</td>\n",
    "      <td>0.894809</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>7</th>\n",
    "      <td>class</td>\n",
    "      <td>10000</td>\n",
    "      <td>200</td>\n",
    "      <td>SimplestCNNClassifier5_1layerPooling</td>\n",
    "      <td>0.001</td>\n",
    "      <td>195.0</td>\n",
    "      <td>0.999838</td>\n",
    "      <td>0.887440</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier0_1layerk4</td>\n",
    "      <td>0.001</td>\n",
    "      <td>240.0</td>\n",
    "      <td>0.999910</td>\n",
    "      <td>0.875941</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier0_1layerGELU</td>\n",
    "      <td>0.001</td>\n",
    "      <td>279.0</td>\n",
    "      <td>0.999910</td>\n",
    "      <td>0.871407</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>11</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier0_1layer</td>\n",
    "      <td>0.001</td>\n",
    "      <td>276.0</td>\n",
    "      <td>0.999892</td>\n",
    "      <td>0.869625</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier0_1layer</td>\n",
    "      <td>0.001</td>\n",
    "      <td>284.0</td>\n",
    "      <td>0.999904</td>\n",
    "      <td>0.868410</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier0_1layer16</td>\n",
    "      <td>0.001</td>\n",
    "      <td>237.0</td>\n",
    "      <td>0.999897</td>\n",
    "      <td>0.867844</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>6</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier0_1layer64c</td>\n",
    "      <td>0.001</td>\n",
    "      <td>298.0</td>\n",
    "      <td>0.999929</td>\n",
    "      <td>0.867196</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>8</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier0_1layer16</td>\n",
    "      <td>0.001</td>\n",
    "      <td>262.0</td>\n",
    "      <td>0.999874</td>\n",
    "      <td>0.867034</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>9</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier0_1layerk4</td>\n",
    "      <td>0.001</td>\n",
    "      <td>263.0</td>\n",
    "      <td>0.999874</td>\n",
    "      <td>0.865495</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>10</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier0_1layerk2</td>\n",
    "      <td>0.001</td>\n",
    "      <td>274.0</td>\n",
    "      <td>0.999892</td>\n",
    "      <td>0.862661</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>class</td>\n",
    "      <td>dynamic</td>\n",
    "      <td>300</td>\n",
    "      <td>SimplestCNNClassifier0_1layerk2</td>\n",
    "      <td>0.001</td>\n",
    "      <td>263.0</td>\n",
    "      <td>0.999904</td>\n",
    "      <td>0.857964</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>class</td>\n",
    "      <td>10000</td>\n",
    "      <td>200</td>\n",
    "      <td>SimplestCNNClassifier5_1layer</td>\n",
    "      <td>0.001</td>\n",
    "      <td>114.0</td>\n",
    "      <td>0.999892</td>\n",
    "      <td>0.856345</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>class</td>\n",
    "      <td>10000</td>\n",
    "      <td>200</td>\n",
    "      <td>SimplestCNNClassifier0_1layer</td>\n",
    "      <td>0.001</td>\n",
    "      <td>153.0</td>\n",
    "      <td>0.999811</td>\n",
    "      <td>0.846708</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>class</td>\n",
    "      <td>10000</td>\n",
    "      <td>200</td>\n",
    "      <td>SimplestCNNClassifier0_1layer64c</td>\n",
    "      <td>0.001</td>\n",
    "      <td>169.0</td>\n",
    "      <td>0.999748</td>\n",
    "      <td>0.846627</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gustavo_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
