{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "dtype = torch.float\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "torch.get_default_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_map = {\n",
    "    \"A\":[1.0, 0.0, 0.0, 0.0],\n",
    "    \"T\":[0.0, 1.0, 0.0, 0.0],\n",
    "    \"G\":[0.0, 0.0, 1.0, 0.0],\n",
    "    \"C\":[0.0, 0.0, 0.0, 1.0],\n",
    "\n",
    "    'W':[0.5, 0.5, 0.0, 0.0],\n",
    "    'S':[0.0, 0.0, 0.5, 0.5],\n",
    "    'M':[0.5, 0.0, 0.0, 0.5],\n",
    "    'K':[0.0, 0.5, 0.5, 0.0],\n",
    "    'R':[0.5, 0.0, 0.5, 0.0],\n",
    "    'Y':[0.0, 0.5, 0.0, 0.5],\n",
    "    \n",
    "    'B':[0.0, 0.3, 0.3, 0.3],\n",
    "    'D':[0.3, 0.3, 0.3, 0.0],\n",
    "    'H':[0.3, 0.3, 0.0, 0.3],\n",
    "    'V':[0.3, 0.0, 0.3, 0.3],\n",
    "\n",
    "    'N':[0.25, 0.25, 0.25, 0.25],\n",
    "}\n",
    "\n",
    "def encode_sequence(sequence):\n",
    "    encoded_seq = []\n",
    "\n",
    "    for base in sequence:\n",
    "        encoded_seq.append(base_map[base])\n",
    "    \n",
    "    return torch.tensor(encoded_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch dataset object to load Sequences and Classification Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, train, test, level):\n",
    "\n",
    "        self.classes = pd.concat([train[level], test[level]]).unique().tolist()\n",
    "        self.classes.sort()\n",
    "        self.level = level\n",
    "        self.labels = train[level]\n",
    "        self.encoded_labels = SequenceDataset.__encoded_labels__(self.classes, self.labels)\n",
    "        self.sequences = SequenceDataset.__sequences__(train)\n",
    "\n",
    "        self.test = SequenceDatasetTest(\n",
    "            labels = test[level],\n",
    "            classes = self.classes,\n",
    "            encoded_labels = SequenceDataset.__encoded_labels__(self.classes, test[level]),\n",
    "            sequences = SequenceDataset.__sequences__(test)\n",
    "            )\n",
    "\n",
    "    def __encoded_labels__(classes, labels):\n",
    "        return torch.nn.functional.one_hot(torch.tensor([classes.index(l) for l in labels]), len(classes)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    def __sequences__(ds):\n",
    "        sequences = []\n",
    "        for _, row in ds.iterrows():\n",
    "            sequences.append(encode_sequence(row[\"truncated_sequence\"]))        \n",
    "        return torch.stack(sequences, dim=0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return   self.sequences[idx], self.encoded_labels[idx]\n",
    "    \n",
    "    def __getitems__(self, ids):\n",
    "        idx = torch.tensor(ids, device=torch.device('cuda:0'))\n",
    "        return   list(zip(torch.index_select(self.sequences, 0, idx), torch.index_select(self.encoded_labels, 0, idx)))\n",
    "    \n",
    "    def get_test(self):\n",
    "        return self.test\n",
    "\n",
    "class SequenceDatasetTest(SequenceDataset):    \n",
    "    def __init__(self, labels, classes, encoded_labels, sequences):\n",
    "        self.labels = labels\n",
    "        self.classes = classes\n",
    "        self.encoded_labels = encoded_labels\n",
    "        self.sequences = sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate PyTorch DataLoader objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaders_generator(ds_train, ds_test, bs = 128):\n",
    "    train_loader = DataLoader(ds_train, batch_size=bs, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "    test_loader = DataLoader(ds_test, batch_size=bs, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple CNN Model with 3 Conv1d layers and 2 fully connected layers\n",
    "# Input (1-Dimension 4-Channels)\n",
    "\n",
    "## Notes:\n",
    "#   - Bad fully connected size\n",
    "#   - Too much VRAM\n",
    "class SimplestCNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "\n",
    "        self.padding2 = nn.CircularPad1d((1,2))\n",
    "        self.conv2 = nn.Conv1d(8, 32, kernel_size=4)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.padding3 = nn.CircularPad1d((1,2))\n",
    "        self.conv3 = nn.Conv1d(32, 128, kernel_size=4)\n",
    "        self.adAvgPool3 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(28800, 28800*2)\n",
    "        self.linear2 = nn.Linear(28800*2, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "        x = self.adAvgPool1(x)\n",
    "\n",
    "        x = self.conv2(self.padding2(x))\n",
    "        x = self.adAvgPool2(x)\n",
    "        \n",
    "        x = self.conv3(self.padding3(x))\n",
    "        x = self.adAvgPool3(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A test of a CNN Model with 3 different Conv1d layers concatenated and 2 fully connected layers\n",
    "# Input (1-Dimension 4-Channels)\n",
    "\n",
    "## Notes:\n",
    "#   - \n",
    "class SimpleCNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimpleCNNClassifier, self).__init__()\n",
    "\n",
    "        self.padding = nn.CircularPad1d((1,2))\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(4, 4, kernel_size=4, groups=4)\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(4, 4, kernel_size=4)        \n",
    "        self.act2 = nn.ReLU()\n",
    "        \n",
    "        self.act3 = nn.ReLU()        \n",
    "        self.conv3 = nn.Conv1d(4, 8, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "        \n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(14400, 7200)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "        a = self.conv1(self.padding(x))\n",
    "        a = self.act1(a)        \n",
    "        \n",
    "        b = self.conv2(self.padding(x))\n",
    "        b = self.act2(b)\n",
    "        \n",
    "        c = self.conv3(x)\n",
    "        c = self.act3(c)\n",
    "        \n",
    "        x = torch.flatten(torch.cat([a,b,c], dim=1), 1)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        \n",
    "        x = self.act4(x)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A test of a CNN Model with 3 different Conv1d layers concatenated, 2 fully connected layers, and dropouts\n",
    "# Input (1-Dimension 4-Channels)\n",
    "\n",
    "## Notes:\n",
    "#   - \n",
    "class SimpleCNNWithDropoutClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimpleCNNWithDropoutClassifier, self).__init__()\n",
    "\n",
    "        self.padding = nn.CircularPad1d((1,2))\n",
    "\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.conv1 = nn.Conv1d(4, 4, kernel_size=4, groups=4)\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(4, 4, kernel_size=4)\n",
    "        self.act2 = nn.ReLU()\n",
    "        \n",
    "        self.act3 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(4, 8, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.linear1 = nn.Linear(14400, 7200)\n",
    "\n",
    "        self.dropout3 = nn.Dropout(p=0.2)\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "        x = self.dropout1(x)\n",
    "        a = self.conv1(self.padding(x))\n",
    "        a = self.act1(a)\n",
    "        \n",
    "        b = self.conv2(self.padding(x))\n",
    "        b = self.act2(b)\n",
    "        \n",
    "        c = self.conv3(x)\n",
    "        c = self.act3(c)\n",
    "        \n",
    "        x = torch.flatten(torch.cat([a,b,c], dim=1), 1)\n",
    "        \n",
    "        x = self.dropout2(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act4(x)\n",
    "        \n",
    "        x = self.dropout3(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A CNN Model with 2 different Conv1d layers concatenated, 2 fully connected layers\n",
    "# Input (1-Dimension 4-Channels)\n",
    "\n",
    "## Notes:\n",
    "#   - Miss sequential Conv layers\n",
    "class BaseCNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(BaseCNNClassifier, self).__init__()\n",
    "\n",
    "        self.conv1_1 = nn.Conv1d(1, 4, kernel_size=4)\n",
    "        self.conv1_2 = nn.Conv1d(1, 4, kernel_size=4, dilation=2)\n",
    "        self.avgPool = nn.AvgPool1d(4, stride=2)\n",
    "        \n",
    "        self.padding = nn.CircularPad1d((1,2))\n",
    "        \n",
    "        self.act1 = nn.ReLU()\n",
    "        self.act2 = nn.ReLU()\n",
    "\n",
    "        self.linear1 = nn.Linear(14392, 14392)\n",
    "        self.linear2 = nn.Linear(14392, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.unsqueeze(torch.flatten(x, start_dim=1), 1)\n",
    "        x = self.padding(x)\n",
    "        \n",
    "        x_1_1 = self.conv1_1(x)\n",
    "        x_1_2 = self.conv1_2(self.padding(x))      \n",
    "\n",
    "        x = torch.cat([x_1_1, x_1_2], dim=1)\n",
    "        x = self.avgPool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.act1(x)\n",
    "        x = self.linear1(x)\n",
    "        \n",
    "        x = self.act2(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A UNet Model with 2 encode+decode levels and 2 fully connected layers\n",
    "# Input (1-Dimension 4-Channels)\n",
    "\n",
    "## Notes:\n",
    "#   - \n",
    "class UnetBasedCNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(UnetBasedCNNClassifier, self).__init__()\n",
    "\n",
    "        # First Encode Level\n",
    "        self.padding_e_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.act_e_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_e_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_2 = nn.Conv1d(8, 8, kernel_size=4)\n",
    "        self.act_e_1_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_1_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "\n",
    "        # Second Encode Level        \n",
    "        self.padding_e_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_1 = nn.Conv1d(8, 16, kernel_size=4)\n",
    "        self.act_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_e_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_e_2_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_2_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "        \n",
    "        # Transition Level\n",
    "        self.padding_t_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_1 = nn.Conv1d(16, 32, kernel_size = 4)\n",
    "        self.act_t_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_t_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_2 = nn.Conv1d(32, 32, kernel_size = 4)\n",
    "        self.act_t_1_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # First Decode Level\n",
    "        self.upconv_1_1 = nn.ConvTranspose1d(32, 16, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_1 = nn.Conv1d(32, 16, kernel_size=4)\n",
    "        self.act_d_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_d_1_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # Second Decode Level\n",
    "        self.upconv_2_1 = nn.ConvTranspose1d(16, 8, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_1 = nn.Conv1d(16, 8, kernel_size=4)\n",
    "        self.act_d_2_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_2 = nn.Conv1d(8, 8, kernel_size=4)\n",
    "        self.act_d_2_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # Output Level\n",
    "        self.conv_out_1 = nn.Conv1d(8, nClasses, kernel_size=1)\n",
    "        \n",
    "        self.linear_out_1 = nn.Linear(7200, 14400)\n",
    "        self.act_out_1 = nn.ReLU()\n",
    "        self.linear_out_2 = nn.Linear(14400, nClasses)\n",
    "        self.act_out_2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.reshape(x.shape[0],4,-1)              # Reshape X shape: torch.Size([3, 4, 900])\n",
    "\n",
    "        # Encoder 1\n",
    "        x_e_1 = self.padding_e_1_1(x)               # Padding X shape: torch.Size([3, 4, 900])\n",
    "        x_e_1 = self.conv_e_1_1(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        x_e_1 = self.act_e_1_1(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        \n",
    "        x_e_1 = self.padding_e_1_2(x_e_1)           # Padding X shape: torch.Size([3, 8, 903])\n",
    "        x_e_1 = self.conv_e_1_2(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        x_e_1 = self.act_e_1_2(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        \n",
    "        x_e_p_1 = self.avgPool_e_1_1(x_e_1)         # Pool X shape: torch.Size([3, 8, 450])\n",
    "\n",
    "\n",
    "        # Encoder 2\n",
    "        x_e_2 = self.padding_e_2_1(x_e_p_1)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_e_2 = self.conv_e_2_1(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_1(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "        \n",
    "        x_e_2 = self.padding_e_2_2(x_e_2)           # Padding X shape: torch.Size([3, 16, 453])\n",
    "        x_e_2 = self.conv_e_2_2(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_2(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "\n",
    "        x_e_p_2 = self.avgPool_e_2_1(x_e_2)         # Pool X shape: torch.Size([3, 16, 225])\n",
    "\n",
    "\n",
    "        # Transition\n",
    "        x_t_1 = self.padding_t_1_1(x_e_p_2)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_t_1 = self.conv_t_1_1(x_t_1)              # Conv X shape: torch.Size([3, 32, 109])\n",
    "        x_t_1 = self.act_t_1_1(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 109])\n",
    "        \n",
    "        x_t_1 = self.padding_t_1_2(x_t_1)           # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_t_1 = self.conv_t_1_2(x_t_1)              # Conv X shape: torch.Size([3, 32, 106])\n",
    "        x_t_1 = self.act_t_1_2(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 106])\n",
    "\n",
    "\n",
    "        # Decode 1\n",
    "        x_d_1 = self.upconv_1_1(x_t_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "\n",
    "        x_d_1 = torch.cat([x_d_1, x_e_2], dim=1)    # \n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        x_d_1 = self.conv_d_1_1(x_d_1)              # \n",
    "        x_d_1 = self.act_d_1_1(x_d_1)               # \n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        x_d_1 = self.conv_d_1_2(x_d_1)              # \n",
    "        x_d_1 = self.act_d_1_2(x_d_1)               # \n",
    "\n",
    "\n",
    "        # Decode 2\n",
    "        x_d_2 = self.upconv_2_1(x_d_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "\n",
    "        x_d_2 = torch.cat([x_d_2, x_e_1], dim=1)    # \n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        x_d_2 = self.conv_d_2_1(x_d_2)              # \n",
    "        x_d_2 = self.act_d_2_1(x_d_2)               # \n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        x_d_2 = self.conv_d_2_2(x_d_2)              # \n",
    "        x_d_2 = self.act_d_2_2(x_d_2)               # \n",
    "\n",
    "\n",
    "        # Output\n",
    "\n",
    "        x = torch.flatten(x_d_2, 1)\n",
    "        \n",
    "        x = self.act_out_1(x)\n",
    "        x = self.linear_out_1(x)\n",
    "        \n",
    "        x = self.act_out_2(x)\n",
    "        x = self.linear_out_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A UNet Model variant with 2 encode+decode levels, 2 fully connected layers, and dropouts\n",
    "# Input (1-Dimension 4-Channels)\n",
    "\n",
    "## Notes:\n",
    "#   - \n",
    "class UnetBasedCNNWithDropoutClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(UnetBasedCNNWithDropoutClassifier, self).__init__()\n",
    "\n",
    "        self.input_dropout1 = nn.Dropout(p=0.2)\n",
    "\n",
    "        # First Encode Level\n",
    "        self.padding_e_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.act_e_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_e_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_2 = nn.Conv1d(8, 8, kernel_size=4)\n",
    "        self.act_e_1_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_1_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "\n",
    "        # Second Encode Level        \n",
    "        self.padding_e_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_1 = nn.Conv1d(8, 16, kernel_size=4)\n",
    "        self.act_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_e_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_e_2_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_2_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "        \n",
    "        # Transition Level\n",
    "        self.padding_t_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_1 = nn.Conv1d(16, 32, kernel_size = 4)\n",
    "        self.act_t_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_t_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_2 = nn.Conv1d(32, 32, kernel_size = 4)\n",
    "        self.act_t_1_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # First Decode Level\n",
    "        self.upconv_1_1 = nn.ConvTranspose1d(32, 16, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_1 = nn.Conv1d(32, 16, kernel_size=4)\n",
    "        self.act_d_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_d_1_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # Second Decode Level\n",
    "        self.upconv_2_1 = nn.ConvTranspose1d(16, 8, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_1 = nn.Conv1d(16, 8, kernel_size=4)\n",
    "        self.act_d_2_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_2 = nn.Conv1d(8, 8, kernel_size=4)\n",
    "        self.act_d_2_2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        # Output Level\n",
    "        self.conv_out_1 = nn.Conv1d(8, nClasses, kernel_size=1)\n",
    "        \n",
    "        \n",
    "        self.output_dropout1 = nn.Dropout(p=0.2)\n",
    "        self.linear_out_1 = nn.Linear(7200, 14400)\n",
    "        self.act_out_1 = nn.ReLU()\n",
    "\n",
    "        \n",
    "        self.output_dropout2 = nn.Dropout(p=0.2)\n",
    "        self.linear_out_2 = nn.Linear(14400, nClasses)\n",
    "        self.act_out_2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.reshape(x.shape[0],4,-1)              # Reshape X shape: torch.Size([3, 4, 900])\n",
    "        x = self.input_dropout1(x)\n",
    "\n",
    "        x_e_1 = self.padding_e_1_1(x)               # Padding X shape: torch.Size([3, 4, 900])\n",
    "        x_e_1 = self.conv_e_1_1(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        x_e_1 = self.act_e_1_1(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        \n",
    "        x_e_1 = self.padding_e_1_2(x_e_1)           # Padding X shape: torch.Size([3, 8, 903])\n",
    "        x_e_1 = self.conv_e_1_2(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        x_e_1 = self.act_e_1_2(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        \n",
    "        x_e_p_1 = self.avgPool_e_1_1(x_e_1)         # Pool X shape: torch.Size([3, 8, 450])\n",
    "\n",
    "\n",
    "        x_e_2 = self.padding_e_2_1(x_e_p_1)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_e_2 = self.conv_e_2_1(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_1(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "        \n",
    "        x_e_2 = self.padding_e_2_2(x_e_2)           # Padding X shape: torch.Size([3, 16, 453])\n",
    "        x_e_2 = self.conv_e_2_2(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_2(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "\n",
    "        x_e_p_2 = self.avgPool_e_2_1(x_e_2)         # Pool X shape: torch.Size([3, 16, 225])\n",
    "\n",
    "\n",
    "        x_t_1 = self.padding_t_1_1(x_e_p_2)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_t_1 = self.conv_t_1_1(x_t_1)              # Conv X shape: torch.Size([3, 32, 109])\n",
    "        x_t_1 = self.act_t_1_1(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 109])\n",
    "        \n",
    "        x_t_1 = self.padding_t_1_2(x_t_1)           # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_t_1 = self.conv_t_1_2(x_t_1)              # Conv X shape: torch.Size([3, 32, 106])\n",
    "        x_t_1 = self.act_t_1_2(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 106])\n",
    "\n",
    "\n",
    "        x_d_1 = self.upconv_1_1(x_t_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "\n",
    "        x_d_1 = torch.cat([x_d_1, x_e_2], dim=1)    # \n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        x_d_1 = self.conv_d_1_1(x_d_1)              # \n",
    "        x_d_1 = self.act_d_1_1(x_d_1)               # \n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        x_d_1 = self.conv_d_1_2(x_d_1)              # \n",
    "        x_d_1 = self.act_d_1_2(x_d_1)               # \n",
    "\n",
    "\n",
    "        x_d_2 = self.upconv_2_1(x_d_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "\n",
    "        x_d_2 = torch.cat([x_d_2, x_e_1], dim=1)    # \n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        x_d_2 = self.conv_d_2_1(x_d_2)              # \n",
    "        x_d_2 = self.act_d_2_1(x_d_2)               # \n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        x_d_2 = self.conv_d_2_2(x_d_2)              # \n",
    "        x_d_2 = self.act_d_2_2(x_d_2)               # \n",
    "\n",
    "\n",
    "        x = torch.flatten(x_d_2, 1)\n",
    "        x = self.output_dropout1(x)\n",
    "        \n",
    "        x = self.act_out_1(x)\n",
    "        x = self.linear_out_1(x)\n",
    "        \n",
    "        x = self.output_dropout2(x)\n",
    "        x = self.act_out_2(x)\n",
    "        x = self.linear_out_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A UNet Model with 2 encode(with dilation)+decode levels and 2 fully connected layers\n",
    "# Input (1-Dimension 4-Channels)\n",
    "\n",
    "## Notes:\n",
    "#   - \n",
    "class UnetBasedCNNWithDilationClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(UnetBasedCNNWithDilationClassifier, self).__init__()\n",
    "\n",
    "        # First Encode Level\n",
    "        self.padding_e_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.act_e_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.convd_e_1_1 = nn.Conv1d(4, 8, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "        self.actd_e_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_e_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_e_1_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_1_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "        # Second Encode Level        \n",
    "        self.padding_e_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_1 = nn.Conv1d(16, 32, kernel_size=4)\n",
    "        self.act_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.convd_e_2_1 = nn.Conv1d(16, 32, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "        self.actd_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_e_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_2 = nn.Conv1d(64, 64, kernel_size=4)\n",
    "        self.act_e_2_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_2_1 = nn.AvgPool1d(2, stride=2)\n",
    "        \n",
    "        # Transition Level\n",
    "        self.padding_t_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_1 = nn.Conv1d(64, 128, kernel_size = 4)\n",
    "        self.act_t_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_t_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_2 = nn.Conv1d(128, 128, kernel_size = 4)\n",
    "        self.act_t_1_2 = nn.ReLU()\n",
    "\n",
    "        # First Decode Level\n",
    "        self.upconv_1_1 = nn.ConvTranspose1d(128, 64, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_1 = nn.Conv1d(128, 64, kernel_size=4)\n",
    "        self.act_d_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_2 = nn.Conv1d(64, 64, kernel_size=4)\n",
    "        self.act_d_1_2 = nn.ReLU()\n",
    "\n",
    "        # Second Decode Level\n",
    "        self.upconv_2_1 = nn.ConvTranspose1d(64, 32, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_1 = nn.Conv1d(48, 24, kernel_size=4)\n",
    "        self.act_d_2_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_2 = nn.Conv1d(24, 24, kernel_size=4)\n",
    "        self.act_d_2_2 = nn.ReLU()\n",
    "\n",
    "        # Output Level\n",
    "        self.conv_out_1 = nn.Conv1d(24, nClasses, kernel_size=1)\n",
    "        \n",
    "        self.linear_out_1 = nn.Linear(21600, 7200)\n",
    "        self.act_out_1 = nn.ReLU()\n",
    "\n",
    "        self.linear_out_2 = nn.Linear(7200, nClasses)\n",
    "        self.act_out_2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.reshape(x.shape[0],4,-1)              # Reshape X shape: torch.Size([3, 4, 900])\n",
    "\n",
    "        # Encoder 1\n",
    "        x_e_1 = self.padding_e_1_1(x)               # Padding X shape: torch.Size([3, 4, 900])\n",
    "        x_e_1 = self.conv_e_1_1(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])        \n",
    "        x_e_1 = self.act_e_1_1(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])        \n",
    "\n",
    "        x_e_1_d = self.convd_e_1_1(x)\n",
    "        x_e_1_d = self.actd_e_1_1(x_e_1_d)\n",
    "        \n",
    "        x_e_1 = torch.cat([x_e_1, x_e_1_d], dim=1)\n",
    "        \n",
    "        x_e_1 = self.padding_e_1_2(x_e_1)           # Padding X shape: torch.Size([3, 8, 903])\n",
    "        x_e_1 = self.conv_e_1_2(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        x_e_1 = self.act_e_1_2(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        \n",
    "        x_e_p_1 = self.avgPool_e_1_1(x_e_1)         # Pool X shape: torch.Size([3, 8, 450])\n",
    "\n",
    "        # Encoder 2\n",
    "        x_e_2 = self.padding_e_2_1(x_e_p_1)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_e_2 = self.conv_e_2_1(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_1(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "\n",
    "        x_e_2_d = self.convd_e_2_1(x_e_p_1)\n",
    "        x_e_2_d = self.actd_e_2_1(x_e_2_d)        \n",
    "        x_e_2 = torch.cat([x_e_2, x_e_2_d], dim=1)\n",
    "        \n",
    "        x_e_2 = self.padding_e_2_2(x_e_2)           # Padding X shape: torch.Size([3, 16, 453])\n",
    "        x_e_2 = self.conv_e_2_2(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_2(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "\n",
    "        x_e_p_2 = self.avgPool_e_2_1(x_e_2)         # Pool X shape: torch.Size([3, 16, 225])\n",
    "\n",
    "\n",
    "        # Transition\n",
    "        x_t_1 = self.padding_t_1_1(x_e_p_2)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_t_1 = self.conv_t_1_1(x_t_1)              # Conv X shape: torch.Size([3, 32, 109])\n",
    "        x_t_1 = self.act_t_1_1(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 109])\n",
    "        \n",
    "        x_t_1 = self.padding_t_1_2(x_t_1)           # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_t_1 = self.conv_t_1_2(x_t_1)              # Conv X shape: torch.Size([3, 32, 106])\n",
    "        x_t_1 = self.act_t_1_2(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 106])\n",
    "\n",
    "\n",
    "        # Decode 1\n",
    "        x_d_1 = self.upconv_1_1(x_t_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "\n",
    "        x_d_1 = torch.cat([x_d_1, x_e_2], dim=1)    # \n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        x_d_1 = self.conv_d_1_1(x_d_1)              # \n",
    "        x_d_1 = self.act_d_1_1(x_d_1)               # \n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        x_d_1 = self.conv_d_1_2(x_d_1)              # \n",
    "        x_d_1 = self.act_d_1_2(x_d_1)               # \n",
    "\n",
    "\n",
    "        # Decode 2\n",
    "        x_d_2 = self.upconv_2_1(x_d_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "\n",
    "        x_d_2 = torch.cat([x_d_2, x_e_1], dim=1)    # \n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        x_d_2 = self.conv_d_2_1(x_d_2)              # \n",
    "        x_d_2 = self.act_d_2_1(x_d_2)               # \n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        x_d_2 = self.conv_d_2_2(x_d_2)              # \n",
    "        x_d_2 = self.act_d_2_2(x_d_2)               # \n",
    "\n",
    "\n",
    "        # Output\n",
    "        x = torch.flatten(x_d_2, 1)\n",
    "\n",
    "        x = self.act_out_1(x)\n",
    "        x = self.linear_out_1(x)\n",
    "        \n",
    "        x = self.act_out_2(x)\n",
    "        x = self.linear_out_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A UNet Model variant with 2 encode(with dilation)+decode levels, 2 fully connected layers, and dropouts\n",
    "# Input (1-Dimension 4-Channels)\n",
    "\n",
    "## Notes:\n",
    "#   - \n",
    "class UnetBasedCNNWithDropoutAndDilationClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(UnetBasedCNNWithDropoutAndDilationClassifier, self).__init__()\n",
    "\n",
    "        self.input_dropout1 = nn.Dropout(p=0.2)\n",
    "\n",
    "        # First Encode Level\n",
    "        self.padding_e_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.act_e_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.convd_e_1_1 = nn.Conv1d(4, 8, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "        self.actd_e_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_e_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_1_2 = nn.Conv1d(16, 16, kernel_size=4)\n",
    "        self.act_e_1_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_1_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "        # Second Encode Level        \n",
    "        self.padding_e_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_1 = nn.Conv1d(16, 32, kernel_size=4)\n",
    "        self.act_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.convd_e_2_1 = nn.Conv1d(16, 32, kernel_size=4, groups=4, dilation=2, padding=3, padding_mode=\"circular\")\n",
    "        self.actd_e_2_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_e_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_e_2_2 = nn.Conv1d(64, 64, kernel_size=4)\n",
    "        self.act_e_2_2 = nn.ReLU()\n",
    "\n",
    "        self.avgPool_e_2_1 = nn.AvgPool1d(2, stride=2)\n",
    "\n",
    "        # Transition Level\n",
    "        self.padding_t_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_1 = nn.Conv1d(64, 128, kernel_size = 4)\n",
    "        self.act_t_1_1 = nn.ReLU()\n",
    "        \n",
    "        self.padding_t_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_t_1_2 = nn.Conv1d(128, 128, kernel_size = 4)\n",
    "        self.act_t_1_2 = nn.ReLU()\n",
    "\n",
    "        # First Decode Level\n",
    "        self.upconv_1_1 = nn.ConvTranspose1d(128, 64, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_1_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_1 = nn.Conv1d(128, 64, kernel_size=4)\n",
    "        self.act_d_1_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_1_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_1_2 = nn.Conv1d(64, 64, kernel_size=4)\n",
    "        self.act_d_1_2 = nn.ReLU()\n",
    "\n",
    "        # Second Decode Level\n",
    "        self.upconv_2_1 = nn.ConvTranspose1d(64, 32, kernel_size=2, stride=2)\n",
    "\n",
    "        self.padding_d_2_1 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_1 = nn.Conv1d(48, 24, kernel_size=4)\n",
    "        self.act_d_2_1 = nn.ReLU()\n",
    "\n",
    "        self.padding_d_2_2 = nn.CircularPad1d((1,2))\n",
    "        self.conv_d_2_2 = nn.Conv1d(24, 24, kernel_size=4)\n",
    "        self.act_d_2_2 = nn.ReLU()\n",
    "\n",
    "        # Output Level\n",
    "        self.conv_out_1 = nn.Conv1d(24, nClasses, kernel_size=1)\n",
    "        \n",
    "        self.output_dropout1 = nn.Dropout(p=0.2)\n",
    "        self.linear_out_1 = nn.Linear(21600, 43200)\n",
    "        self.act_out_1 = nn.ReLU()\n",
    "\n",
    "        self.output_dropout2 = nn.Dropout(p=0.2)\n",
    "        self.linear_out_2 = nn.Linear(43200, nClasses)\n",
    "        self.act_out_2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0],4,-1)              # Reshape X shape: torch.Size([3, 4, 900])\n",
    "\n",
    "        x = self.input_dropout1(x)\n",
    "\n",
    "        # Encode 1\n",
    "        x_e_1 = self.padding_e_1_1(x)               # Padding X shape: torch.Size([3, 4, 900])\n",
    "        x_e_1 = self.conv_e_1_1(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])        \n",
    "        x_e_1 = self.act_e_1_1(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])        \n",
    "\n",
    "        x_e_1_d = self.convd_e_1_1(x)\n",
    "        x_e_1_d = self.actd_e_1_1(x_e_1_d)\n",
    "        \n",
    "        x_e_1 = torch.cat([x_e_1, x_e_1_d], dim=1)\n",
    "        \n",
    "        x_e_1 = self.padding_e_1_2(x_e_1)           # Padding X shape: torch.Size([3, 8, 903])\n",
    "        x_e_1 = self.conv_e_1_2(x_e_1)              # Conv X shape: torch.Size([3, 8, 900])\n",
    "        x_e_1 = self.act_e_1_2(x_e_1)               # ActFunc X shape: torch.Size([3, 8, 900])\n",
    "        \n",
    "        x_e_p_1 = self.avgPool_e_1_1(x_e_1)         # Pool X shape: torch.Size([3, 8, 450])\n",
    "\n",
    "        # Encode 2\n",
    "        x_e_2 = self.padding_e_2_1(x_e_p_1)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_e_2 = self.conv_e_2_1(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_1(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "\n",
    "        x_e_2_d = self.convd_e_2_1(x_e_p_1)\n",
    "        x_e_2_d = self.actd_e_2_1(x_e_2_d)        \n",
    "        x_e_2 = torch.cat([x_e_2, x_e_2_d], dim=1)\n",
    "        \n",
    "        x_e_2 = self.padding_e_2_2(x_e_2)           # Padding X shape: torch.Size([3, 16, 453])\n",
    "        x_e_2 = self.conv_e_2_2(x_e_2)              # Conv X shape: torch.Size([3, 16, 450])\n",
    "        x_e_2 = self.act_e_2_2(x_e_2)               # ActFunc X shape: torch.Size([3, 16, 450])\n",
    "\n",
    "        x_e_p_2 = self.avgPool_e_2_1(x_e_2)         # Pool X shape: torch.Size([3, 16, 225])\n",
    "\n",
    "        # Transition\n",
    "        x_t_1 = self.padding_t_1_1(x_e_p_2)         # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_t_1 = self.conv_t_1_1(x_t_1)              # Conv X shape: torch.Size([3, 32, 109])\n",
    "        x_t_1 = self.act_t_1_1(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 109])\n",
    "        \n",
    "        x_t_1 = self.padding_t_1_2(x_t_1)           # Padding X shape: torch.Size([3, 8, 453])\n",
    "        x_t_1 = self.conv_t_1_2(x_t_1)              # Conv X shape: torch.Size([3, 32, 106])\n",
    "        x_t_1 = self.act_t_1_2(x_t_1)               # ActFunc X shape: torch.Size([3, 32, 106])\n",
    "\n",
    "        # Decode 1\n",
    "        x_d_1 = self.upconv_1_1(x_t_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "\n",
    "        x_d_1 = torch.cat([x_d_1, x_e_2], dim=1)    # \n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        x_d_1 = self.conv_d_1_1(x_d_1)              # \n",
    "        x_d_1 = self.act_d_1_1(x_d_1)               # \n",
    "\n",
    "        x_d_1 = self.padding_e_1_1(x_d_1)           # \n",
    "        x_d_1 = self.conv_d_1_2(x_d_1)              # \n",
    "        x_d_1 = self.act_d_1_2(x_d_1)               # \n",
    "\n",
    "        # Decode 2\n",
    "        x_d_2 = self.upconv_2_1(x_d_1)              # UpConv X shape: torch.Size([3, 16, 214])\n",
    "\n",
    "        x_d_2 = torch.cat([x_d_2, x_e_1], dim=1)    # \n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        x_d_2 = self.conv_d_2_1(x_d_2)              # \n",
    "        x_d_2 = self.act_d_2_1(x_d_2)               # \n",
    "\n",
    "        x_d_2 = self.padding_e_1_1(x_d_2)           # \n",
    "        x_d_2 = self.conv_d_2_2(x_d_2)              # \n",
    "        x_d_2 = self.act_d_2_2(x_d_2)               # \n",
    "\n",
    "        # Output\n",
    "        x = torch.flatten(x_d_2, 1)\n",
    "\n",
    "        x = self.output_dropout1(x)\n",
    "        x = self.act_out_1(x)\n",
    "        x = self.linear_out_1(x)\n",
    "        \n",
    "        x = self.output_dropout2(x)\n",
    "        x = self.act_out_2(x)\n",
    "        x = self.linear_out_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary models tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier1(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier1, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "\n",
    "        self.padding2 = nn.CircularPad1d((1,2))\n",
    "        self.conv2 = nn.Conv1d(8, 32, kernel_size=4)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.padding3 = nn.CircularPad1d((1,2))\n",
    "        self.conv3 = nn.Conv1d(32, 128, kernel_size=4)\n",
    "        self.adAvgPool3 = nn.AdaptiveAvgPool1d(225)\n",
    "\n",
    "        self.linear1 = nn.Linear(28800, 14400)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(14400, 7200)\n",
    "        self.act5 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "\n",
    "        x = self.conv1(self.padding1(x))\n",
    "        x = self.adAvgPool1(x)\n",
    "\n",
    "        x = self.conv2(self.padding2(x))\n",
    "        x = self.adAvgPool2(x)\n",
    "        \n",
    "        x = self.conv3(self.padding3(x))\n",
    "        x = self.adAvgPool3(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.act5(x)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier2(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier2, self).__init__()\n",
    "        \n",
    "        # First convolutional layer\n",
    "        # Input: (batch_size, 1, 4, 900)\n",
    "        self.padding1 = nn.CircularPad2d((1, 2, 1, 1))\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 4), stride=1)\n",
    "        # Output: (batch_size, 8, 900, 4)\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        self.padding2 = nn.CircularPad2d((1, 2, 1, 1))\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 4), stride=1)\n",
    "        # Output: (batch_size, 16, 4, 900)\n",
    "        \n",
    "        # Third convolutional layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 4), stride=1, padding=(1, 0), padding_mode=\"circular\")\n",
    "        # Output: (batch_size, 32, 1, 900)\n",
    "        \n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear((32 * 1 * 900 ), (nClasses*2))\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        self.fc2 = nn.Linear((nClasses*2), nClasses)\n",
    "        \n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x,1)\n",
    "\n",
    "        # Convolutional layers\n",
    "        x = self.padding1(x)\n",
    "        x = self.relu(self.conv1(x))\n",
    "\n",
    "        x = self.padding2(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        \n",
    "        x = self.relu(self.conv3(x))\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.relu(self.fc1(self.dropout1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier3(nn.Module):\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier3, self).__init__()\n",
    "\n",
    "        self.padding1 = nn.CircularPad1d((1,2))\n",
    "        self.conv1 = nn.Conv1d(4, 8, kernel_size=4)\n",
    "\n",
    "        self.padding2 = nn.CircularPad1d((1,2))\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=4)\n",
    "\n",
    "        self.padding3 = nn.CircularPad1d((1,2))\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=4)\n",
    "\n",
    "        self.linear1 = nn.Linear(28800, 7200)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(7200, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "        x = self.conv1(self.padding1(x))\n",
    "        x = self.conv2(self.padding2(x))        \n",
    "        x = self.conv3(self.padding3(x))\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [\n",
    "    # \"genus\",\n",
    "    # \"species\",\n",
    "    # \"order\", \n",
    "    # \"family\", \n",
    "    \"class\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [\n",
    "    # 64,\n",
    "    # 128,\n",
    "    # 256,\n",
    "    # 512,\n",
    "    # 2048,\n",
    "    \"dynamic\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [\n",
    "    # 2,\n",
    "    # 5,\n",
    "    # 50,\n",
    "    100,\n",
    "    # 150,\n",
    "    # 200,\n",
    "    # 500\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [\n",
    "    # SimplestCNNClassifier,\n",
    "    # SimpleCNNClassifier,\n",
    "    # SimpleCNNWithDropoutClassifier,\n",
    "    # BaseCNNClassifier,\n",
    "    # UnetBasedCNNClassifier,\n",
    "    # UnetBasedCNNWithDropoutClassifier,\n",
    "    # UnetBasedCNNWithDilationClassifier,\n",
    "    # UnetBasedCNNWithDropoutAndDilationClassifier,\n",
    "    SimplestCNNClassifier1,\n",
    "    SimplestCNNClassifier2,\n",
    "    SimplestCNNClassifier3,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_functions = {\n",
    "    \"CrossEntropyLoss\":{\n",
    "        \"function\":nn.CrossEntropyLoss,\n",
    "        \"params\":{},\n",
    "        \"function_params\":{}\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [\n",
    "    # 1e-2,\n",
    "    # 5e-2,\n",
    "    # 1e-3,\n",
    "    # 5e-3,\n",
    "    # 1e-4,\n",
    "    5e-4,\n",
    "    # 1e-4,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [\n",
    "    {\n",
    "        \"optim\":torch.optim.AdamW,\n",
    "        \"params\":{\n",
    "            \"weight_decay\":1e-3,\n",
    "            \"amsgrad\":True\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparams = {\n",
    "    \"batch_size\": batch_sizes,\n",
    "    \"epochs\": epochs,\n",
    "    \"model\": models_list,\n",
    "    \"loss_function\": loss_functions,\n",
    "    \"learning_rate\": learning_rates,\n",
    "    \"optimizer\": optimizers    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Test(model, loss_fn, optimizer, epochs, learning_rate, batch_size, train_data,test_data,id=\"\"):\n",
    "    \n",
    "    print(\"Model: \\t\\t\\t\"+(model._get_name() if not model._get_name() == \"OptimizedModule\" else model.__dict__[\"_modules\"][\"_orig_mod\"].__class__.__name__))\n",
    "    print(\"  Loss Func.: \\t\\t\"+loss_fn._get_name())\n",
    "    print(\"  Optimizer: \\t\\t\"+type(optimizer).__name__)\n",
    "    print(\"  Epochs: \\t\\t\"+str(epochs))\n",
    "    print(\"  Learning Rate: \\t\"+str(learning_rate))\n",
    "\n",
    "    print(\"\\nModel Arch: \")\n",
    "    print(str(model))\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    # Test CUDA compatibility\n",
    "    if torch.cuda.get_device_capability() < (7, 0):\n",
    "        print(\"Exiting because torch.compile is not supported on this device.\")\n",
    "        import sys\n",
    "        sys.exit(0)\n",
    "\n",
    "\n",
    "    epochs_results = []\n",
    "    current = {\n",
    "        \"model\":(model._get_name() if not model._get_name() == \"OptimizedModule\" else model.__dict__[\"_modules\"][\"_orig_mod\"].__class__.__name__),\n",
    "        \"loss_function\":loss_fn._get_name(),\n",
    "        \"epoch\":None,\n",
    "        \"learning_rate\":learning_rate,\n",
    "        \"batch_size\":None,\n",
    "        \"train_size\":None,\n",
    "        \"test_size\":None,\n",
    "        \"optimizer\":type(optimizer).__name__,\n",
    "        \"train_acc\":None,\n",
    "        \"train_loss\":None,\n",
    "        \"test_acc\":None,\n",
    "        \"test_loss\":None,\n",
    "    }\n",
    "\n",
    "    # Prepare batch sizes to use\n",
    "    if batch_size == \"dynamic\":\n",
    "        bss = [10000, 64, 3000, 64, 3000]\n",
    "    else:\n",
    "        bss = [batch_size]\n",
    "    if len(bss) > epochs:\n",
    "        bss = bss[0:epochs]\n",
    "    print(\"Batch Sizes List: \"+str(bss))\n",
    "    batch_lim = int(epochs/len(bss))\n",
    "    \n",
    "    \n",
    "    t_start = time.time()\n",
    "    best = {\n",
    "        \"epoch\":0,\n",
    "        \"train_acc\":0,\n",
    "        \"train_loss\":10000000,\n",
    "        \"test_acc\":0,\n",
    "        \"test_loss\":10000000,\n",
    "    }\n",
    "    \n",
    "    train_loader = None\n",
    "    test_loader = None\n",
    "    \n",
    "    # Epochs\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "\n",
    "        # Create DataLoaders with current batch size\n",
    "        if epoch%batch_lim == 0 and len(bss) > 0:\n",
    "            if train_loader:\n",
    "                del train_loader\n",
    "            if test_loader:\n",
    "                del test_loader\n",
    "\n",
    "            batch_size = bss.pop(0)\n",
    "            train_loader, test_loader = loaders_generator(train_data, test_data, batch_size)\n",
    "\n",
    "        print(\"Batch Size: \"+str(batch_size))\n",
    "        \n",
    "        \n",
    "        # Train Phase\n",
    "\n",
    "        # Compile optimizer function\n",
    "        fn = torch.compile(optimizer.step)\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "\n",
    "        # Run train over the batches\n",
    "        for batch, (X, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            # Compute prediction and loss\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            fn()\n",
    "\n",
    "            # Update results\n",
    "            train_loss += loss.item()\n",
    "            train_acc += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "        # Train results\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(train_loader.dataset)\n",
    "        print(f\"Train Error: \\n Accuracy: {(100*train_acc):>0.1f}%, Avg loss: {train_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "        # Test Phase\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_loader:\n",
    "                pred = model(X)\n",
    "                test_loss += loss_fn(pred, y).item()\n",
    "                test_acc += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "        # Test results\n",
    "        test_loss /= len(test_loader)\n",
    "        test_acc /= len(test_loader.dataset)\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*test_acc):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "        # Update Results\n",
    "        if best[\"test_acc\"] < test_acc or (best[\"test_acc\"] == test_acc and best[\"train_acc\"] < train_acc):\n",
    "            best[\"epoch\"] = epoch+1\n",
    "            best[\"test_acc\"] = test_acc\n",
    "            best[\"test_loss\"] = test_loss\n",
    "            best[\"train_acc\"] = train_acc\n",
    "            best[\"train_loss\"] = train_loss\n",
    "\n",
    "            # If accuracy over 50%, export the current best treined model\n",
    "            if test_acc > 0.5:\n",
    "                torch.save(model.state_dict(), \"/media/stark/Models/Gustavo/\"+train_data.level+\"/\"+str(id)+\"_\"+current[\"model\"]+\".pth\")\n",
    "                                \n",
    "                    \n",
    "        current[\"epoch\"] = epoch+1\n",
    "        current[\"batch_size\"] = batch_size\n",
    "        current[\"train_size\"] = train_loader.dataset.__len__()\n",
    "        current[\"test_size\"] = test_loader.dataset.__len__()\n",
    "        current[\"train_acc\"] = train_acc\n",
    "        current[\"train_loss\"] = train_loss\n",
    "        current[\"test_acc\"] = test_acc\n",
    "        current[\"test_loss\"] = test_loss\n",
    "\n",
    "        epochs_results.append(current.copy())\n",
    "\n",
    "    # Save Train/Test iteration information\n",
    "    pd.DataFrame(epochs_results).to_csv(\"./results/epochs/\"+str(id)+\"__\"+current[\"model\"]+\"_train_test.csv\")\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"Best Epoch:{best['epoch']} \\n\\tAccuracy: {(100*best['test_acc']):>0.1f}%, Avg loss: {best['test_loss']:>8f} \\n\")\n",
    "    print(\"Train and Test execution time: \"+str(format(time.time()-t_start, '.4f'))+\"s\")\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Global references\n",
    "_model_ = None\n",
    "_lossfunction_ = None\n",
    "_optimizer_ = None\n",
    "\n",
    "# Function to clean cache\n",
    "def clear():\n",
    "    global _model_, _lossfunction_, _optimizer_\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    torch.compiler.reset()\n",
    "    torch._dynamo.reset()\n",
    "\n",
    "    if _model_:\n",
    "        del _model_\n",
    "        _model_ = None\n",
    "    if _lossfunction_:\n",
    "        del _lossfunction_\n",
    "        _lossfunction_ = None\n",
    "    if _optimizer_:\n",
    "        del _optimizer_\n",
    "        _optimizer_ = None\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "results = []\n",
    "current = {}\n",
    "\n",
    "id = 0\n",
    "time_id = str(int(time.time()))\n",
    "print(\"Time ID: \"+str(time_id))\n",
    "\n",
    "for level in levels:\n",
    "    clear()\n",
    "\n",
    "    # Load train and test datasets\n",
    "    train_data = pd.read_csv(\"../new_data/StratifiedSplit/\"+level+\"/train_dataset.csv\")\n",
    "    test_data = pd.read_csv(\"../new_data/StratifiedSplit/\"+level+\"/test_dataset.csv\")\n",
    "    print(level)\n",
    "    print(train_data.shape)\n",
    "    print(test_data.shape)\n",
    "\n",
    "    dataset = SequenceDataset(\n",
    "        train=train_data, \n",
    "        test=test_data, \n",
    "        level=level)\n",
    "\n",
    "\n",
    "    for batch_size in hiperparams[\"batch_size\"]:\n",
    "        for epochs in hiperparams[\"epochs\"]:\n",
    "            for model in hiperparams[\"model\"]:\n",
    "                for loss_function_name, loss_function in hiperparams[\"loss_function\"].items():\n",
    "                    for learning_rate in hiperparams[\"learning_rate\"]:\n",
    "                        for optimizer in hiperparams[\"optimizer\"]:\n",
    "                            \n",
    "                            optim = optimizer[\"optim\"]\n",
    "                            optim_params = optimizer[\"params\"] if \"params\" in optimizer.keys() else {}\n",
    "\n",
    "                            current = {\n",
    "                                    \"id\": id,\n",
    "                                    \"start_time\":time.time(),\n",
    "                                    \"end_time\": None,\n",
    "                                    \"level\": level,\n",
    "                                    \"batch_size\": batch_size,\n",
    "                                    \"epochs\": epochs,\n",
    "                                    \"model\": model.__name__,\n",
    "                                    \"loss_function\": loss_function_name+\" (\"+str(loss_function[\"function\"])+\")\",\n",
    "                                    \"learning_rate\": learning_rate,\n",
    "                                    \"optimizer\": optim.__name__+\" (params: \"+str(optim_params)+\")\",\n",
    "                                    \"obs\": \"9:1\",\n",
    "                                    \"error\": None\n",
    "                                }\n",
    "\n",
    "\n",
    "                            try:                                \n",
    "                                clear()\n",
    "\n",
    "                                # Change precision to improve model performance \n",
    "                                torch.set_float32_matmul_precision('high')\n",
    "                                \n",
    "                                # Initialize a compiled model, loss function, and optimizer\n",
    "                                _model_ = torch.compile(model(dataset.encoded_labels.shape[1]))\n",
    "                                _lossfunction_ = loss_function[\"function\"](**{func:params[0](*params[1:]) for func,params in loss_function[\"function_params\"].items()})\n",
    "                                _optimizer_ = optim(_model_.parameters(), lr=learning_rate, **optim_params)\n",
    "\n",
    "\n",
    "                                # Runt Train-Test\n",
    "                                result = Train_Test(\n",
    "                                    model=_model_,\n",
    "                                    loss_fn=_lossfunction_,\n",
    "                                    optimizer=_optimizer_,\n",
    "                                    epochs=epochs,\n",
    "                                    learning_rate=learning_rate,\n",
    "                                    batch_size=batch_size,\n",
    "                                    train_data=dataset,\n",
    "                                    test_data=dataset.get_test(),\n",
    "                                    id=time_id+\"_\"+str(id),\n",
    "                                    )\n",
    "                                    \n",
    "                                current[\"end_time\"] = time.time()\n",
    "                                current[\"best_epoch\"] = result[\"epoch\"]\n",
    "                                current[\"train_acc_best_epoch\"] = result[\"train_acc\"]\n",
    "                                current[\"train_loss_best_epoch\"] = result[\"train_loss\"]\n",
    "                                current[\"test_acc_best_epoch\"] = result[\"test_acc\"]\n",
    "                                current[\"test_loss_best_epoch\"] = result[\"test_loss\"]\n",
    "\n",
    "                                clear()                                \n",
    "                                \n",
    "                            except Exception as e:\n",
    "                                print(e)\n",
    "                                current[\"error\"] = str(e)\n",
    "                            \n",
    "                            # Save the results\n",
    "                            results.append(current)\n",
    "                            pd.DataFrame(results).to_csv(\"./results/summarized/\"+str(time_id)+\"_models_train_test_\"+str(len(results))+\".csv\")\n",
    "                            \n",
    "                            id = id+1\n",
    "\n",
    "clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gustavo_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
