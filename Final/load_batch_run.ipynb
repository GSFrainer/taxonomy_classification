{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.amp import GradScaler\n",
    "\n",
    "# dtype = torch.float\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# torch.set_default_device(device)\n",
    "# torch.get_default_device()\n",
    "\n",
    "from datetime import timedelta\n",
    "import math\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo!\n",
    "\n",
    "- [ ] Salvar lista de classes possíveis no original, de acordo com a config de amostragem\n",
    "- [ ] Remover classes não presentes no original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_map = {\n",
    "    \"A\":[1.0, 0.0, 0.0, 0.0],\n",
    "    \"T\":[0.0, 1.0, 0.0, 0.0],\n",
    "    \"G\":[0.0, 0.0, 1.0, 0.0],\n",
    "    \"C\":[0.0, 0.0, 0.0, 1.0],\n",
    "\n",
    "    'W':[0.5, 0.5, 0.0, 0.0],\n",
    "    'S':[0.0, 0.0, 0.5, 0.5],\n",
    "    'M':[0.5, 0.0, 0.0, 0.5],\n",
    "    'K':[0.0, 0.5, 0.5, 0.0],\n",
    "    'R':[0.5, 0.0, 0.5, 0.0],\n",
    "    'Y':[0.0, 0.5, 0.0, 0.5],\n",
    "    \n",
    "    'B':[0.0, 0.3, 0.3, 0.3],\n",
    "    'D':[0.3, 0.3, 0.3, 0.0],\n",
    "    'H':[0.3, 0.3, 0.0, 0.3],\n",
    "    'V':[0.3, 0.0, 0.3, 0.3],\n",
    "\n",
    "    'N':[0.25, 0.25, 0.25, 0.25],\n",
    "}\n",
    "\n",
    "def encode_sequence(sequence):\n",
    "    encoded_seq = []\n",
    "\n",
    "    for base in sequence:\n",
    "        encoded_seq.append(base_map[base])\n",
    "    \n",
    "    return torch.tensor(encoded_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch dataset object to load Sequences and Classification Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):    \n",
    "    def __init__(self, classes, level, dataset):\n",
    "        self.classes = classes\n",
    "        self.level = level\n",
    "\n",
    "        dataset = dataset.loc[dataset[level].isin(classes)]\n",
    "\n",
    "        self.labels = dataset[level]\n",
    "        self.sequences = SequenceDataset.__sequences__(dataset)\n",
    "        self.encoded_labels = SequenceDataset.__encoded_labels__(self.classes, self.labels)\n",
    "\n",
    "    def __encoded_labels__(classes, labels):\n",
    "        return torch.nn.functional.one_hot(torch.tensor([classes.index(l) for l in labels]), len(classes)).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    def __sequences__(ds):\n",
    "        sequences = []\n",
    "        for _, row in ds.iterrows():\n",
    "            sequences.append(encode_sequence(row[\"truncated_sequence\"]))        \n",
    "        return torch.stack(sequences, dim=0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return   self.sequences[idx], self.encoded_labels[idx]\n",
    "    \n",
    "    def __getitems__(self, ids):\n",
    "        idx = torch.tensor(ids, device=torch.device('cuda:0'))\n",
    "        return   list(zip(torch.index_select(self.sequences, 0, idx), torch.index_select(self.encoded_labels, 0, idx)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate PyTorch DataLoader objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaders_generator(ds_train, ds_test, bs = 128):\n",
    "    train_loader = DataLoader(ds_train, batch_size=bs, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "    test_loader = DataLoader(ds_test, batch_size=bs, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=4):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        # Padding to maintain input size\n",
    "        self.padding = nn.CircularPad1d((1,2))\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        \n",
    "        # Activation\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Store the input for the residual connection\n",
    "        residual = x\n",
    "        \n",
    "        # Main path\n",
    "        out = self.padding(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        residual = self.shortcut(residual)\n",
    "        \n",
    "        # Add residual connection\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplestCNNClassifier_8layers_Residual(nn.Module):\n",
    "    def __init__(self, nClasses):\n",
    "        super(SimplestCNNClassifier_8layers_Residual, self).__init__()\n",
    "        \n",
    "        # Residual blocks with adaptive pooling\n",
    "        self.residual_block1 = ResidualBlock(4, 16)\n",
    "        self.adAvgPool1 = nn.AdaptiveAvgPool1d(450)\n",
    "        \n",
    "        self.residual_block2 = ResidualBlock(16, 32)\n",
    "        self.adAvgPool2 = nn.AdaptiveAvgPool1d(225)\n",
    "        \n",
    "        self.residual_block3 = ResidualBlock(32, 64)\n",
    "        self.adAvgPool3 = nn.AdaptiveAvgPool1d(112)\n",
    "        \n",
    "        self.residual_block4 = ResidualBlock(64, 128)\n",
    "        self.adAvgPool4 = nn.AdaptiveAvgPool1d(56)\n",
    "        \n",
    "        self.residual_block5 = ResidualBlock(128, 256)\n",
    "        self.adAvgPool5 = nn.AdaptiveAvgPool1d(28)\n",
    "        \n",
    "        self.residual_block6 = ResidualBlock(256, 512)\n",
    "        self.adAvgPool6 = nn.AdaptiveAvgPool1d(14)\n",
    "        \n",
    "        # Two additional residual blocks\n",
    "        self.residual_block7 = ResidualBlock(512, 1024)\n",
    "        self.adAvgPool7 = nn.AdaptiveAvgPool1d(7)\n",
    "        \n",
    "        self.residual_block8 = ResidualBlock(1024, 2048)\n",
    "        self.adAvgPool8 = nn.AdaptiveAvgPool1d(3)\n",
    "        \n",
    "        # Activation and fully connected layers\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        # Calculate the input size for linear layers\n",
    "        # Note: You might need to adjust this based on your specific input dimensions\n",
    "        self.linear1 = nn.Linear(6144, 6144)\n",
    "        self.linear2 = nn.Linear(6144, nClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Move channel dimension\n",
    "        x = torch.movedim(x, -1, -2)\n",
    "        \n",
    "        # First residual block\n",
    "        x = self.residual_block1(x)\n",
    "        x = self.adAvgPool1(x)\n",
    "        \n",
    "        # Second residual block\n",
    "        x = self.residual_block2(x)\n",
    "        x = self.adAvgPool2(x)\n",
    "        \n",
    "        # Third residual block\n",
    "        x = self.residual_block3(x)\n",
    "        x = self.adAvgPool3(x)\n",
    "        \n",
    "        # Fourth residual block\n",
    "        x = self.residual_block4(x)\n",
    "        x = self.adAvgPool4(x)\n",
    "        \n",
    "        # Fifth residual block\n",
    "        x = self.residual_block5(x)\n",
    "        x = self.adAvgPool5(x)\n",
    "        \n",
    "        # Sixth residual block\n",
    "        x = self.residual_block6(x)\n",
    "        x = self.adAvgPool6(x)\n",
    "        \n",
    "        # Seventh residual block\n",
    "        x = self.residual_block7(x)\n",
    "        x = self.adAvgPool7(x)\n",
    "        \n",
    "        # Eighth residual block\n",
    "        x = self.residual_block8(x)\n",
    "        x = self.adAvgPool8(x)\n",
    "        \n",
    "        # Flatten and fully connected layers\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global references\n",
    "_model_ = None\n",
    "_lossfunction_ = None\n",
    "_optimizer_ = None\n",
    "\n",
    "# Function to clean cache\n",
    "def clear():\n",
    "    global _model_, _lossfunction_, _optimizer_\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    torch.compiler.reset()\n",
    "    torch._dynamo.reset()\n",
    "\n",
    "    if _model_:\n",
    "        del _model_\n",
    "        _model_ = None\n",
    "    if _lossfunction_:\n",
    "        del _lossfunction_\n",
    "        _lossfunction_ = None\n",
    "    if _optimizer_:\n",
    "        del _optimizer_\n",
    "        _optimizer_ = None\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_once(level, dataset_path, model_path):\n",
    "    \n",
    "    # Clean Models Cache\n",
    "    clear()\n",
    "\n",
    "    times_log = {}\n",
    "    times_log[\"Start_Time\"] = time.time()\n",
    "\n",
    "    # Load Data\n",
    "    data = pd.read_csv(dataset_path)\n",
    "    droped_sequences_by_null = data.shape[0]\n",
    "    data = data.loc[~data[level].isna()]\n",
    "    droped_sequences_by_null = droped_sequences_by_null - data.shape[0]\n",
    "    classes = pd.read_csv(\"./Classes/\"+level+\".csv\")\n",
    "    dataset = SequenceDataset(classes=classes, level=level, dataset=data)\n",
    "    droped_sequences_by_class = data.shape[0] - dataset.__len__()\n",
    "    batch_size = 50000\n",
    "    dataloader = DataLoader(dataset, batch_size, shuffle=True, generator=torch.Generator(device='cuda'))\n",
    "    times_log[\"Data_Loaded_Time\"] = time.time()\n",
    "\n",
    "    # Load Model\n",
    "    _model_ = torch.compile(SimplestCNNClassifier_8layers_Residual(dataset.encoded_labels.shape[1]))\n",
    "    _model_.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "    _model_.eval()\n",
    "    times_log[\"Model_Loaded_Time\"] = time.time()\n",
    "    \n",
    "    # Run Predict\n",
    "    pred_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = _model_(X)\n",
    "            pred_acc += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "    pred_acc /= len(dataloader.dataset)\n",
    "    times_log[\"Prediction_Finished_Time\"] = time.time()\n",
    "\n",
    "    \n",
    "    # Save Results\n",
    "    results = {\n",
    "        \"acc\":0,\n",
    "        \"n_classes\":len(classes.shape[0]),\n",
    "        \"n_sequences\":SequenceDataset.__len__(),\n",
    "        \"droped_sequences_by_null\": droped_sequences_by_null,\n",
    "        \"droped_sequences_by_class\": droped_sequences_by_class,\n",
    "        \"batch_size\":batch_size,\n",
    "        \"reserved_memory\": torch.cuda.memory_reserved() / 1024 / 1024,\n",
    "        **times_log\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level: class\tModel: SimplestCNNClassifier_8layers_Residual\tAccuracy: 0\tTotal time: 0:00:00\n",
      "Level: class\tModel: SimplestCNNClassifier_8layers_Residual\tAccuracy: 0\tTotal time: 0:00:00\n",
      "Level: class\tModel: SimplestCNNClassifier_8layers_Residual\tAccuracy: 0\tTotal time: 0:00:00\n",
      "Level: order\tModel: SimplestCNNClassifier_8layers_Residual\tAccuracy: 0\tTotal time: 0:00:00\n",
      "Level: order\tModel: SimplestCNNClassifier_8layers_Residual\tAccuracy: 0\tTotal time: 0:00:00\n",
      "Level: order\tModel: SimplestCNNClassifier_8layers_Residual\tAccuracy: 0\tTotal time: 0:00:00\n",
      "Level: family\tModel: SimplestCNNClassifier_8layers_Residual\tAccuracy: 0\tTotal time: 0:00:00\n",
      "Level: family\tModel: SimplestCNNClassifier_8layers_Residual\tAccuracy: 0\tTotal time: 0:00:00\n",
      "Level: family\tModel: SimplestCNNClassifier_8layers_Residual\tAccuracy: 0\tTotal time: 0:00:00\n",
      "Level: genus\tModel: SimplestCNNClassifier_8layers_Residual\tAccuracy: 0\tTotal time: 0:00:00\n",
      "Level: genus\tModel: SimplestCNNClassifier_8layers_Residual\tAccuracy: 0\tTotal time: 0:00:00\n",
      "Level: genus\tModel: SimplestCNNClassifier_8layers_Residual\tAccuracy: 0\tTotal time: 0:00:00\n",
      "Level: species\tModel: SimplestCNNClassifier_8layers_Residual\tAccuracy: 0\tTotal time: 0:00:00\n",
      "Level: species\tModel: SimplestCNNClassifier_8layers_Residual\tAccuracy: 0\tTotal time: 0:00:00\n",
      "Level: species\tModel: SimplestCNNClassifier_8layers_Residual\tAccuracy: 0\tTotal time: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "def run_batch(levels, models_list, data_path):\n",
    "    results = []\n",
    "\n",
    "    for level in levels:\n",
    "\n",
    "        level_models = models_list.loc[models_list[\"level\"] == level]\n",
    "        for index, level_model in level_models.iterrows():\n",
    "\n",
    "            # Run\n",
    "            run = run_once(\n",
    "                level = level,\n",
    "                dataset_path = data_path,\n",
    "                model_path = \"./Models/\"+str(level).capitalize()+\"/\"+str(level_model[\"experiment_id\"])+\"_\"+str(index)+\"_\"+level_model[\"model\"]+\".pth\",\n",
    "            )\n",
    "            \n",
    "            # Save Results\n",
    "            results.append(\n",
    "                {\n",
    "                    \"id\":str(index),\n",
    "                    \"level\":level_model[\"level\"],\n",
    "                    \"model\":level_model[\"model\"],\n",
    "                } | run\n",
    "            )\n",
    "\n",
    "            print(\"Level: \"+level+\"\\tModel: \"+level_model[\"model\"]+\"\\tAccuracy: \"+str(run[\"acc\"])+\"\\tTotal time: \"+str(timedelta(seconds=math.floor(run[\"Prediction_Finished_Time\"]-run[\"Start_Time\"]))))\n",
    "\n",
    "    pd.DataFrame(results).to_csv(\"./Results/\"+str(int(time.time()))+\"_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [\n",
    "    \"class\", \n",
    "    \"order\", \n",
    "    \"family\", \n",
    "    \"genus\",\n",
    "    \"species\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = pd.read_csv(\"./Models/Models_List.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../sequences.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "Order\n",
      "Family\n",
      "Genus\n",
      "Species\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
